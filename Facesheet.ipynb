{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e575474",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "#!/usr/bin/env python\n",
    "from flask import Flask, request, send_file, Blueprint\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import io\n",
    "from io import BytesIO\n",
    "import requests\n",
    "from flask.json import jsonify\n",
    "import jwt\n",
    "\n",
    "from random import randint\n",
    "import datetime\n",
    "\n",
    "import smbclient \n",
    "\n",
    "import logging\n",
    "\n",
    "\n",
    "from locale import normalize\n",
    "import spacy\n",
    "\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spaczz.matcher import FuzzyMatcher\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import pyap\n",
    "import usaddress\n",
    "import re\n",
    "import datefinder\n",
    "from dateutil import parser\n",
    "import string\n",
    "from iteration_utilities import unique_everseen\n",
    "from requests_ntlm import HttpNtlmAuth\n",
    "import msoffcrypto\n",
    "from zipfile import ZipFile\n",
    "import traceback\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "from validate_jwt import validate_jwt\n",
    "\n",
    "facesheetextraction = Blueprint(\"facesheetextraction\", __name__)\n",
    "\n",
    "\n",
    "file_path = \"./api/PDQ/reference/Spacy\"\n",
    "nlp = spacy.load(file_path + '/en_core_web_md-3.4.0')\n",
    "matcher = Matcher(nlp.vocab)                    \n",
    "\n",
    "\n",
    "## PART 1 of code from  here\n",
    "REGEXDate=\"^(0[1-9]|1[012])[-/.](0[1-9]|[12][0-9]|3[01])[-/.](19|20)\\d\\d$\"\n",
    "REGEXPhone = r\"\\(?([2-9][0-9]{2})\\)?[-.● ]([0-9]{3})[-.● ]([0-9]{4})\"\n",
    "REGEXPhone2 = r\"\\(?([2-9][0-9]{2})\\)?[-.● ]?([0-9]{3})[-.● ]?([0-9]{4})\"\n",
    "REGEXICDCode = r\"\\b[01a-z][0-9][0-9ab]\\.?\\,?[0-9a-z]{0,4}\"\n",
    "REGEXICDCode_repl = r'[^A-Za-z0-9. ]+'\n",
    "REGEXName=r'[^A-Za-z ,''-]+'\n",
    "REGEXMemberId=r'([u-v][0-9]{10})|([u-v][0-9]{8})|([1]\\d{10})'\n",
    "REGEXMemberId2=r'([1]\\d{8})'\n",
    "REGEXAlphaNumeric=r'[^A-Za-z0-9]+'\n",
    "REGEXMRN=r'[^A-Za-z0-9]+'\n",
    "\n",
    "\n",
    "def getNPI(input):\n",
    "\n",
    "\n",
    "    #npi = input[-10:]\n",
    "    npi=(''.join(filter(str.isdigit, input)))\n",
    "\n",
    "    if not( npi.isnumeric() and len(npi) == 10 and npi.startswith(\"1\")):\n",
    "        return(None)\n",
    "\n",
    "    PARAMS = {'version':'2.1', 'number':npi}\n",
    "    try:\n",
    "        npiresponse = requests.get('https://npiregistry.cms.hhs.gov/api',params=PARAMS)\n",
    "\n",
    "        npiresponsejson  = npiresponse.json()\n",
    "        if \"Errors\" not in npiresponsejson and npiresponsejson['result_count'] != 0 :\n",
    "            return(npiresponsejson)\n",
    "        else:\n",
    "            logging.info('FACE SHEET 2827 : extractFace sheet :  NPI registry Call returned errors:' + str(npiresponsejson) )\n",
    "            return(None)\n",
    "    except:\n",
    "        logging.error('FACE SHEET 2827 : extractFace sheet :  NPI registry Call failed:'  )\n",
    "        return(npi)\n",
    "\n",
    "        #return(None)\n",
    "    \n",
    "def split_name(name):\n",
    "    \"\"\"\n",
    "        Returns the names classified into firstname, lastname and middlename.\n",
    "\n",
    "                Parameters:\n",
    "                        name (str): name\n",
    "\n",
    "                Returns:\n",
    "                         name (dict): a dictionary with names first,last and middle name\n",
    "        \"\"\"\n",
    "    name = name.strip('-')\n",
    "    name = name.replace(\"(m)\",\" \")\n",
    "    name = name.replace(\"(f)\",\" \")\n",
    "    name= removeBrackets(name)\n",
    "    name = name.replace(\"name \",\" \")\n",
    "    name = name.replace(\".\",\",\")\n",
    "    \n",
    "    if \",\" in name:\n",
    "        names = name.split(\",\")\n",
    "        if len(names) >= 2:\n",
    "            last_name = names[0]\n",
    "            names.remove(last_name)\n",
    "            first_name = ''.join([str(nm) for nm in names])\n",
    "            return {'firstName': first_name.strip(), 'lastName': last_name.strip()}\n",
    "    else:\n",
    "        names = name.split()\n",
    "        if len(names) >= 2:\n",
    "            last_name = names[-1]\n",
    "            names.remove(last_name)\n",
    "            first_name = ' '.join([str(nm) for nm in names])\n",
    "            return {'firstName': first_name.strip(), 'lastName': last_name.strip()}\n",
    "        else:\n",
    "            first_name = name\n",
    "            last_name = name\n",
    "            return {'firstName': first_name.strip(),'lastName': last_name.strip()}\n",
    "    \n",
    "    return {'firstName': name.strip(),'lastName': name.strip()}\n",
    "\n",
    "\n",
    "def gettaxId(tin):\n",
    "    tin=tin.strip()\n",
    "    \n",
    "    tinwords=tin.split('/')\n",
    "    if len(tinwords) > 1:\n",
    "        if len(tinwords[0].strip()) ==9:\n",
    "            tin=tinwords[0]\n",
    "        elif len(tinwords[1].strip()) ==9:    \n",
    "            tin=tinwords[1]\n",
    "\n",
    "    tin=(''.join(filter(str.isdigit, tin)))\n",
    "    if tin.isnumeric() and len(tin) == 9:\n",
    "        return(tin)\n",
    "    \n",
    "\n",
    "    return(None)\n",
    "    \n",
    "def formatMRN(mrnRaw):  \n",
    "    mrnRaw=removeBrackets(mrnRaw)\n",
    "    mrnRaw=mrnRaw.replace(\"mrn\",\"\").replace(\"MRN\",\"\")\n",
    "    mrnwords=mrnRaw.split()\n",
    "    for mrnword in mrnwords:\n",
    "        mrn=re.sub(REGEXMRN,'',mrnword)\n",
    "        numbers = sum(c.isdigit() for c in mrn)\n",
    "        if numbers > 2:\n",
    "            return(mrn)\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def getEMR(emrText):\n",
    "    emrText=str(emrText)\n",
    "    if emrText == None: \n",
    "        return (\"N\")\n",
    "    if emrText.upper().find(\"DO NOT REQUEST CLINICAL\")  > -1 or emrText.upper().find(\"DO NOT CALL FOR CLINICAL\") > -1: \n",
    "        return (\"Y\")\n",
    "    if emrText.upper().strip() == \"YES\"  or emrText.upper().strip() == \"Y\": \n",
    "        return (\"Y\")\n",
    "    if emrText.upper().strip() == \"NO\"   or emrText.upper().strip() == \"N\":\n",
    "        return (\"N\")        \n",
    "\n",
    "    return(\"N\")\n",
    "\n",
    "def formatPhone(phone):\n",
    "    if phone is None:\n",
    "        return(None)\n",
    "    \n",
    "    phoneNo = (''.join(filter(str.isdigit, phone)))\n",
    "    if len(phoneNo) < 10:\n",
    "        return(None)\n",
    "        \n",
    "    if phoneNo is not None:\n",
    "        if phoneNo.startswith('91') and len(phoneNo) > 11:\n",
    "            phoneNo==phoneNo[2:12]\n",
    "        elif phoneNo.startswith('1'):\n",
    "            phoneNo=phoneNo[1:11]\n",
    "        else:\n",
    "            phoneNo=phoneNo[0:10]\n",
    "\n",
    "    return(phoneNo)\n",
    "\n",
    "def removeBrackets(text):\n",
    "    if text.find('(') != -1 and text.find(')') != -1:\n",
    "        open = text.index('(')\n",
    "        close = text.index(')')\n",
    "        return text[:open] + text[close+1:]\n",
    "    \n",
    "    return(text)\n",
    "\n",
    "def getProviderName(provName):\n",
    "    \n",
    "    provName = removeBrackets(provName)\n",
    "    provName = re.sub(REGEXName, '', provName)\n",
    "    provName = provName.replace(\".\",\"\").lower().strip()\n",
    "    provName = provName.replace(\",\",\" , \").strip()\n",
    "    replaceitems = ['dr', 'md', 'do', 'rn', 'np ','lpn','mbbs']\n",
    "    provNameNoTitle = ''\n",
    "    provNames = provName.split()\n",
    "    for provNamePart in provNames:\n",
    "        if provNamePart not in replaceitems:\n",
    "            provNameNoTitle = provNameNoTitle +' ' + provNamePart\n",
    "\n",
    "    provName = provNameNoTitle\n",
    "    if provName.endswith(\",\"):\n",
    "        provName=provName[:-1]\n",
    "    if len(provName) ==0:\n",
    "        return {'firstName': None,'lastName': None}\n",
    "    return(split_name(provName))\n",
    "\n",
    "def preclean_input_text_for_find_dates(text):\n",
    "    cleaned_text = re.sub(r'[a-z]:\\s', ' ', text, flags=re.IGNORECASE)\n",
    "    cleaned_text = cleaned_text.replace(\"date/time\",\"date time\")\n",
    "    return cleaned_text\n",
    "\n",
    "def preclean_hospitalnames(hospName):\n",
    "    hospName = hospName.replace('.',' ').replace(\"'\",\"\")\n",
    "    return hospName    \n",
    "\n",
    "def dateParse(input):\n",
    "    \n",
    "    try:\n",
    "        posBracket = input.lower().find(\"(\")\n",
    "        if posBracket > -1:\n",
    "            input = input[0:(posBracket-1)]\n",
    "\n",
    "        if len(input) >= 10:\n",
    "            input = input[0:10]\n",
    "        \n",
    "        wordsinDate = input.split()\n",
    "        if len(wordsinDate) > 0:\n",
    "            input = wordsinDate[0]\n",
    "\n",
    "\n",
    "        today = date.today()\n",
    "        Year = today.year\n",
    "\n",
    "        dobparse = parser.parse(input)\n",
    "        if dobparse.year > Year:\n",
    "            dobparse = dobparse.replace(year=dobparse.year - 100)\n",
    "        dobfmt = dobparse.strftime(\"%m/%d/%Y\")\n",
    "        return(dobfmt)        \n",
    "    except Exception as ex :\n",
    "        print(ex)\n",
    "        return None\n",
    "\n",
    "def dateExtract(text):\n",
    "    extractedDate=None\n",
    "    dates = datefinder.find_dates(preclean_input_text_for_find_dates(text),source=True, strict=True,index=True)\n",
    "    if len(list(dates)) == 0:\n",
    "        date_val = re.findall(r'\\d+/\\d+/\\d+', text)   #To handle 2 digit years as datefinder is missing them\n",
    "        if len(date_val) > 0:\n",
    "            dates = datefinder.find_dates(date_val[0],source=True, strict=True,index=True)\n",
    "            for date in dates:\n",
    "                extractedDate = dateParse(date[1])\n",
    "                return(extractedDate)\n",
    "    else:\n",
    "        dates = datefinder.find_dates(preclean_input_text_for_find_dates(text),source=True, strict=True,index=True)        \n",
    "        for date in dates:\n",
    "            extractedDate = dateParse(date[1])\n",
    "            return(extractedDate)\n",
    "\n",
    "    return(extractedDate)            \n",
    "\n",
    "def translateStatetoCode(State):\n",
    "    if len(State) == 2: \n",
    "        return State\n",
    "\n",
    "    us_state_to_abbrev = {\n",
    "    \"alabama\": \"AL\",\n",
    "    \"alaska\": \"AK\",\n",
    "    \"arizona\": \"AZ\",\n",
    "    \"arkansas\": \"AR\",\n",
    "    \"california\": \"CA\",\n",
    "    \"colorado\": \"CO\",\n",
    "    \"connecticut\": \"CT\",\n",
    "    \"delaware\": \"DE\",\n",
    "    \"florida\": \"FL\",\n",
    "    \"georgia\": \"GA\",\n",
    "    \"hawaii\": \"HI\",\n",
    "    \"idaho\": \"ID\",\n",
    "    \"illinois\": \"IL\",\n",
    "    \"indiana\": \"IN\",\n",
    "    \"iowa\": \"IA\",\n",
    "    \"kansas\": \"KS\",\n",
    "    \"kentucky\": \"KY\",\n",
    "    \"louisiana\": \"LA\",\n",
    "    \"Maine\": \"ME\",\n",
    "    \"maryland\": \"MD\",\n",
    "    \"massachusetts\": \"MA\",\n",
    "    \"michigan\": \"MI\",\n",
    "    \"minnesota\": \"MN\",\n",
    "    \"mississippi\": \"MS\",\n",
    "    \"missouri\": \"MO\",\n",
    "    \"montana\": \"MT\",\n",
    "    \"nebraska\": \"NE\",\n",
    "    \"nevada\": \"NV\",\n",
    "    \"new hampshire\": \"NH\",\n",
    "    \"new jersey\": \"NJ\",\n",
    "    \"new mexico\": \"NM\",\n",
    "    #\"new york\": \"NY\",     could be city\n",
    "    \"north carolina\": \"NC\",\n",
    "    \"north dakota\": \"ND\",\n",
    "    \"ohio\": \"OH\",\n",
    "    \"oklahoma\": \"OK\",\n",
    "    \"oregon\": \"OR\",\n",
    "    \"pennsylvania\": \"PA\",\n",
    "    \"rhode island\": \"RI\",\n",
    "    \"south carolina\": \"SC\",\n",
    "    \"south dakota\": \"SD\",\n",
    "    \"tennessee\": \"TN\",\n",
    "    \"texas\": \"TX\",\n",
    "    \"utah\": \"UT\",\n",
    "    \"vermont\": \"VT\",\n",
    "    \"virginia\": \"VA\",\n",
    "    \"washington\": \"WA\",\n",
    "    \"west virginia\": \"WV\",\n",
    "    \"wisconsin\": \"WI\",\n",
    "    \"wyoming\": \"WY\",\n",
    "    \"district of columbia\": \"DC\",\n",
    "    \"american samoa\": \"AS\",\n",
    "    \"guam\": \"GU\",\n",
    "    \"northern mariana islands\": \"MP\",\n",
    "    \"puerto rico\": \"PR\",\n",
    "    \"united states minor outlying islands\": \"UM\",\n",
    "    \"u.s. virgin islands\": \"VI\"    }\n",
    "\n",
    "    citywithStateNames = {\n",
    "        \"AL city\":  \"alabama city\",\n",
    "        \"AZ city\":  \"arizona city\",\n",
    "        \"AK city\":  \"arkansas city\",\n",
    "        \"CA city\" :\t\"california city\",\n",
    "        \"CA hot springs\" :\t\"california hot springs\",\n",
    "        \"CO city\" : \"colorado city\",\n",
    "        \"CO springs\" : \"colorado springs\",\n",
    "        \"DE city\" :\t\"delaware city\",\n",
    "        \"DE water gap\" :\t\"delaware water gap\",   \n",
    "        \"ID city\" : \"idaho city\",\n",
    "        \"ID falls\" : \"idaho falls\",\n",
    "        \"ID springs\" : \"idaho springs\",\n",
    "        \"IL city\" : \"illinois city\",\n",
    "        \"IO city\" : \"iowa city\",\n",
    "        \"IO park\" : \"iowa park\",        \n",
    "        \"ks city\" :\t\"kansas city\",\n",
    "        \"md heights\" : \"maryland heights\",\n",
    "        \"md line\" : \"maryland line\",\n",
    "        \"md center\" : \"maryland center\",        \n",
    "        \"mi city\" : \"michingan city\",        \n",
    "        \"mn city\" : \"minneapolis city\", \n",
    "        \"MI city\" : \"mississippi city\",\n",
    "        \"mo city\" : \"montana city\",\n",
    "        \"ne city\" :\t\"nebraska city\"\n",
    "}\n",
    "\n",
    "    for fullState in us_state_to_abbrev:\n",
    "        State=State.lower().replace(fullState,us_state_to_abbrev[fullState])\n",
    "\n",
    "    for cityWithStatename in citywithStateNames:\n",
    "        if State.find(cityWithStatename) > -1: \n",
    "            State = State.replace(cityWithStatename,citywithStateNames[cityWithStatename])\n",
    "\n",
    "    return(State)\n",
    "    \n",
    "\n",
    "\n",
    "def PreProcessforExtractAddress(pipelineRawContent):\n",
    "\n",
    "    pipelineRawContent = translateStatetoCode(pipelineRawContent)\n",
    "    if pipelineRawContent.find(\"#\") > -1 :\n",
    "        if  (pipelineRawContent.find(\" suite \") == -1 and pipelineRawContent.find(\" ste \") ==-1):\n",
    "            pipelineRawContent = pipelineRawContent.replace(\"#\",\"ste\")\n",
    "        else:\n",
    "            pipelineRawContent = pipelineRawContent.replace(\"#\",\" \")\n",
    "\n",
    "    pipelineRawContent = pyap.parser.AddressParser(country='US')._normalize_string(pipelineRawContent)\n",
    "    pipelineRawContent = pipelineRawContent.upper().replace(\"|\",\" \").replace(\"#\",\" \").replace(\".\",\" \").replace(\",\",\" \").replace(\";\",\" \").replace(\"'\",\"\")\n",
    "    return(pipelineRawContent)\n",
    "    #return(pipelineRawContent.upper().replace(\"|\",\" \").replace(\"#\",\" \").replace(\".\",\" \").replace(\",\",\" \").replace(\";\",\" \").replace(\"'\",\"\"))\n",
    "\n",
    "\n",
    "def ExtractAddress(strAddr):\n",
    "    addresses = pyap.parse(strAddr, country='US')\n",
    "\n",
    "    if addresses:\n",
    "        return(addresses)\n",
    "    else:\n",
    "        return(None)\n",
    "\n",
    "def SplitAddress(strAddr):\n",
    "    varAddr1=\"\"\n",
    "    varState=\"\"\n",
    "    varCity=\"\"\n",
    "    varZip=\"\"\n",
    "\n",
    "    addrwords = strAddr.split()\n",
    "    if len(addrwords) > 2 and addrwords[0].isnumeric() and  addrwords[1].isnumeric() :\n",
    "        strAddr =  ' '.join(addrwords[1:])\n",
    "\n",
    "    try:\n",
    "        splitaddr = usaddress.tag(strAddr)\n",
    "    except:\n",
    "        return (varAddr1,varCity,varState,varZip)\n",
    "\n",
    "    if len(splitaddr) != 2:\n",
    "        return (varAddr1,varCity,varState,varZip)\n",
    "\n",
    "    if splitaddr[1] != 'Street Address':\n",
    "        return (varAddr1,varCity,varState,varZip)\n",
    "\n",
    "    part = splitaddr[0]\n",
    "\n",
    "    for component in part:\n",
    "        if component == 'Recipient':\n",
    "            continue\n",
    "        if component == 'StateName':\n",
    "            varState = part['StateName'].replace(',',' ').strip().upper()\n",
    "            varState=(''.join(filter(str.isalpha, varState)))\n",
    "            varState=translateStatetoCode(varState).upper()\n",
    "        elif component == 'PlaceName':\n",
    "            varCity = part['PlaceName'].replace(',',' ').strip()\n",
    "        elif component == 'ZipCode':\n",
    "            chkzip = (''.join(filter(str.isdigit, part['ZipCode'])))\n",
    "            if len(chkzip) >= 4:\n",
    "                varZip = part['ZipCode'].replace(',',' ').strip()\n",
    "                varZip = varZip[0:5]\n",
    "\n",
    "        else:\n",
    "            varAddr1 = (varAddr1+\" \"+ part[component]).strip()\n",
    "            if varAddr1.strip().endswith(\",\"):\n",
    "                varAddr1 = varAddr1[1:(len(varAddr1)-1)]\n",
    "    return (varAddr1,varCity,varState,varZip)\n",
    "\n",
    "def callGoogleMapsaddress(addrText):\n",
    "    api_key = os.getenv('GOOGLE_MAPS_API_KEY')\n",
    "    base_url = os.getenv('GOOGLE_MAPS_URL')          #\"https://maps.googleapis.com/maps/api/geocode/json\"\n",
    "    endpoint = f\"{base_url}?address={addrText}&key={api_key}\"\n",
    "    try: \n",
    "        r = requests.get(endpoint)\n",
    "        if r.status_code not in range(200, 299):\n",
    "            return None\n",
    "        results = r.json()['results'][0]\n",
    "        address_components = results['address_components']\n",
    "        foundHealth = False\n",
    "        for address_component in address_components:\n",
    "            for type in address_component['types']:\n",
    "                if type.lower() == \"health\":\n",
    "                    foundHealth = True\n",
    "                    break\n",
    "        \n",
    "        if 'types' in results:\n",
    "            for placeType in results['types']:\n",
    "                if placeType.lower() == \"health\":\n",
    "                    foundHealth = True\n",
    "                    break\n",
    "\n",
    "        if not foundHealth:\n",
    "            return (None,None,None,None,None,None,None,None)\n",
    "\n",
    "        for address_component in address_components:\n",
    "            for type in address_component['types']:\n",
    "                if type == \"street_number\":\n",
    "                    street_number  = address_component['long_name'].lower()\n",
    "                if type == \"route\":\n",
    "                    route_short_name = address_component['short_name'].lower()\n",
    "                    route_long_name  = address_component['long_name'].lower()\n",
    "                if type == \"locality\":\n",
    "                    locality_short_name = address_component['short_name'].lower()\n",
    "                    locality_long_name = address_component['long_name'].lower()\n",
    "                if type == \"administrative_area_level_1\":\n",
    "                    administrative_area_level_1_short_name = address_component['short_name'].lower()\n",
    "                    administrative_area_level_1_long_name = address_component['long_name'].lower()\n",
    "                if type == \"postal_code\":\n",
    "                    postal_code_short_name = address_component['short_name'].lower()\n",
    "    except:\n",
    "        return (None,None,None,None,None,None,None,None)\n",
    "        \n",
    "    return(street_number,route_short_name,route_long_name,locality_short_name,locality_long_name,administrative_area_level_1_short_name,administrative_area_level_1_long_name,postal_code_short_name)\n",
    "\n",
    "\n",
    "def chkTokenPresent(pipelineRawContent,wordBeforecount,wordAftercount,fieldKeys,tokenLabel,tokenValue,row,offset=0):\n",
    "\n",
    "    if row is not None:\n",
    "        tokenPos = row['value']['spans'][0]['offset']\n",
    "        tokenLen = row['value']['spans'][0]['length']\n",
    "    else:\n",
    "        tokenPos = (pipelineRawContent[offset:].find(tokenValue))+offset\n",
    "        tokenLen = len(tokenValue)\n",
    "    \n",
    "    labels = fieldKeys[tokenLabel]\n",
    "    if tokenPos > -1 :\n",
    "        leftText = pipelineRawContent[0:tokenPos]\n",
    "        rightText = pipelineRawContent[tokenPos+tokenLen: ]\n",
    "        leftWords = leftText.split()\n",
    "        wordBeforecount=wordBeforecount*-1\n",
    "        leftSearchText = ' '.join(leftWords[int(wordBeforecount):])\n",
    "        for label in labels:\n",
    "            if leftSearchText.find(label) > -1: \n",
    "                return(label)        \n",
    "\n",
    "        rightWords = rightText.split()\n",
    "        rightSearchText = ' '.join(rightWords[:int(wordAftercount)])\n",
    "        for label in labels:\n",
    "            if rightSearchText.find(label) > -1: \n",
    "                return(label) \n",
    "            \n",
    "    return None\n",
    "\n",
    "def reformatCustomerID(inputId):\n",
    "    outputId = re.sub(REGEXAlphaNumeric, '', inputId)\n",
    "    return(outputId)\n",
    "\n",
    "def reformatICD(icd):\n",
    "    if icd.find('1') == 0 and icd.find('.') == 3:\n",
    "        icd='i' + icd[1:]\n",
    "    if icd.find('0') == 0 and icd.find('.') == 3:\n",
    "        icd='o' + icd[1:]\n",
    " \n",
    "\n",
    "    if len(icd) > 3 and icd.find('.') == -1:\n",
    "        icd=icd[0:3] + '.' + icd[3:]\n",
    "    return(icd)\n",
    "\n",
    "def getICDCodes(pipelineRawContent): \n",
    "    icdRegexMatchReturn = []\n",
    "    for match in re.finditer(REGEXICDCode, pipelineRawContent):\n",
    "        reformattedICDCode = reformatICD(match.group())\n",
    "        icdRegexMatchReturn.append([match.group(),reformattedICDCode,match.start()])\n",
    "        pipelineRawContent = pipelineRawContent.replace(match.group(),reformattedICDCode)        \n",
    "  \n",
    "    return(icdRegexMatchReturn,pipelineRawContent)\n",
    "\n",
    "def getPipeLineOCRRawContent(pipelineContext):\n",
    "    pipelineContent=''   \n",
    "    if (pipelineContext.get('OCRStep') is None):\n",
    "        return(pipelineContent)\n",
    "\n",
    "    pipelineExtractionReadResults = pipelineContext['OCRStep']['Result'][0]['analyzeResult']['readResults']\n",
    "    for pipelineExtractionReadResult in pipelineExtractionReadResults:\n",
    "        pipelineExtractionLines = pipelineExtractionReadResult['lines']\n",
    "        for pipelineExtractionLine in pipelineExtractionLines:\n",
    "            pipelineContent=pipelineContent + pipelineExtractionLine['text'] + ' '\n",
    "    return(pipelineContent.replace(\"#\",\" \").replace(\":\",\" \").replace(\";\",\" \").replace(\"\\n\",\" \").lower())\n",
    "    #return(pipelineContent.replace(\":\",\" \").replace(\";\",\" \").replace(\"\\n\",\" \").lower())\n",
    "\n",
    "def getPipeLineRawContent(pipelineContext):\n",
    "    \n",
    "    pipelineExtractionStepResults = pipelineContext['ExtractionStep']['Result']\n",
    "    for pipelineExtractionStepResult in pipelineExtractionStepResults:\n",
    "        pipelineExtractionStepResults = pipelineExtractionStepResult['Result']\n",
    "        for pipelineExtractionStepResult in pipelineExtractionStepResults:\n",
    "\n",
    "            if pipelineExtractionStepResult['analyzeResult']['modelId'] == 'prebuilt-document': \n",
    "                pipelineContent = pipelineExtractionStepResult['analyzeResult']['content'] \n",
    "                #return(pipelineContent.replace(\"#\",\"\").replace(\":\",\" \").replace(\";\",\" \").replace(\"\\n\",\" \").lower())\n",
    "                return(pipelineContent.replace(\":\",\" \").replace(\";\",\" \").replace(\"\\n\",\" \").lower())\n",
    "\n",
    "def getPipeLineRawContentFirst4Pages(pipelineContext):\n",
    "    pipelineContent=''\n",
    "    pipelineExtractionStepResults = pipelineContext['ExtractionStep']['Result']\n",
    "    for pipelineExtractionStepResult in pipelineExtractionStepResults:\n",
    "        pipelineExtractionStepResults = pipelineExtractionStepResult['Result']\n",
    "        for pipelineExtractionStepResult in pipelineExtractionStepResults:\n",
    "            \n",
    "            if pipelineExtractionStepResult['analyzeResult']['modelId'] == 'prebuilt-document': \n",
    "                pipelineContentpages = pipelineExtractionStepResult['analyzeResult']['pages'] \n",
    "                for pipelineContentpage in pipelineContentpages:\n",
    "                    if pipelineContentpage['pageNumber'] < 5:\n",
    "                        pipelineContentLines = pipelineContentpage['lines']\n",
    "                        for pipelineContentLine in pipelineContentLines:\n",
    "                            pipelineContent=pipelineContent+pipelineContentLine['content']+ ' '\n",
    "                    #return(pipelineContent.replace(\"#\",\"\").replace(\":\",\" \").replace(\";\",\" \").replace(\"\\n\",\" \").lower())\n",
    "    \n",
    "    return(pipelineContent.replace(\":\",\" \").replace(\";\",\" \").replace(\"\\n\",\" \").lower())\n",
    "\n",
    "def getPipelinePreBuiltkeyValuePairs(pipelineContext,nlp,fieldKeys):\n",
    "\n",
    "    pipelinePreBuiltkeyValuePairs=[]\n",
    "    pipelineExtractionStepResults = pipelineContext['ExtractionStep']['Result']\n",
    "    for pipelineExtractionStepResult in pipelineExtractionStepResults:\n",
    "        pipelineExtractionStepResults = pipelineExtractionStepResult['Result']\n",
    "        for pipelineExtractionStepResult in pipelineExtractionStepResults:\n",
    "            if pipelineExtractionStepResult['analyzeResult']['modelId'] != 'prebuilt-document': \n",
    "                continue\n",
    "            PreBuiltkeyValuePairs = pipelineExtractionStepResult['analyzeResult']['keyValuePairs']\n",
    "\n",
    "            for pipelinePreBuiltkeyValuePair in PreBuiltkeyValuePairs:\n",
    "\n",
    "                if 'value'  not in pipelinePreBuiltkeyValuePair or pipelinePreBuiltkeyValuePair['value']['content'] is None or pipelinePreBuiltkeyValuePair['value']['content'] == \"\" or len(pipelinePreBuiltkeyValuePair['value']['content']) < 3:\n",
    "                    continue\n",
    "\n",
    "                if pipelinePreBuiltkeyValuePair['value']['content'] in fieldKeys['excludeGeneralWords']:\n",
    "                    continue\n",
    "\n",
    "                if 'confidence' in pipelinePreBuiltkeyValuePair and pipelinePreBuiltkeyValuePair['confidence']  < 0.35:\n",
    "                    continue\n",
    "            \n",
    "                if (int(pipelinePreBuiltkeyValuePair['value']['boundingRegions'][0]['pageNumber']) < 5): \n",
    "                    #pipelinePreBuiltkeyValuePair['value']['content']= pipelinePreBuiltkeyValuePair['value']['content'].replace(\"#\",\"\").replace(\":\",\" \").replace(\";\",\" \").replace(\"\\n\",\" \").lower().strip()\n",
    "                    #pipelinePreBuiltkeyValuePair['key']['content']= pipelinePreBuiltkeyValuePair['key']['content'].replace(\"#\",\"\").replace(\":\",\" \").replace(\";\",\" \").replace(\"\\n\",\" \").lower().strip()\n",
    "                    pipelinePreBuiltkeyValuePair['Name']= pipelinePreBuiltkeyValuePair['key']['content'].replace(\"#\",\" \").replace(\":\",\" \").replace(\";\",\" \").replace(\"\\n\",\" \").lower().strip()\n",
    "                    pipelinePreBuiltkeyValuePair['Value']= pipelinePreBuiltkeyValuePair['value']['content'].replace(\"#\",\" \").replace(\":\",\" \").replace(\";\",\" \").replace(\"\\n\",\" \").lower().strip()\n",
    "\n",
    "                    pipelinePreBuiltkeyValuePairs.append(pipelinePreBuiltkeyValuePair)\n",
    "\n",
    "\n",
    "    return(pipelinePreBuiltkeyValuePairs)\n",
    "\n",
    "def getPipelineCustomkeyValuePairs(pipelineContext,fieldKeys):\n",
    "    PipelineCustomKeyValuePairs=[]\n",
    "\n",
    "    PipelineExtractedFields = pipelineContext['ExtractedFields']\n",
    "    for pipelineExtractedField in PipelineExtractedFields:\n",
    "        \n",
    "        if str(pipelineExtractedField['CloudService']).find('2827-model') == -1 :  ##2827-model-using-templates-v1\n",
    "            continue\n",
    "\n",
    "        if 'Page' in pipelineExtractedField and int(pipelineExtractedField['Page']) > 5:\n",
    "            continue\n",
    "\n",
    "        if 'Value'  not in pipelineExtractedField or pipelineExtractedField['Value'] is None or pipelineExtractedField['Value'] == \"\" or len(pipelineExtractedField['Value']) < 3:\n",
    "            continue\n",
    "\n",
    "        if 'Confidence' in pipelineExtractedField and pipelineExtractedField['Confidence']  < 0.60:\n",
    "            continue\n",
    "\n",
    "        if pipelineExtractedField['Value'] in fieldKeys['excludeGeneralWords']:\n",
    "            continue\n",
    "\n",
    "        PipelineCustomKeyValuePairs.append(pipelineExtractedField)\n",
    "\n",
    "    return(PipelineCustomKeyValuePairs)\n",
    "\n",
    "def get_name_addr(mapped_name):\n",
    "    \n",
    "    name = \"N/A\"\n",
    "    addr = \"N/A\"\n",
    "\n",
    "    try:\n",
    "        first_ind = re.search(r'\\d',mapped_name).start()\n",
    "        name = mapped_name[:first_ind].strip().upper()\n",
    "        mapped_name = mapped_name[first_ind:]\n",
    "        mapped_name = mapped_name.replace(r'\\n', ' ').replace(r'\\r', ' ').replace(r'\\r\\n', ' ')\n",
    "       \n",
    "        addr = re.sub(r'[^\\x00-\\x7f]', \" \", mapped_name).strip().upper()\n",
    "\n",
    "    except:\n",
    "        return name, addr\n",
    "    return name, addr\n",
    "    \n",
    "def get_state_details(state_sheets,tax_id, state):\n",
    "\n",
    "    if state == 'CA' or state == 'FL' or state == 'PA':\n",
    "        state_codes = [i for i in state_sheets.keys() if state in i]\n",
    "        for stat in state_codes:\n",
    "            df = state_sheets[stat]\n",
    "            df = df.loc[df['TAX ID NUMBER'] == tax_id]\n",
    "            if len(df) > 0:\n",
    "                name, addr = get_name_addr(df)\n",
    "                return name, addr, df.iloc[0]['TAX ID NUMBER'],df.iloc[0]['EMR AVAILABLE']\n",
    "        return \"N/A\", \"N/A\", \"N/A\", \"N/A\"\n",
    "    try:\n",
    "        df = state_sheets[state]\n",
    "        df = df.loc[df['TAX ID NUMBER'] == tax_id]\n",
    "        if len(df) > 0:\n",
    "            name, addr = get_name_addr(df)\n",
    "            a = df.iloc[0]\n",
    "            a = a.to_dict()\n",
    "            del df\n",
    "            return name, addr, a['TAX ID NUMBER'], a['EMR AVAILABLE']\n",
    "            #return name, addr, df.iloc[0]['TAX ID NUMBER'], df.iloc[0]['EMR AVAILABLE']\n",
    "    except: \n",
    "        return \"N/A\", \"N/A\", \"N/A\", \"N/A\"\n",
    "    return \"N/A\", \"N/A\", \"N/A\", \"N/A\"\n",
    "\n",
    "def ipcmReFormat(decrypted,fieldKeys):\n",
    "#columns - #  PROV_ID ,PROV_NM,PROV_ALT_NM,PROV_TAX_ID,EMR AVAILABLE FACILITY NAME,_merge,TAX ID NUMBER\n",
    "\n",
    "    decryptedXLS = pd.ExcelFile(decrypted)\n",
    "    df_provider = pd.read_excel(decryptedXLS, sheet_name='Provider Alias')\n",
    "    df_provider.drop(columns=['PROV_ID'])\n",
    "    df_provider['PROV_TAX_ID']= df_provider['PROV_TAX_ID'].astype(str)\n",
    "    df_provider['PROV_TAX_ID']= df_provider['PROV_TAX_ID'].str.zfill(9)\n",
    "\n",
    "    #df_provider[pd.to_numeric(df_provider['NATL_PROV_ID'], errors='coerce').notnull()].astype(int)\n",
    "    df_provider['NATL_PROV_ID'] = df_provider['NATL_PROV_ID'].astype('Int64').astype(str)\n",
    " \n",
    "    ##################### Load all sheets\n",
    "    state_df = pd.DataFrame()\n",
    "    for sheet in decryptedXLS.sheet_names:\n",
    "        state = sheet\n",
    "        if sheet in fieldKeys['excludeIPCMGRidTabs']:\n",
    "            continue\n",
    "        if sheet  == 'Provider Alias':\n",
    "            continue\n",
    "        \n",
    "        df = pd.read_excel(decryptedXLS, sheet_name=sheet, header=1)\n",
    "        try:\n",
    "            ind = df[df[df.columns[0]]=='FACILITY NAME'].index.values\n",
    "        except:\n",
    "            logging.info('FACE SHEET 2827 : ipcmReFormat unknown sheet name  - %s',str(sheet) ) \n",
    "            continue\n",
    "\n",
    "        df = df[ind[0]:]\n",
    "        df.columns = df.iloc[0]\n",
    "        #df = df[pd.to_numeric(df['TAX ID NUMBER'], errors='coerce').notnull()]\n",
    "        df['TAX ID NUMBER']= df['TAX ID NUMBER'].astype(str)\n",
    "        df = df[['TAX ID NUMBER', 'EMR AVAILABLE', 'FACILITY NAME']]\n",
    "        df = df.reset_index(drop=True)\n",
    "        if len(df) > 0:\n",
    "            df[['FACILITY NAME', 'ADDRESS']] = df.apply(\n",
    "                lambda row: get_name_addr(row['FACILITY NAME']), axis=1, result_type='expand')\n",
    "        else:\n",
    "            continue\n",
    "        if sheet.upper() == 'PUERTO RICO' :\n",
    "            state = 'PR'\n",
    "        if '-' in sheet:\n",
    "            state = sheet.split('-')[0]\n",
    "            state = state.strip()\n",
    "            \n",
    "        df = df.assign(STE_CD = state)\n",
    "        df = df.T.drop_duplicates().T\n",
    "        state_df = pd.concat([state_df, df])\n",
    "\n",
    "    state_df = state_df.reset_index(drop=True)\n",
    "    state_df.rename(columns={'TAX ID NUMBER': 'PROV_TAX_ID'}, inplace=True)\n",
    "    state_df['PROV_TAX_ID']= state_df['PROV_TAX_ID'].astype(str)    \n",
    "    state_df['PROV_TAX_ID']= state_df['PROV_TAX_ID'].str.zfill(9)\n",
    "\n",
    "    combined_df = pd.merge(df_provider, state_df, on=['PROV_TAX_ID', 'STE_CD'], how='outer', indicator=True)\n",
    "    combined_df= combined_df.drop_duplicates()\n",
    "\n",
    "    combined_df['PROV_TAX_ID']= combined_df['PROV_TAX_ID'].astype(str)\n",
    "    combined_df['PROV_TAX_ID']= combined_df['PROV_TAX_ID'].str.strip()\n",
    "\n",
    "    combined_df['PROV_ALT_NM']= combined_df['PROV_ALT_NM'].astype(str)\n",
    "    combined_df['PROV_ALT_NM']= preclean_hospitalnames(combined_df['PROV_ALT_NM'].str.strip())\n",
    "    \n",
    "\n",
    "    combined_df['PROV_NM']= combined_df['PROV_NM'].astype(str)\n",
    "    combined_df['PROV_NM']= preclean_hospitalnames(combined_df['PROV_NM'].str.strip())\n",
    "\n",
    "    combined_df['EMR AVAILABLE']= combined_df['EMR AVAILABLE'].astype(str)\n",
    "    combined_df['EMR AVAILABLE']= combined_df['EMR AVAILABLE'].str.strip()\n",
    "\n",
    "    combined_df['FACILITY NAME']= combined_df['FACILITY NAME'].astype(str)\n",
    "    combined_df['FACILITY NAME']= preclean_hospitalnames(combined_df['FACILITY NAME'].str.strip())\n",
    "    \n",
    "\n",
    "    combined_df = combined_df.replace('nan', np.nan)\n",
    "\n",
    "    del state_df\n",
    "    del df_provider\n",
    "    return (combined_df)\n",
    "\n",
    "def ipcmRefresh(ipcmZipFile,fieldKeys):\n",
    "\n",
    "    try:\n",
    "        auth_user = os.getenv('OSCP_NP_USER')\n",
    "        auth_password = os.getenv('OSCP_NP_PASS')     \n",
    "        ipcmGridLocation = os.getenv('IPCM-GRID-LOCATION')\n",
    "\n",
    "        IPCM_GRID_PASSWORD = os.getenv('IPCM-GRID-PASSWORD')\n",
    "        \n",
    "        ipcmGridXls = \"IPCM Assignment Grid.xlsx\"    \n",
    "        user='internal'+ '\\\\' + auth_user\n",
    "        #resp = requests.get(ipcmGridLocation,auth=HttpNtlmAuth(user,auth_password),verify=False)\n",
    "        resp = requests.get(ipcmGridLocation,auth=HttpNtlmAuth(user,auth_password),verify='/usr/local/share/ca-certificates/ca-bundle.crt')\n",
    "\n",
    "    #   Copy zip file from sharepoint to NAS share location     \n",
    "        logging.info('FACE SHEET 2827 : ipcmRefresh saving zip file complete')\n",
    "        with smbclient.open_file(ipcmZipFile, mode=\"wb\",username=auth_user, password=auth_password,share_access='w') as ipcmZipFD:\n",
    "            ipcmZipFD.write(resp.content)\n",
    "\n",
    "        dir_path = os.path.dirname(os.path.realpath(__file__))\n",
    "\n",
    "        output_folder = os.path.join(dir_path, \"ipcm\")\n",
    "        ipcmxls_full_path = os.path.join(output_folder,ipcmGridXls)\n",
    "        try:\n",
    "            os.makedirs(output_folder)\n",
    "            logging.info('FACE SHEET 2827 : ipcmRefresh unzipping  directory %s created successfully',output_folder)\n",
    "        except:\n",
    "            logging.info('FACE SHEET 2827 : ipcmRefresh unzipping  directory %s unsuccesfull, continuing.',output_folder)            \n",
    "            pass\n",
    "\n",
    "    #   Save Unzipped xls file in local  default path\n",
    "        with smbclient.open_file(ipcmZipFile, mode=\"rb\",username=auth_user, password=auth_password,share_access='r') as ipcmZipFD:\n",
    "            with ZipFile(ipcmZipFD,'r') as zip:\n",
    "                zip.extract(ipcmGridXls,output_folder)\n",
    "                logging.info('FACE SHEET 2827 : ipcmRefresh unzipping  zip file complete')\n",
    "\n",
    "    #   Decrypt XLSX with password\n",
    "        decrypted = io.BytesIO()\n",
    "\n",
    "    #   Read zip file from local path and decrypt into memory\n",
    "\n",
    "        with open(ipcmxls_full_path, \"rb\") as f:\n",
    "            ipcmXlsfileEncrypted = msoffcrypto.OfficeFile(f)\n",
    "            ipcmXlsfileEncrypted.load_key(password=IPCM_GRID_PASSWORD)  # Use password\n",
    "            ipcmXlsfileEncrypted.decrypt(decrypted)\n",
    "            df_provider = ipcmReFormat(decrypted,fieldKeys)\n",
    "            del decrypted\n",
    "            logging.info('FACE SHEET 2827 : ipcmRefresh decrypt of xls file complete')\n",
    "        \n",
    "            try:\n",
    "                # Deletes all temp file\n",
    "                os.remove(ipcmxls_full_path) \n",
    "                logging.info('FACE SHEET 2827 : ipcmRefresh file %s removed successfully',ipcmxls_full_path)\n",
    "\n",
    "                os.rmdir(output_folder)\n",
    "                logging.info('FACE SHEET 2827 : ipcmRefresh directory %s removed successfully',output_folder)\n",
    "\n",
    "            except:\n",
    "                logging.error('FACE SHEET 2827 : ipcmRefresh directory %s removal Unexpected error - %s',output_folder,  sys.exc_info()[0])\n",
    "\n",
    "\n",
    "            return(df_provider)\n",
    "\n",
    "\n",
    "    except Exception as ex:\n",
    "        logging.info('FACE SHEET 2827 : ipcm grid refresh failed with : %s ', str(ex))\n",
    "        exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "        logging.error(traceback.print_exc())\n",
    "        return(None)\n",
    "\n",
    "def readIPCM(ipcmZip,fieldKeys):\n",
    "    auth_user = os.getenv('OSCP_NP_USER')\n",
    "    auth_password = os.getenv('OSCP_NP_PASS')\n",
    "    ipcmZipPickle = ipcmZip+\".pickled\"\n",
    "    try:\n",
    "        # if file in local path - check when last refreshed - if more than specified days, refresh local file\n",
    "        today  = date.today()\n",
    "        difference=100\n",
    "        try:\n",
    "            fileStat = smbclient.stat(ipcmZipPickle,username=auth_user, password=auth_password)\n",
    "            dt = date.fromtimestamp(fileStat.st_chgtime)\n",
    "            difference = abs(today-dt).days\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        if difference >= 1:\n",
    "            logging.info('FACE SHEET 2827 : ipcm grid needs refresh for  : %s ', str(today))\n",
    "            df_provider = ipcmRefresh(ipcmZip,fieldKeys)\n",
    "            logging.info('FACE SHEET 2827 : ipcm grid refresh complete ')\n",
    "\n",
    "            if df_provider is not None:\n",
    "                \n",
    "                with smbclient.open_file(ipcmZipPickle, mode=\"wb\",username=auth_user, password=auth_password,share_access=\"w\") as ipcmPickleFD:\n",
    "                    df_provider.to_pickle(ipcmPickleFD)\n",
    "                    logging.info('FACE SHEET 2827 : ipcmRefresh completing saving of pickle format')\n",
    "                    del df_provider\n",
    "                    gc.collect()\n",
    "\n",
    "        with smbclient.open_file(ipcmZipPickle, mode=\"rb\",username=auth_user, password=auth_password,share_access=\"r\") as ipcmFD:\n",
    "            df= pd.read_pickle(ipcmFD)  #converters={'TAX ID NUMBER':str,'PROV_ALT_NM':str,'EMR AVAILALBLE':str,'FACILITY NAME':str,'NPI':str})\n",
    "            logging.info('FACE SHEET 2827 : ipcmRefresh reading of pickle format complete') \n",
    "            return(df)\n",
    "\n",
    "    except Exception as ex:\n",
    "        logging.ERROR('FACE SHEET 2827 : ipcm grid readIPCM failed   : %s ', str(ex))\n",
    "        return(None)\n",
    "\n",
    "def readIPCMCPF(ipcmCPF,fieldKeys):\n",
    "    auth_user = os.getenv('OSCP_NP_USER')\n",
    "    auth_password = os.getenv('OSCP_NP_PASS')\n",
    "    try:\n",
    "        try:\n",
    "            fileStat = smbclient.stat(ipcmCPF,username=auth_user, password=auth_password)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "        with smbclient.open_file(ipcmCPF, mode=\"rb\",username=auth_user, password=auth_password,share_access=\"r\") as ipcmFD:\n",
    "            df= pd.read_pickle(ipcmFD)  #converters={'TAX ID NUMBER':str,'PROV_ALT_NM':str,'EMR AVAILALBLE':str,'FACILITY NAME':str,'NPI':str})\n",
    "            logging.info('FACE SHEET 2827 : ipcmRefresh reading of pickle format complete') \n",
    "            return(df)\n",
    "\n",
    "    except Exception as ex:\n",
    "        logging.ERROR('FACE SHEET 2827 : ipcm grid readIPCMCPF failed   : %s ', str(ex))\n",
    "        return(None)\n",
    "\n",
    "\n",
    "def getAuthorizationContactName(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineRawContentdoc,nlp,pipelineOCRRawContent,pipelineCustomkeyValuePairs):\n",
    "    authContactName = None\n",
    "    for fieldKey in fieldKeys['authorizationContactName']:\n",
    "        for extractedField in pipelinePreBuiltkeyValuePairs:\n",
    "            keyName = extractedField['Name']\n",
    "            if (keyName.find(fieldKey) > -1 ):\n",
    "                authContactName = extractedField['Value']\n",
    "                if authContactName.find('selected') > -1:\n",
    "                    continue\n",
    "                if authContactName.find(briaApiJson['customerDetails']['lastName']) > -1 or authContactName.find(briaApiJson['customerDetails']['firstName']) > -1:\n",
    "                    continue\n",
    "                \n",
    "                authContactNameChk = re.sub(REGEXName, '', authContactName)\n",
    "                if len(authContactNameChk) < 5:\n",
    "                    continue\n",
    "                if chkTokenPresent(pipelineRawContent,10,5,fieldKeys,'excludeContactName',authContactName,extractedField) is not None:\n",
    "                    continue                    \n",
    "\n",
    "                if chkTokenPresent(pipelineOCRRawContent,10,5,fieldKeys,'excludeContactName',authContactName,extractedField) is not None:\n",
    "                    continue                    \n",
    "\n",
    "                if (authContactName not in fieldKeys['excludeContactNameValue']):\n",
    "                    briaApiJson['generalInformation']['authorizationContactName'] = authContactName\n",
    "                    return\n",
    "\n",
    "\n",
    "    if  briaApiJson['generalInformation']['authorizationContactName'] == \"\":                \n",
    "        for pipelineCustomkeyValuePair in pipelineCustomkeyValuePairs:\n",
    "            if pipelineCustomkeyValuePair['Name'] == 'authorizationContactName':\n",
    "                if pipelineCustomkeyValuePair['Name'] not in fieldKeys['excludeContactNameValue']:\n",
    "                    authContactNameChk = re.sub(REGEXName, '', pipelineCustomkeyValuePair['Value'])\n",
    "                    if len(authContactNameChk) > 5 and (authContactNameChk not in fieldKeys['excludeContactNameValue']): \n",
    "                        briaApiJson['generalInformation']['authorizationContactName'] = authContactNameChk\n",
    "                        return\n",
    "\n",
    "    if  briaApiJson['generalInformation']['authorizationContactName'] == \"\":                \n",
    "        for token in pipelineRawContentdoc:\n",
    "            if token.ent_type_ == \"PERSON\" or token.ent_type_ == \"ORG\" and (token.text not in fieldKeys['excludeContactName']) :\n",
    "                if chkTokenPresent(pipelineRawContent,5,3,fieldKeys,'authorizationContactName',token.text,None) is not None:\n",
    "                    if chkTokenPresent(pipelineRawContent,10,5,fieldKeys,'excludeContactName',token.text,None) is None:\n",
    "                        authContactNameChk = re.sub(REGEXName, '', token.text)\n",
    "                        if len(authContactNameChk) > 5 and (authContactNameChk not in fieldKeys['excludeContactNameValue']): \n",
    "                            briaApiJson['generalInformation']['authorizationContactName'] = authContactNameChk\n",
    "                            return\n",
    "\n",
    "def getFaxNumber(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineOCRRawContent,pipelineCustomkeyValuePairs):\n",
    "    \n",
    "    for match in re.finditer(REGEXPhone, pipelineRawContent):\n",
    "\n",
    "        if chkTokenPresent(pipelineRawContent,20,3,fieldKeys,'excludeContactPhone',match.group(),None, match.start()) is not None: \n",
    "            continue                   \n",
    "\n",
    "        phoneNoRaw = formatPhone(str(match.group()))            \n",
    "\n",
    "        if phoneNoRaw is None  or phoneNoRaw in fieldKeys['excludeCignaphoneno']:\n",
    "            continue \n",
    "\n",
    "        if chkTokenPresent(pipelineRawContent,7,3,fieldKeys,'faxNumber',match.group(),None,match.start()) is not None:\n",
    "            if chkTokenPresent(pipelineRawContent,2,0,fieldKeys,'fax',match.group(),None,match.start()) is not None:\n",
    "                if chkTokenPresent(pipelineRawContent,0,2,fieldKeys,'phone',match.group(),None,match.start()) is None:\n",
    "                    briaApiJson['generalInformation']['faxNumber'] = phoneNoRaw\n",
    "                    return\n",
    "            if chkTokenPresent(pipelineRawContent,0,2,fieldKeys,'fax',match.group(),None,match.start()) is not None:\n",
    "                if chkTokenPresent(pipelineRawContent,2,0,fieldKeys,'phone',match.group(),None,match.start()) is None:\n",
    "                    briaApiJson['generalInformation']['faxNumber'] = phoneNoRaw\n",
    "                    return\n",
    "\n",
    "\n",
    "    for match in re.finditer(REGEXPhone2, pipelineRawContent):\n",
    "        if chkTokenPresent(pipelineRawContent,20,3,fieldKeys,'excludeContactPhone',match.group(),None, match.start()) is not None: \n",
    "            continue                   \n",
    "\n",
    "        phoneNoRaw = formatPhone(str(match.group()))            \n",
    "\n",
    "        if phoneNoRaw is None  or phoneNoRaw in fieldKeys['excludeCignaphoneno']:\n",
    "            continue \n",
    "        \n",
    "        if chkTokenPresent(pipelineRawContent,7,3,fieldKeys,'faxNumber',match.group(),None,match.start()) is not None:\n",
    "            if chkTokenPresent(pipelineRawContent,2,0,fieldKeys,'fax',match.group(),None,match.start()) is not None:\n",
    "                if chkTokenPresent(pipelineRawContent,0,2,fieldKeys,'phone',match.group(),None,match.start()) is None:\n",
    "                    briaApiJson['generalInformation']['faxNumber'] = phoneNoRaw\n",
    "                    return\n",
    "            if chkTokenPresent(pipelineRawContent,0,2,fieldKeys,'fax',match.group(),None,match.start()) is not None:\n",
    "                if chkTokenPresent(pipelineRawContent,2,0,fieldKeys,'phone',match.group(),None,match.start()) is None:\n",
    "                    briaApiJson['generalInformation']['faxNumber'] = phoneNoRaw\n",
    "                    return\n",
    "\n",
    "    \n",
    "    if briaApiJson['generalInformation']['faxNumber'] == \"\":\n",
    "        for pipelineCustomkeyValuePair in pipelineCustomkeyValuePairs:\n",
    "            if pipelineCustomkeyValuePair['Name'] == 'contactfaxNumber':\n",
    "                phoneNoRaw = formatPhone(pipelineCustomkeyValuePair['Value'])\n",
    "                if phoneNoRaw is not None  and phoneNoRaw not in fieldKeys['excludeCignaphoneno']:\n",
    "                    briaApiJson['generalInformation']['faxNumber'] = phoneNoRaw\n",
    "                    return\n",
    "\n",
    "def getContactPhoneNumber(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineOCRRawContent,pipelineCustomkeyValuePairs):\n",
    "\n",
    "    for match in re.finditer(REGEXPhone, pipelineRawContent):\n",
    "        if chkTokenPresent(pipelineRawContent,20,3,fieldKeys,'excludeContactPhone',match.group(),None, match.start()) is not None: \n",
    "            continue                   \n",
    "\n",
    "        phoneNoRaw = formatPhone(str(match.group()))            \n",
    "\n",
    "        if phoneNoRaw is None  or phoneNoRaw in fieldKeys['excludeCignaphoneno'] or phoneNoRaw == briaApiJson['generalInformation']['faxNumber']:\n",
    "            continue \n",
    "\n",
    "        if chkTokenPresent(pipelineRawContent,7,3,fieldKeys,'phoneNumber',match.group(),None,match.start()) is not None:\n",
    "            if chkTokenPresent(pipelineRawContent,2,0,fieldKeys,'phone',match.group(),None,match.start()) is not None:\n",
    "                if chkTokenPresent(pipelineRawContent,0,2,fieldKeys,'fax',match.group(),None,match.start()) is None:\n",
    "                    briaApiJson['generalInformation']['phoneNumber'] = phoneNoRaw\n",
    "                    return\n",
    "            if chkTokenPresent(pipelineRawContent,0,2,fieldKeys,'phone',match.group(),None,match.start()) is not None:\n",
    "                if chkTokenPresent(pipelineRawContent,2,0,fieldKeys,'fax',match.group(),None,match.start()) is None:\n",
    "                    briaApiJson['generalInformation']['phoneNumber'] = phoneNoRaw\n",
    "                    return\n",
    "\n",
    "            if chkTokenPresent(pipelineRawContent,5,5,fieldKeys,'fax',match.group(),None,match.start()) is None:\n",
    "                briaApiJson['generalInformation']['phoneNumber'] = phoneNoRaw\n",
    "                return                    \n",
    "\n",
    "\n",
    "    for match in re.finditer(REGEXPhone2, pipelineRawContent):\n",
    "        if chkTokenPresent(pipelineRawContent,20,3,fieldKeys,'excludeContactPhone',match.group(),None, match.start()) is not None: \n",
    "            continue                   \n",
    "\n",
    "        phoneNoRaw = formatPhone(str(match.group()))            \n",
    "\n",
    "        if phoneNoRaw is None  or phoneNoRaw in fieldKeys['excludeCignaphoneno'] or phoneNoRaw == briaApiJson['generalInformation']['faxNumber']:\n",
    "            continue \n",
    "\n",
    "        if chkTokenPresent(pipelineRawContent,7,3,fieldKeys,'phoneNumber',match.group(),None,match.start()) is not None:\n",
    "            if chkTokenPresent(pipelineRawContent,2,0,fieldKeys,'phone',match.group(),None,match.start()) is not None:\n",
    "                if chkTokenPresent(pipelineRawContent,0,2,fieldKeys,'fax',match.group(),None,match.start()) is None:\n",
    "                    briaApiJson['generalInformation']['phoneNumber'] = phoneNoRaw\n",
    "                    return\n",
    "            if chkTokenPresent(pipelineRawContent,0,2,fieldKeys,'phone',match.group(),None,match.start()) is not None:\n",
    "                if chkTokenPresent(pipelineRawContent,2,0,fieldKeys,'fax',match.group(),None,match.start()) is None:\n",
    "                    briaApiJson['generalInformation']['phoneNumber'] = phoneNoRaw\n",
    "                    return\n",
    "\n",
    "    if briaApiJson['generalInformation']['phoneNumber'] == \"\":                \n",
    "        for pipelineCustomkeyValuePair in pipelineCustomkeyValuePairs:\n",
    "            if pipelineCustomkeyValuePair['Name'] == 'contactphoneNumber':\n",
    "                phoneNoRaw = formatPhone(pipelineCustomkeyValuePair['Value'])\n",
    "                if phoneNoRaw is not None and phoneNoRaw not in fieldKeys['excludeCignaphoneno']:\n",
    "                    briaApiJson['generalInformation']['phoneNumber'] = phoneNoRaw\n",
    "                    return\n",
    "\n",
    "\n",
    "def getCustomerId(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineRawContentdoc,pipelineCustomJson,pipelineOCRRawContent,pipelineCustomkeyValuePairs):\n",
    "    \"\"\"\n",
    "        Process data dict to fetch customer Id.\n",
    "\n",
    "                Parameters:\n",
    "                        briaApiJson (dict): Output Dictionary\n",
    "                        data (list): Key Value Pair Data Dictionary\n",
    "\n",
    "    \"\"\"\n",
    "    if pipelineCustomJson is not None:\n",
    "        if not (pipelineCustomJson.get('customerUniqueId') is None):\n",
    "            custId = reformatCustomerID(pipelineCustomJson['customerUniqueId'].lower())\n",
    "            if pipelineRawContent.find(custId) > -1 and len(custId) > 7:\n",
    "                briaApiJson['customerDetails']['customerId'] = custId\n",
    "                return\n",
    "\n",
    "    customerId=None\n",
    "    for fieldKey in fieldKeys['customerId']:\n",
    "        fieldKey = fieldKey.lower()\n",
    "        for extractedField in pipelinePreBuiltkeyValuePairs:\n",
    "  \n",
    "            keyName = extractedField['Name']\n",
    "            if (keyName.find(fieldKey) > -1 ):\n",
    "                customerId = reformatCustomerID(extractedField['Value'])\n",
    "                \n",
    "                if (customerId.startswith(\"1\") or customerId.startswith(\"u\")) and len(customerId) > 8 and  len(customerId) < 12 and customerId[1:].isnumeric():\n",
    "                    briaApiJson['customerDetails']['customerId'] = customerId\n",
    "                    return\n",
    "                elif customerId.startswith(\"v\") and len(customerId) > 8 and  len(customerId) < 12  and customerId[1:].isnumeric():\n",
    "                    briaApiJson['customerDetails']['customerId'] = \"u\" + customerId[1:]\n",
    "                    return\n",
    "                else:\n",
    "                    customerId = None\n",
    "\n",
    "    for fieldKey in fieldKeys['customerIdFull']:\n",
    "        fieldKey = fieldKey.lower()\n",
    "        for extractedField in pipelinePreBuiltkeyValuePairs:\n",
    "            keyName = extractedField['Name']\n",
    "            if (keyName == fieldKey) :\n",
    "                customerIdE = reformatCustomerID(extractedField['Value'])\n",
    "                customerIds= re.finditer(REGEXMemberId,customerIdE)\n",
    "                for customerIdIter in customerIds:\n",
    "                    customerId = str(customerIdIter.group())\n",
    "                    if (str(customerId).startswith(\"1\") or str(customerId).startswith(\"u\")) and len(customerId) > 8 and  len(customerId) < 12 and customerId[1:].isnumeric():\n",
    "                        briaApiJson['customerDetails']['customerId'] = customerId[0:]\n",
    "                        return\n",
    "                    elif str(customerId).startswith(\"v\") and len(customerId) > 8 and  len(customerId) < 12 and customerId[1:].isnumeric():\n",
    "                        briaApiJson['customerDetails']['customerId'] = \"u\" + customerId[0][1:]\n",
    "                        return\n",
    "                    else:\n",
    "                        customerId = None\n",
    "\n",
    "    if briaApiJson['customerDetails']['customerId'] == \"\":\n",
    "        customerIds= re.finditer(REGEXMemberId,pipelineRawContent)\n",
    "        for customerIdIter in customerIds:\n",
    "            customerId = str(customerIdIter.group())\n",
    "            if chkTokenPresent(pipelineRawContent,20,3,fieldKeys,'customerId',customerId,None) is not None:\n",
    "                briaApiJson['customerDetails']['customerId'] = customerId\n",
    "                return \n",
    "\n",
    "    if briaApiJson['customerDetails']['customerId'] == \"\":\n",
    "        customerIds= re.finditer(REGEXMemberId,pipelineOCRRawContent)\n",
    "        for customerIdIter in customerIds:\n",
    "            customerId = str(customerIdIter.group())\n",
    "            if chkTokenPresent(pipelineOCRRawContent,20,3,fieldKeys,'customerId',customerId,None) is not None:\n",
    "                briaApiJson['customerDetails']['customerId'] = customerId\n",
    "                return \n",
    "\n",
    "    if briaApiJson['customerDetails']['customerId'] == \"\":\n",
    "        customerIds= re.finditer(REGEXMemberId2,pipelineOCRRawContent)\n",
    "        for customerIdIter in customerIds:\n",
    "            customerId = str(customerIdIter.group())\n",
    "            if chkTokenPresent(pipelineOCRRawContent,5,2,fieldKeys,'customerId',customerId,None) is not None:\n",
    "                briaApiJson['customerDetails']['customerId'] = customerId\n",
    "                return \n",
    "\n",
    "    if briaApiJson['customerDetails']['customerId'] == \"\":\n",
    "        if not (pipelineCustomJson.get('customerUniqueId') is None):\n",
    "            providerlinkId = pipelineCustomJson['customerUniqueId'].lower()\n",
    "            matcher = FuzzyMatcher(nlp.vocab)\n",
    "            matcher.add(\"ORTH\", [nlp(providerlinkId)])\n",
    "            matches = matcher(pipelineRawContentdoc)\n",
    "            if len(matches) > 0:\n",
    "                briaApiJson['customerDetails']['customerId'] = providerlinkId\n",
    "                return        \n",
    "\n",
    "def getAccountNum(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineOCRRawContent,pipelineCustomkeyValuePairs):\n",
    "    accountNum=None\n",
    "    for fieldKey in fieldKeys['accountNumber']:\n",
    "        fieldKey = fieldKey.lower()\n",
    "        for extractedField in pipelinePreBuiltkeyValuePairs:\n",
    "            keyName = extractedField['Name']            \n",
    "            if (keyName.find(fieldKey) > -1 ):\n",
    "                accountNum = extractedField['Value']\n",
    "                accountNum=(''.join(filter(str.isdigit, accountNum)))\n",
    "                if accountNum.isnumeric() and len(accountNum) >= 7 and len(accountNum) < 9:\n",
    "                    briaApiJson['customerDetails']['accountNumber'] = accountNum\n",
    "                    return\n",
    "                else:\n",
    "                    accountNum = None\n",
    "\n",
    "    if accountNum is None:\n",
    "        accountNums= re.finditer(r'^(d{7})$',pipelineRawContent)\n",
    "        for accountNumIter in accountNums:\n",
    "            accountNum = str(accountNumIter.group())\n",
    "            if chkTokenPresent(pipelineRawContent,10,3,fieldKeys,'accountNumber',str(accountNum),None) is not None:\n",
    "                briaApiJson['customerDetails']['accountNumber'] = accountNum\n",
    "                return \n",
    "\n",
    "    if accountNum is None:\n",
    "        accountNums= re.finditer(r'^(d{7})$',pipelineOCRRawContent)\n",
    "        for accountNumIter in accountNums:\n",
    "            accountNum = str(accountNumIter.group())\n",
    "            if chkTokenPresent(pipelineRawContent,10,3,fieldKeys,'accountNumber',str(accountNum),None) is not None:\n",
    "                briaApiJson['customerDetails']['accountNumber'] = accountNum\n",
    "                return    \n",
    "\n",
    "def getDOB(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineCustomJson,pipelineOCRRawContent,pipelineCustomkeyValuePairs):\n",
    "\n",
    "    for fieldKey in fieldKeys['dateOfBirth']:\n",
    "        fieldKey = fieldKey.lower()\n",
    "        for extractedField in pipelinePreBuiltkeyValuePairs:\n",
    "            keyName = extractedField['Name']\n",
    "            if (keyName.find(fieldKey) > -1 ):\n",
    "                dobfmt=dateExtract(extractedField['Value'])          \n",
    "                if dobfmt is not None:\n",
    "                    briaApiJson['customerDetails']['dateOfBirth'] = dobfmt\n",
    "                    return                \n",
    "\n",
    "    if briaApiJson['customerDetails']['dateOfBirth'] == \"\":\n",
    "        pipelineRawContentCleaned = preclean_input_text_for_find_dates(pipelineRawContent)\n",
    "        dates = datefinder.find_dates(pipelineRawContentCleaned,source=True,strict=True,index=True)\n",
    "        for date in dates:\n",
    "            if chkTokenPresent(pipelineRawContentCleaned,5,3,fieldKeys,'dateOfBirth',date[1],None,date[2][0]) is not None:\n",
    "                dobfmt = dateParse(date[1])\n",
    "                if dobfmt is not None:\n",
    "                    briaApiJson['customerDetails']['dateOfBirth'] = dobfmt\n",
    "                    return                \n",
    "\n",
    "    if briaApiJson['customerDetails']['dateOfBirth'] == \"\":\n",
    "        pipelineRawContentCleaned = preclean_input_text_for_find_dates(pipelineOCRRawContent)\n",
    "        dates = datefinder.find_dates(pipelineRawContentCleaned,source=True,strict=True,index=True)\n",
    "        for date in dates:\n",
    "            if chkTokenPresent(pipelineOCRRawContent,5,3,fieldKeys,'dateOfBirth',date[1],None) is not None:\n",
    "                dobfmt = dateParse(date[1])\n",
    "                if dobfmt is not None:\n",
    "                    briaApiJson['customerDetails']['dateOfBirth'] = dobfmt\n",
    "                    return  \n",
    "\n",
    "    if pipelineCustomJson is not None:\n",
    "        if not (pipelineCustomJson.get('dateOfBirth') is None):\n",
    "            dobfmt = dateParse(pipelineCustomJson['dateOfBirth'])\n",
    "            if dobfmt is not None:\n",
    "                if pipelineRawContent.find(dobfmt) > -1:\n",
    "                    briaApiJson['customerDetails']['dateOfBirth'] = dobfmt\n",
    "                    return\n",
    "\n",
    "    for pipelineCustomkeyValuePair in pipelineCustomkeyValuePairs:\n",
    "        if pipelineCustomkeyValuePair['Name'] == 'dateOfBirth':\n",
    "            dobfmt = dateParse(pipelineCustomkeyValuePair['Value'])\n",
    "            if dobfmt is not None:\n",
    "                briaApiJson['customerDetails']['dateOfBirth'] = dobfmt\n",
    "                return                    \n",
    "\n",
    "\n",
    "\n",
    "def getPatientName(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineRawContentdoc,pipelineCustomJson,pipelineOCRRawContent,pipelineCustomkeyValuePairs):\n",
    "\n",
    "    if pipelineCustomJson is not None:\n",
    "        if not (pipelineCustomJson.get('firstName') is None):\n",
    "            firstName = pipelineCustomJson['firstName'].lower().strip()\n",
    "            if pipelineRawContent.find(firstName) > -1 and len(firstName) > 3:\n",
    "                briaApiJson['customerDetails']['firstName'] = firstName\n",
    "            else:\n",
    "                firstNameparts = firstName.split()\n",
    "                if firstNameparts[0] is not None and len(firstNameparts[0]) > 3 and pipelineRawContent.find(firstNameparts[0] ) > -1:\n",
    "                    briaApiJson['customerDetails']['firstName'] = firstName\n",
    "\n",
    "       \n",
    "    if pipelineCustomJson is not None:    \n",
    "        if not (pipelineCustomJson.get('lastName') is None):\n",
    "            lastName = pipelineCustomJson['lastName'].lower().strip()\n",
    "            if pipelineRawContent.find(lastName) > -1 and len(lastName) > 3:\n",
    "                briaApiJson['customerDetails']['lastName'] = lastName\n",
    "\n",
    "    if briaApiJson['customerDetails']['lastName']   != \"\" and briaApiJson['customerDetails']['firstName'] != \"\":\n",
    "        return\n",
    "\n",
    "\n",
    "    for fieldKey in fieldKeys['patientName']:\n",
    "        fieldKey = fieldKey.lower()\n",
    "        for extractedField in pipelinePreBuiltkeyValuePairs:\n",
    "            keyName = extractedField['Name']\n",
    "            if (keyName.find(fieldKey) > -1 ):  \n",
    "                patientName = extractedField['Value']\n",
    "                split_names = split_name(patientName)\n",
    "                briaApiJson['customerDetails']['firstName'] = split_names['firstName']\n",
    "                briaApiJson['customerDetails']['lastName']  = split_names['lastName']\n",
    "                return\n",
    "\n",
    "    for fieldKey in fieldKeys['patientNamePartial']:\n",
    "        fieldKey = fieldKey.lower()\n",
    "        for extractedField in pipelinePreBuiltkeyValuePairs:\n",
    "            keyName = extractedField['Name']\n",
    "            if (keyName==fieldKey) :  \n",
    "                patientName = extractedField['Value']\n",
    "                if chkTokenPresent(pipelineRawContent,2,10,fieldKeys,'dateOfBirth',patientName,extractedField) is not None:\n",
    "                    split_names = split_name(patientName)\n",
    "                    briaApiJson['customerDetails']['firstName'] = split_names['firstName']\n",
    "                    briaApiJson['customerDetails']['lastName']  = split_names['lastName']\n",
    "                    return\n",
    "                if chkTokenPresent(pipelineOCRRawContent,2,10,fieldKeys,'dateOfBirth',patientName,extractedField) is not None:\n",
    "                    split_names = split_name(patientName)\n",
    "                    briaApiJson['customerDetails']['firstName'] = split_names['firstName']\n",
    "                    briaApiJson['customerDetails']['lastName']  = split_names['lastName']\n",
    "                    return                    \n",
    "\n",
    "    for pipelineCustomkeyValuePair in pipelineCustomkeyValuePairs:\n",
    "        if pipelineCustomkeyValuePair['Name'] == 'patientName':\n",
    "                split_names = split_name(pipelineCustomkeyValuePair['Value'])\n",
    "                briaApiJson['customerDetails']['firstName'] = split_names['firstName']\n",
    "                briaApiJson['customerDetails']['lastName']  = split_names['lastName']\n",
    "                return                                \n",
    "\n",
    "\n",
    "def getRequestType(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineOCRRawContent,pipelineCustomkeyValuePairs):\n",
    "    \n",
    "    for pipelineCustomkeyValuePair in pipelineCustomkeyValuePairs:\n",
    "        if pipelineCustomkeyValuePair['Name'] == 'patientType_Outpatient':  \n",
    "            if (pipelineCustomkeyValuePair['Value'] == \":selected:\"):\n",
    "                briaApiJson['procedureInformation']['requestType']='Outpatient'\n",
    "                return\n",
    "        if pipelineCustomkeyValuePair['Name'] == 'patientType_inpatient':             \n",
    "            if (pipelineCustomkeyValuePair['Value'] == \":selected:\"):\n",
    "                briaApiJson['procedureInformation']['requestType']='Inpatient'\n",
    "                return\n",
    "\n",
    "    for fieldKey in fieldKeys['patientType']:\n",
    "        fieldKey = fieldKey.lower()\n",
    "        for extractedField in pipelinePreBuiltkeyValuePairs:  \n",
    "            keyName = extractedField['Name']\n",
    "            if (keyName.find(fieldKey) > -1 ):  \n",
    "                patientType = extractedField['Value']\n",
    "                for fieldKey2 in fieldKeys['inpatient']:\n",
    "                    if patientType.find(fieldKey2) > -1 :\n",
    "                        briaApiJson['procedureInformation']['requestType']='Inpatient'\n",
    "                        return\n",
    "\n",
    "                for fieldKey2 in fieldKeys['observationStay']:\n",
    "                    if patientType.find(fieldKey2) > -1 :\n",
    "                        briaApiJson['procedureInformation']['requestType']='Outpatient'\n",
    "                        return\n",
    "\n",
    "\n",
    "    for fieldKey in fieldKeys['inpatient']:\n",
    "        fieldKey = fieldKey.lower()\n",
    "        for extractedField in pipelinePreBuiltkeyValuePairs:\n",
    "            keyName = extractedField['Name']            \n",
    "            if ((keyName.find(fieldKey) > -1 ) and extractedField['Value'] ==\":selected:\"):  \n",
    "                briaApiJson['procedureInformation']['requestType']='Inpatient'\n",
    "                return\n",
    "\n",
    "    for fieldKey in fieldKeys['observationStay']:\n",
    "        fieldKey = fieldKey.lower()\n",
    "        for extractedField in pipelinePreBuiltkeyValuePairs:\n",
    "            keyName = extractedField['Name']            \n",
    "            if ((keyName.find(fieldKey) > -1 ) and extractedField['Value'] ==\":selected:\"):  \n",
    "                briaApiJson['procedureInformation']['requestType']='Outpatient'\n",
    "                return\n",
    "\n",
    "## remove some keywords before looking for main words\n",
    "    for fieldKey in fieldKeys['inPatientKeywordsExclude']: \n",
    "        pipelineRawContent = pipelineRawContent.replace(fieldKey,\" \")\n",
    "        pipelineOCRRawContent = pipelineRawContent.replace(fieldKey,\" \")\n",
    "\n",
    "    for fieldKey in fieldKeys['outPatientKeywordsExclude']: \n",
    "        pipelineRawContent = pipelineRawContent.replace(fieldKey,\" \")\n",
    "        pipelineOCRRawContent = pipelineRawContent.replace(fieldKey,\" \")\n",
    "\n",
    "    foundIP=False\n",
    "    IPMatches = [IPpmatch for IPpmatch in fieldKeys['inPatientKeywordsInclude'] if IPpmatch in pipelineRawContent]\n",
    "    IPMatches.extend([IPpmatch for IPpmatch in fieldKeys['inPatientKeywordsInclude'] if IPpmatch in pipelineOCRRawContent])\n",
    "    if len(IPMatches) > 0:\n",
    "        foundIP=True\n",
    "\n",
    "    foundOP=False\n",
    "    OPMatches = [OPpmatch for OPpmatch in fieldKeys['outPatientKeywordsInclude'] if OPpmatch in pipelineRawContent]\n",
    "    OPMatches.extend([OPpmatch for OPpmatch in fieldKeys['outPatientKeywordsInclude'] if OPpmatch in pipelineOCRRawContent])\n",
    "    if len(OPMatches) > 0:\n",
    "        foundOP=True\n",
    "    \n",
    "    if foundIP and not foundOP:\n",
    "        briaApiJson['procedureInformation']['requestType']='Inpatient'\n",
    "        return\n",
    "\n",
    "    if foundOP and not foundIP:\n",
    "        briaApiJson['procedureInformation']['requestType']='Outpatient'\n",
    "        return\n",
    "\n",
    "    briaApiJson['procedureInformation']['requestType']='Inpatient'\n",
    "\n",
    "def getProcedureStartDate(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineOCRRawContent,pipelineCustomkeyValuePairs):\n",
    "    for fieldKey in fieldKeys['procedureStartDate']:\n",
    "        fieldKey = fieldKey.lower()\n",
    "        for extractedField in pipelinePreBuiltkeyValuePairs:\n",
    "            keyName = extractedField['Name']\n",
    "            for exclKeys in fieldKeys['excludeprocedureStartDate']:\n",
    "                if keyName.find(exclKeys) > -1: \n",
    "                    break\n",
    "            \n",
    "                if (keyName.find(fieldKey) > -1):\n",
    "                    procedureStartDatefmt=dateExtract(extractedField['Value'])\n",
    "                    if procedureStartDatefmt is not None:\n",
    "                        briaApiJson['procedureInformation']['procedureStartDate'] = procedureStartDatefmt\n",
    "                \n",
    "\n",
    "    if briaApiJson['procedureInformation']['procedureStartDate'] == \"\":\n",
    "        pipelineRawContent = preclean_input_text_for_find_dates(pipelineRawContent)\n",
    "        dates = datefinder.find_dates(pipelineRawContent,source=True, strict=True,index=True)\n",
    "        for date in dates:\n",
    "            if chkTokenPresent(pipelineRawContent,5,3,fieldKeys,'procedureStartDate',date[1],None,date[2][0]) is not None:\n",
    "                procedureStartDatefmt = date[0].strftime(\"%m/%d/%Y\")\n",
    "                if procedureStartDatefmt is not None:                \n",
    "                    briaApiJson['procedureInformation']['procedureStartDate'] = procedureStartDatefmt\n",
    "                    return \n",
    "\n",
    "    if briaApiJson['procedureInformation']['procedureStartDate'] == \"\":\n",
    "        pipelineOCRRawContent = preclean_input_text_for_find_dates(pipelineRawContent)\n",
    "        dates = datefinder.find_dates(pipelineOCRRawContent,source=True, strict=True,index=True)\n",
    "        for date in dates:\n",
    "            if chkTokenPresent(pipelineOCRRawContent,5,3,fieldKeys,'procedureStartDate',date[1],None,date[2][0]) is not None:\n",
    "                procedureStartDatefmt = date[0].strftime(\"%m/%d/%Y\")\n",
    "                if procedureStartDatefmt is not None:                \n",
    "                    briaApiJson['procedureInformation']['procedureStartDate'] = procedureStartDatefmt\n",
    "                    return\n",
    "\n",
    "    for pipelineCustomkeyValuePair in pipelineCustomkeyValuePairs:\n",
    "        if pipelineCustomkeyValuePair['Name'] == 'admissionDate':\n",
    "            dates = datefinder.find_dates(pipelineCustomkeyValuePair['Value'],source=True, strict=True,index=True)\n",
    "            for date in dates:\n",
    "                procedureStartDatefmt = date[0].strftime(\"%m/%d/%Y\")\n",
    "                if procedureStartDatefmt is not None:                \n",
    "                    briaApiJson['procedureInformation']['procedureStartDate'] = procedureStartDatefmt\n",
    "                    return\n",
    "\n",
    "\n",
    "def getMRN(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineRawContentdoc,pipelineOCRRawContent,pipelineCustomkeyValuePairs):\n",
    "    for fieldKey in fieldKeys['MRN']:\n",
    "        fieldKey = fieldKey.lower()\n",
    "        for extractedField in pipelinePreBuiltkeyValuePairs:\n",
    "            keyName = extractedField['Name']\n",
    "            if (keyName.find(fieldKey) > -1) :\n",
    "                mrn = formatMRN(extractedField['Value'])\n",
    "                if mrn is not None:                        \n",
    "                    briaApiJson['procedureInformation']['medicalRecordNumber'] = mrn\n",
    "                    return\n",
    "\n",
    "  \n",
    "    for pipelineCustomkeyValuePair in pipelineCustomkeyValuePairs:\n",
    "        if pipelineCustomkeyValuePair['Name'] == 'medicalRecordNumber':\n",
    "            mrn = formatMRN(pipelineCustomkeyValuePair['Value'])\n",
    "            if mrn is not None:        \n",
    "                briaApiJson['procedureInformation']['medicalRecordNumber'] = mrn\n",
    "                return\n",
    "\n",
    "    tokpattern = [\n",
    "    [{\"LOWER\": \"mrn\"}, {\"IS_SPACE\": True,\"OP\":\"?\"},{}],\n",
    "    [{\"LOWER\": \"mrn\"}, {\"IS_SPACE\": True,\"OP\":\"?\"},{\"LOWER\": \"#\",\"OP\":\"?\"},{}],\n",
    "    [{\"LOWER\": \"mr\"}, {\"IS_SPACE\": True,\"OP\":\"?\"},{\"LOWER\": \"#\",\"OP\":\"?\"},{}],\n",
    "    [{\"LOWER\": \"mrn#\"}, {\"IS_SPACE\": True,\"OP\":\"?\"},{}],\n",
    "    [{\"LOWER\": \"med rec \"}, {\"IS_SPACE\": True,\"OP\":\"?\"},{}],\n",
    "    [{\"LOWER\": \"med rec #\"}, {\"IS_SPACE\": True,\"OP\":\"?\"},{}]\n",
    "    ]\n",
    "    matcher = Matcher(nlp.vocab)                \n",
    "    matcher.add(\"MRN\", tokpattern)\n",
    "    matches = matcher(pipelineRawContentdoc)\n",
    "    for match_id, start, end in matches:\n",
    "        mrnParts = (pipelineRawContentdoc[start:end].text).split()\n",
    "        mrn=mrnParts[-1]\n",
    "        mrn = formatMRN(mrn)\n",
    "        if mrn is not None:        \n",
    "            briaApiJson['procedureInformation']['medicalRecordNumber'] = mrn\n",
    "            return\n",
    "\n",
    "def getDiagnosisCodes(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,icd10_file,fieldKeys,pipelineRawContentdoc,pipelineOCRRawContent,pipelineCustomkeyValuePairs):\n",
    "    icdCodesextracted=[]\n",
    "    diagnosisCodes=[]\n",
    "    diagnosisCodeRawText = []\n",
    "    auth_user = os.getenv('OSCP_NP_USER')\n",
    "    auth_password = os.getenv('OSCP_NP_PASS')     \n",
    "    with smbclient.open_file(icd10_file, mode=\"rb\",username=auth_user, password=auth_password,share_access=\"r\") as icd10FD:\n",
    "        df_icd10 = pd.read_excel(icd10FD,converters={'DIAG_DESC':str,'DIAG_CD':str})        \n",
    "    \n",
    "    icdCodeDescriptions = df_icd10['DIAG_DESC'].tolist()\n",
    "    phrasematcher = PhraseMatcher(nlp.vocab)\n",
    "    phrasepatterns = [nlp.make_doc(icdCodeDescription) for icdCodeDescription in icdCodeDescriptions]\n",
    "    phrasematcher.add(\"icdCodeDescriptions\", phrasepatterns)\n",
    "    del phrasepatterns\n",
    "\n",
    "    pipelineRawContent=getPipeLineRawContentFirst4Pages(pipelineContextJson)  # Get only first 4 pages\n",
    "    icdRegexMatches=[]\n",
    "    icdRegexMatches,pipelineRawContent = getICDCodes(pipelineRawContent)  # preprocess pipelRawContent as well for searching\n",
    "\n",
    "############ GET ALL diagnosis codes\n",
    "    for icdRegexMatch in icdRegexMatches:\n",
    "        icdMatches = df_icd10.loc[(df_icd10['DIAG_CD'] == icdRegexMatch[1])]\n",
    "        if len(icdMatches.index) > 0:\n",
    "            icdCodesextracted.append(icdRegexMatch[1])\n",
    "\n",
    "    for fieldKey in fieldKeys['diagnosisCodes']:\n",
    "        fieldKey = fieldKey.lower()\n",
    "        for extractedField in pipelinePreBuiltkeyValuePairs:\n",
    "            diagKey = extractedField['Name']\n",
    "            if extractedField['value']['boundingRegions'][0]['pageNumber'] > 4:\n",
    "                continue\n",
    "            if diagKey.lower().find(fieldKey) > -1 :\n",
    "                diagnosisData,_ignore = getICDCodes(extractedField['Value'])\n",
    "                if len(icdCodesextracted) > 0 and len(diagnosisData) > 0:\n",
    "                    for icdCodeextracted in icdCodesextracted:\n",
    "                        for diagnosis in diagnosisData:\n",
    "                            if icdCodeextracted == diagnosis[1]:\n",
    "                                diagnosisCode={}\n",
    "                                diagnosisCode['name'] = \"\"\n",
    "                                diagnosisCode['code'] = icdCodeextracted\n",
    "                                diagnosisCodes.append(diagnosisCode)\n",
    "\n",
    "    \n",
    "    for icdRegexMatch in icdRegexMatches:\n",
    "        if icdRegexMatch[1] in icdCodesextracted:\n",
    "            if (chkTokenPresent(pipelineRawContent,25,5,fieldKeys,'diagnosisCodes',icdRegexMatch[1],None,icdRegexMatch[2]) is not None):\n",
    "                diagnosisCode={}\n",
    "                diagnosisCode['name'] = \"\"\n",
    "                diagnosisCode['code'] = icdRegexMatch[1]\n",
    "                diagnosisCodes.append(diagnosisCode)\n",
    "\n",
    "############ GET ALL diagnosis code texts\n",
    "    for fieldKey in fieldKeys['diagnosisCodes']:\n",
    "        fieldKey = fieldKey.lower()\n",
    "        for extractedField in pipelinePreBuiltkeyValuePairs:\n",
    "            if extractedField['value']['boundingRegions'][0]['pageNumber'] > 4:\n",
    "                continue\n",
    "            diagKey = extractedField['Name']\n",
    "            if diagKey.lower().find(fieldKey) > -1  :\n",
    "                diagnosisCodeRawText.append(extractedField['Value'].strip()) \n",
    "\n",
    "    matches = phrasematcher(pipelineRawContentdoc)\n",
    "    spans= [pipelineRawContentdoc[start:end] for _,start,end in matches]\n",
    "    for span in spacy.util.filter_spans(spans):\n",
    "        diagtext = span.text.strip()  # The matched span\n",
    "        if (chkTokenPresent(pipelineRawContent,25,5,fieldKeys,'diagnosisCodes',diagtext,None,span.start) is not None):\n",
    "            diagnosisCodeRawText.append(diagtext.strip()) \n",
    "\n",
    "    diagnosisCodeCleanedText = []\n",
    "    for diagnosisCodeText in diagnosisCodeRawText:\n",
    "        diagnosisDataCleaned = re.sub(REGEXICDCode_repl,'',diagnosisCodeText)\n",
    "        if len(icdCodesextracted) > 0:\n",
    "            for icdRegexMatch in icdRegexMatches:\n",
    "                diagnosisDataCleaned = diagnosisDataCleaned.replace(icdRegexMatch[0],\"\")\n",
    "            if len(diagnosisDataCleaned) > 0:\n",
    "                diagnosisCodeCleanedText.append(diagnosisDataCleaned.strip())\n",
    "        else:\n",
    "            diagnosisCodeCleanedText.append(diagnosisCodeText.strip())\n",
    "\n",
    "    for diagnosisCodeCleaned in diagnosisCodeCleanedText:\n",
    "        diagnosisCodeCleanedDoc=nlp(diagnosisCodeCleaned)\n",
    "        matches = phrasematcher(diagnosisCodeCleanedDoc)\n",
    "        spans= [diagnosisCodeCleanedDoc[start:end] for _,start,end in matches]\n",
    "        for span in spacy.util.filter_spans(spans):\n",
    "            diagtext = span.text.strip()  # The matched span\n",
    "            diagnosisCode={}\n",
    "            diagnosisCode['name'] = diagtext\n",
    "            diagnosisCode['code'] = \"\"\n",
    "            diagnosisCodes.append(diagnosisCode)\n",
    "        \n",
    "        if len(spans) ==0:\n",
    "            maxLen=1000\n",
    "            diagnosisCodeMatch=None\n",
    "            for icdCodeDescription in icdCodeDescriptions:\n",
    "                if icdCodeDescription.find(diagnosisCodeCleaned)> -1:\n",
    "                    matchLen = len(icdCodeDescription)\n",
    "                    if matchLen < maxLen:\n",
    "                        diagnosisCodeMatch = icdCodeDescription\n",
    "                        maxLen=matchLen\n",
    "            if diagnosisCodeMatch is not None: \n",
    "                diagnosisCode={}\n",
    "                diagnosisCode['name'] = diagnosisCodeMatch\n",
    "                diagnosisCode['code'] = \"\"\n",
    "                diagnosisCodes.append(diagnosisCode)\n",
    "               \n",
    "\n",
    "    if len(diagnosisCodes) > 0: \n",
    "        diagnosisCodes=list(unique_everseen(diagnosisCodes))\n",
    "        briaApiJson['procedureInformation']['diagnosisCodes'].extend(diagnosisCodes)\n",
    "        return\n",
    "      \n",
    "\n",
    "    if len(diagnosisCodes) == 0 :  # If still no diagnosis, pass default one\n",
    "        diagnosisCode={}\n",
    "        diagnosisCode['name'] = \"No Diagnosis Code extracted\"\n",
    "        diagnosisCode['code'] = \"\"\n",
    "        diagnosisCodes.append(diagnosisCode)\n",
    "        briaApiJson['procedureInformation']['diagnosisCodes'].extend(diagnosisCodes)\n",
    "        return    \n",
    "\n",
    "\n",
    "def getProcedureCodes(pipelineRawContent,pipelineRawContentdoc,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineOCRRawContent,pipelineCustomkeyValuePairs):\n",
    "        #getProcedureCodes(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson)    \n",
    "    procedureCodes=[]\n",
    "    procedureCode={}\n",
    "    procedureCode['name'] = \"Observation\"\n",
    "    procedureCode['code'] = \"99218\"\n",
    "    procedureCode['placeOfService'] = 'Hospital Outpatient'\n",
    "    procedureCode['requestedUnits'] = \"23\"\n",
    "\n",
    "    tokpattern = [\n",
    "        [{\"ORTH\": \"day\"}, {\"TEXT\":{\"REGEX\": \"\\d{1}\"}}],\n",
    "        [{\"TEXT\":{\"REGEX\": \"\\d{1}\"}},{\"ORTH\": \"day\"}],\n",
    "        [{\"ORTH\": \"day\"}, {\"TEXT\":{\"REGEX\": \"\\d{2}\"}}],\n",
    "        [{\"TEXT\":{\"REGEX\": \"\\d{2}\"}},{\"ORTH\": \"day\"}]\n",
    "    ]\n",
    "    matcher = Matcher(nlp.vocab)                \n",
    "    matcher.add(\"Matcher_literal_DAYS\", tokpattern)  \n",
    "    matches = matcher(pipelineRawContentdoc)\n",
    "    for match_id, start, end in matches:\n",
    "        if chkTokenPresent(pipelineRawContent,5,3,fieldKeys,'requestedUnits','day',None) is not None:\n",
    "            units=(''.join(filter(str.isdigit, pipelineRawContentdoc[start:end].text)))\n",
    "            if units.isnumeric() and int(units) < 5:\n",
    "                procedureCode['requestedUnits'] = 24* int((pipelineRawContentdoc[start:start].text))\n",
    "                return\n",
    "\n",
    "    tokpattern = [\n",
    "        [{\"ORTH\": \"hour\"}, {\"TEXT\":{\"REGEX\": \"\\d{1}\"}}],\n",
    "        [{\"TEXT\":{\"REGEX\": \"\\d{1}\"}},{\"ORTH\": \"hour\"}],\n",
    "        [{\"ORTH\": \"hr\"}, {\"TEXT\":{\"REGEX\": \"\\d{2}\"}}],\n",
    "        [{\"TEXT\":{\"REGEX\": \"\\d{2}\"}},{\"ORTH\": \"hr\"}],\n",
    "        [{\"ORTH\": \"hrs\"}, {\"TEXT\":{\"REGEX\": \"\\d{1}\"}}],\n",
    "        [{\"TEXT\":{\"REGEX\": \"\\d{2}\"}},{\"ORTH\": \"hrs\"}],\n",
    "\n",
    "    ]\n",
    "    matcher = Matcher(nlp.vocab)                \n",
    "    matcher.add(\"Matcher_literal_Hours\", tokpattern)  \n",
    "    matches = matcher(pipelineRawContentdoc)\n",
    "    for match_id, start, end in matches:\n",
    "        if chkTokenPresent(pipelineRawContent,5,3,fieldKeys,'observationStay','hour',None) is not None:  \n",
    "            units=(''.join(filter(str.isdigit, pipelineRawContentdoc[start:end].text)))          \n",
    "            if units.isnumeric() and int(units) < 100:\n",
    "                procedureCode['requestedUnits'] = units\n",
    "\n",
    "    \n",
    "    briaApiJson['procedureInformation']['procedureCodes'].append(procedureCode)\n",
    "\n",
    "def getRequestingNPI(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineRawContentdoc,pipelineOCRRawContent,pipelineCustomkeyValuePairs):\n",
    "    \n",
    "    for fieldKey in fieldKeys['NPIrequesting']:\n",
    "        fieldKey = fieldKey.lower()\n",
    "        for extractedField in pipelinePreBuiltkeyValuePairs:\n",
    "            keyName = extractedField['Name']\n",
    "            if (keyName.find(fieldKey) > -1 ):\n",
    "                npiResponse = getNPI(extractedField['Value'])\n",
    "                if npiResponse is not None and npiResponse[\"results\"][0][\"enumeration_type\"] == \"NPI-1\":\n",
    "                    briaApiJson['providerDetails']['requestingProvider']['npi'] = npiResponse[\"results\"][0][\"number\"]\n",
    "                    break\n",
    "                else:\n",
    "                    if (extractedField['Value']).isnumeric() and (extractedField['Value']).startswith(\"1\") and len((extractedField['Value'])) ==10 :\n",
    "                        briaApiJson['providerDetails']['requestingProvider']['npi'] = (extractedField['Value'])\n",
    "                        break\n",
    "\n",
    "    for fieldKey in fieldKeys['NPIservicing']:\n",
    "        fieldKey = fieldKey.lower()\n",
    "        for extractedField in pipelinePreBuiltkeyValuePairs:\n",
    "            keyName = extractedField['Name']\n",
    "            if (keyName.find(fieldKey) > -1 ):\n",
    "                npiResponse = getNPI(extractedField['Value'])\n",
    "                if npiResponse is not None and npiResponse[\"results\"][0][\"enumeration_type\"] == \"NPI-2\":\n",
    "                    briaApiJson['providerDetails']['servicingProvider']['npi'] = npiResponse[\"results\"][0][\"number\"]\n",
    "\n",
    "\n",
    "#IF No npi tags are found \n",
    "    for requestingNPIMatch in re.findall(\"[1][0-9]{9}\", pipelineRawContent):\n",
    "        npiRegistryResponse = getNPI(requestingNPIMatch)\n",
    "        if npiRegistryResponse is None:\n",
    "            continue\n",
    "\n",
    "        if npiRegistryResponse[\"results\"][0][\"enumeration_type\"] == \"NPI-2\":\n",
    "            npiServicingProvider = npiRegistryResponse[\"results\"][0][\"number\"]\n",
    "            if briaApiJson['providerDetails']['servicingProvider']['npi'] == \"\":\n",
    "                if chkTokenPresent(pipelineRawContent,5,3,fieldKeys,'NPI',npiServicingProvider,None) is not None:\n",
    "                    briaApiJson['providerDetails']['servicingProvider']['npi'] = npiServicingProvider\n",
    "        \n",
    "        elif npiRegistryResponse[\"results\"][0][\"enumeration_type\"] == \"NPI-1\":\n",
    "            npiRequestingProvider = npiRegistryResponse[\"results\"][0][\"number\"]\n",
    "            npiRequestingProviderFirstName = npiRegistryResponse[\"results\"][0][\"basic\"][\"first_name\"].lower()\n",
    "            npiRequestingProviderLastName = npiRegistryResponse[\"results\"][0][\"basic\"][\"last_name\"].lower()\n",
    "            if pipelineRawContent.find(npiRequestingProviderFirstName) > -1 or pipelineRawContent.find(npiRequestingProviderLastName) > -1:\n",
    "                if chkTokenPresent(pipelineRawContent,5,3,fieldKeys,'NPIrequesting',npiRequestingProvider,None) is not None:\n",
    "                    briaApiJson['providerDetails']['requestingProvider']['npi'] = npiRequestingProvider\n",
    "                    briaApiJson['providerDetails']['requestingProvider']['firstName'] = npiRegistryResponse[\"results\"][0][\"basic\"][\"first_name\"]\n",
    "                    briaApiJson['providerDetails']['requestingProvider']['lastName'] = npiRegistryResponse[\"results\"][0][\"basic\"][\"last_name\"]\n",
    "                    continue\n",
    "                else:\n",
    "                    briaApiJson['providerDetails']['requestingProvider']['npi'] = npiRequestingProvider\n",
    "                    briaApiJson['providerDetails']['requestingProvider']['firstName'] = npiRegistryResponse[\"results\"][0][\"basic\"][\"first_name\"]\n",
    "                    briaApiJson['providerDetails']['requestingProvider']['lastName'] = npiRegistryResponse[\"results\"][0][\"basic\"][\"last_name\"]\n",
    "\n",
    "            else:\n",
    "                if chkTokenPresent(pipelineRawContent,5,3,fieldKeys,'NPI',npiRequestingProvider,None) is not None:\n",
    "                    briaApiJson['providerDetails']['requestingProvider']['npi'] = npiRequestingProvider\n",
    "\n",
    "\n",
    "def getServicingfacilityName(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineRawContentdoc,hospitalfile,pipelineOCRRawContent,pipelineCustomkeyValuePairs):\n",
    "\n",
    "    if briaApiJson['providerDetails']['servicingProvider']['facilityName'] == \"\":\n",
    "        phrasematcher = PhraseMatcher(nlp.vocab)\n",
    "\n",
    "        #hospitallist = open(hospitalfile,'r')\n",
    "        #phrasepatterns = [nlp.make_doc(phraseLine.lower().replace(\"\\n\",\"\")) for phraseLine in hospitallist]\n",
    "        auth_user = os.getenv('OSCP_NP_USER')\n",
    "        auth_password = os.getenv('OSCP_NP_PASS')         \n",
    "        with smbclient.open_file(hospitalfile, mode=\"r\",username=auth_user, password=auth_password,share_access=\"r\") as hospitallist:\n",
    "            phrasepatterns = [nlp.make_doc(phraseLine.lower().replace(\"\\n\",\"\")) for phraseLine in hospitallist]\n",
    "\n",
    "\n",
    "        phrasematcher.add(\"Hospitals\", phrasepatterns)\n",
    "        matches = phrasematcher(pipelineRawContentdoc)\n",
    "        match_count_dictionary = {} #hold counts of unique matches\n",
    "        \n",
    "        del phrasepatterns        \n",
    "        maxlen=0\n",
    "        maxStart=0\n",
    "        maxEnd=0\n",
    "        for match_id, start, end in matches:\n",
    "            matchLen = len(str(pipelineRawContentdoc[start:end]))\n",
    "            if matchLen > maxlen:\n",
    "                maxlen = matchLen\n",
    "                maxStart = start\n",
    "                maxEnd =end\n",
    "            if len(matches) > 1: #populate dictionary only if more than one match found\n",
    "                if str(pipelineRawContentdoc[start:end]) in match_count_dictionary:\n",
    "                    match_count_dictionary[str(pipelineRawContentdoc[start:end])] = match_count_dictionary.get(str(pipelineRawContentdoc[start:end])) + 1 #increasing count of match occurrences\n",
    "                else:\n",
    "                    match_count_dictionary[str(pipelineRawContentdoc[start:end])] = 1 # all unique matches start at 1\n",
    "        if len(matches) > 1: # only finding the highest count match if there is more than one match found\n",
    "            # edit to account for non-stem matches\n",
    "            maxcount = 0 \n",
    "            mostmatches = ''\n",
    "            for x,y in match_count_dictionary.items():\n",
    "                if y > maxcount:\n",
    "                    maxcount = y\n",
    "                    mostmatches = x\n",
    "            if maxcount > 1: # if there is a max count that is greater than 1 \n",
    "                stem = mostmatches\n",
    "                maxlen = len(stem)\n",
    "                stem_matches = [match for match in match_count_dictionary.keys() if match.find(stem) != -1]\n",
    "                maxcount = 0\n",
    "                for match in stem_matches: #checking if another match has the most common stem, but is more common\n",
    "                    if len(match) > maxlen: #if the match is longer than the stem (eliminates getting the stem count)\n",
    "                        if match_count_dictionary.get(match) > maxcount:\n",
    "                            maxcount = match_count_dictionary.get(match)\n",
    "                            mostmatches = match\n",
    "\n",
    "\n",
    "        if maxlen > 0:        \n",
    "            briaApiJson['providerDetails']['servicingProvider']['facilityName'] = str(pipelineRawContentdoc[maxStart:maxEnd])\n",
    "            return\n",
    "\n",
    "    if briaApiJson['providerDetails']['servicingProvider']['facilityName'] == \"\":\n",
    "        for pipelineCustomkeyValuePair in pipelineCustomkeyValuePairs:\n",
    "            if pipelineCustomkeyValuePair['Name'] == 'facilityName':\n",
    "                if len(str(pipelineCustomkeyValuePair['Value'])) > len(briaApiJson['providerDetails']['servicingProvider']['facilityName']):\n",
    "                    briaApiJson['providerDetails']['servicingProvider']['facilityName']  = str(pipelineCustomkeyValuePair['Value'])\n",
    "                    return\n",
    "\n",
    "    if briaApiJson['providerDetails']['servicingProvider']['facilityName'] == \"\":\n",
    "        for fieldKey in fieldKeys['servicingProviderfacilityName']:\n",
    "            fieldKey = fieldKey.lower()\n",
    "            for extractedField in pipelinePreBuiltkeyValuePairs:\n",
    "                keyName = extractedField['Name']\n",
    "                if (keyName.find(fieldKey) > -1):\n",
    "                    briaApiJson['providerDetails']['servicingProvider']['facilityName']  = str(extractedField['Value'])\n",
    "                    return\n",
    "\n",
    "def getRequestingProvider(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineRawContentdoc,nlp,pipelineOCRRawContent,pipelineCustomkeyValuePairs):\n",
    "    if briaApiJson['providerDetails']['requestingProvider']['firstName'] != \"\" and briaApiJson['providerDetails']['requestingProvider']['lastName'] != \"\":\n",
    "        return  \n",
    "\n",
    "    referringProvider=[]\n",
    "    for fieldKey in fieldKeys['requestingProviderName']:\n",
    "        fieldKey = fieldKey.lower()\n",
    "\n",
    "        for extractedField in pipelinePreBuiltkeyValuePairs:\n",
    "            keyName = extractedField['Name']\n",
    "            keyValue = extractedField['Value']\n",
    "            \n",
    "            foundproviderNameExclude = False\n",
    "            for providerNameExclude in fieldKeys['excludeProviderName']:\n",
    "                if (providerNameExclude in keyName) or (providerNameExclude in keyValue):\n",
    "                    if keyValue not in referringProvider:\n",
    "                        referringProvider.append(keyValue)\n",
    "                    foundproviderNameExclude = True\n",
    "                    break\n",
    "            if (foundproviderNameExclude):\n",
    "                continue            \n",
    "            \n",
    "            foundDoctorTitle = False\n",
    "\n",
    "            for drTitle in fieldKeys['doctorTitlesKey']:\n",
    "                if keyName.find(drTitle) > -1: \n",
    "                    foundDoctorTitle=True\n",
    "                    break \n",
    "            for drTitle in fieldKeys['doctorTitlesValue']:\n",
    "                if keyValue.find(drTitle) > -1: \n",
    "                    foundDoctorTitle=True\n",
    "                    break \n",
    "            \n",
    "            if not(foundDoctorTitle):\n",
    "                continue\n",
    "\n",
    "            if (keyName.find(fieldKey) > -1 ):\n",
    "                if str(extractedField['Value']).find(\"selected\") > -1: \n",
    "                    break\n",
    "                providerNames = getProviderName(extractedField['Value'])\n",
    "                \n",
    "                if  (providerNames.get('firstName') is not None):\n",
    "                    briaApiJson['providerDetails']['requestingProvider']['firstName'] = providerNames['firstName']\n",
    "                if ( (providerNames.get('lastName') is not None) ):                    \n",
    "                    briaApiJson['providerDetails']['requestingProvider']['lastName']  = providerNames['lastName']\n",
    "                    # special logic added when name is split in multiple lines fir XSOLIS templates\n",
    "                    if providerNames['firstName'] == providerNames['lastName']:\n",
    "                        tokenPos = extractedField['value']['spans'][0]['offset']\n",
    "                        remainingText = pipelineRawContent[tokenPos:].replace(',',' ')\n",
    "                        splitWords = remainingText.split()\n",
    "                        if len(splitWords) >0 :\n",
    "                            briaApiJson['providerDetails']['requestingProvider']['firstName'] = splitWords[1]\n",
    "                    return \n",
    "\n",
    "\n",
    "\n",
    "    for pipelineCustomkeyValuePair in pipelineCustomkeyValuePairs:\n",
    "        if pipelineCustomkeyValuePair['Name'] == 'admitting_physician_name':\n",
    "            if len(briaApiJson['providerDetails']['requestingProvider']['firstName']) + len(briaApiJson['providerDetails']['requestingProvider']['lastName']) < len(pipelineCustomkeyValuePair['Value']):\n",
    "                if pipelineCustomkeyValuePair['Value'].lower() not in referringProvider: \n",
    "                    providerNames = getProviderName(str(pipelineCustomkeyValuePair['Value']))\n",
    "                    briaApiJson['providerDetails']['requestingProvider']['firstName'] = providerNames['firstName']\n",
    "                    briaApiJson['providerDetails']['requestingProvider']['lastName']  = providerNames['lastName']\n",
    "                    return\n",
    "\n",
    "    for pipelineCustomkeyValuePair in pipelineCustomkeyValuePairs:\n",
    "        if pipelineCustomkeyValuePair['Name'] == 'attending_physician_name':\n",
    "            if len(briaApiJson['providerDetails']['requestingProvider']['firstName']) + len(briaApiJson['providerDetails']['requestingProvider']['lastName']) < len(pipelineCustomkeyValuePair['Value']):\n",
    "                if pipelineCustomkeyValuePair['Value'].lower() not in referringProvider: \n",
    "                    providerNames = getProviderName(str(pipelineCustomkeyValuePair['Value']))\n",
    "                    briaApiJson['providerDetails']['requestingProvider']['firstName'] = providerNames['firstName']\n",
    "                    briaApiJson['providerDetails']['requestingProvider']['lastName']  = providerNames['lastName']\n",
    "                    return\n",
    "\n",
    "    for fieldKey in fieldKeys['requestingProviderName']:\n",
    "        fieldKey = fieldKey.lower()\n",
    "\n",
    "        for extractedField in pipelinePreBuiltkeyValuePairs:\n",
    "            keyName = extractedField['Name']\n",
    "            keyValue = extractedField['Value']\n",
    "            \n",
    "            if (keyName.find(fieldKey) > -1 ):\n",
    "                if str(extractedField['Value']).find(\"selected\") > -1: \n",
    "                    break\n",
    "                providerNames = getProviderName(extractedField['Value'])\n",
    "                providerNamesFirst = providerNames.get('firstName')\n",
    "                providerNamesLast = providerNames.get('lastName')\n",
    "                if providerNamesLast is not None and providerNamesFirst is not None :\n",
    "                    providerNamesLastDoc = nlp(providerNamesLast)\n",
    "                    \n",
    "                    for token in providerNamesLastDoc:\n",
    "                        if token.ent_type_ == \"PERSON\":\n",
    "                            briaApiJson['providerDetails']['requestingProvider']['lastName']  = providerNamesLast\n",
    "                            break\n",
    "                    providerNamesFirsttDoc = nlp(providerNamesFirst)\n",
    "                    for token in providerNamesFirsttDoc:\n",
    "                        if token.ent_type_ == \"PERSON\":\n",
    "                            briaApiJson['providerDetails']['requestingProvider']['firstName']  = providerNamesFirst\n",
    "                            break\n",
    "\n",
    "\n",
    "\n",
    "def getTIN(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineRawContentdoc,pipelineOCRRawContent,pipelineCustomkeyValuePairs):\n",
    "    for fieldKey in fieldKeys['TIN']:\n",
    "        fieldKey = fieldKey.lower()\n",
    "       \n",
    "        for extractedField in pipelinePreBuiltkeyValuePairs:\n",
    "            keyName = extractedField['Name']\n",
    "            if (keyName.find(fieldKey) > -1 ):\n",
    "                tin = gettaxId(extractedField['Value'])\n",
    "                if tin is not None:\n",
    "                    \n",
    "                    if chkTokenPresent(pipelineRawContent,5,2,fieldKeys,'TINrequesting',extractedField['Value'],extractedField) is not None:\n",
    "                        if briaApiJson['providerDetails']['requestingProvider']['tin'] == '':\n",
    "                            briaApiJson['providerDetails']['requestingProvider']['tin'] = tin\n",
    "                    else:\n",
    "                        if briaApiJson['providerDetails']['servicingProvider']['tin'] == '':\n",
    "                            briaApiJson['providerDetails']['servicingProvider']['tin'] = tin\n",
    "                        \n",
    "\n",
    "\n",
    "    tokpattern = [\n",
    "    [{\"LOWER\": \"tax\"}, {\"ORTH\": \"-\",\"OP\":\"?\"},{\"LOWER\": \"id\"},{\"IS_SPACE\": True,\"OP\":\"?\"},{\"TEXT\":{\"REGEX\": \"\\d{9}\"}}],\n",
    "    [{\"LOWER\": \"tax\"}, {\"ORTH\": \"-\",\"OP\":\"?\"},{\"LOWER\": \"id\"},{\"IS_SPACE\": True,\"OP\":\"?\"},{\"TEXT\":{\"REGEX\": \"\\d{2}\"}},{\"ORTH\": \"-\",\"OP\":\"?\"} ,{\"TEXT\":{\"REGEX\": \"\\d{7}\"}}],\n",
    "\n",
    "    [{\"LOWER\": \"tax\"}, {\"ORTH\": \"-\",\"OP\":\"?\"},{\"LOWER\": \"i\"},{\"LOWER\": \"d\"},{\"IS_SPACE\": True,\"OP\":\"?\"},{\"TEXT\":{\"REGEX\": \"\\d{9}\"}}],\n",
    "    [{\"LOWER\": \"tax\"}, {\"ORTH\": \"-\",\"OP\":\"?\"},{\"LOWER\": \"i\"},{\"LOWER\": \"d\"},{\"IS_SPACE\": True,\"OP\":\"?\"},{\"TEXT\":{\"REGEX\": \"\\d{2}\"}},{\"ORTH\": \"-\",\"OP\":\"?\"} ,{\"TEXT\":{\"REGEX\": \"\\d{7}\"}}],\n",
    "\n",
    "    [{\"LOWER\": \"tax\"}, {\"ORTH\": \"-\",\"OP\":\"?\"},{\"LOWER\": \"i\"},{\"LOWER\": \"d\"},{\"IS_SPACE\": True,\"OP\":\"?\"},{},{\"TEXT\":{\"REGEX\": \"\\d{9}\"}}],\n",
    "    [{\"LOWER\": \"tax\"}, {\"ORTH\": \"-\",\"OP\":\"?\"},{\"LOWER\": \"i\"},{\"LOWER\": \"d\"},{\"IS_SPACE\": True,\"OP\":\"?\"},{},{\"TEXT\":{\"REGEX\": \"\\d{2}\"}},{\"ORTH\": \"-\",\"OP\":\"?\"} ,{\"TEXT\":{\"REGEX\": \"\\d{7}\"}}],\n",
    "\n",
    "    [{\"TEXT\":{\"REGEX\": \"\\d{2}\"}},{\"ORTH\": \"-\",\"OP\":\"?\"} ,{\"TEXT\":{\"REGEX\": \"\\d{7}\"}}],\n",
    "\n",
    "    [{\"LOWER\": \"tin\"}, {\"ORTH\": \"-\",\"OP\":\"?\"},{\"IS_SPACE\": True,\"OP\":\"?\"},{\"TEXT\":{\"REGEX\": \"\\d{9}\"}}],\n",
    "    [{\"LOWER\": \"tin\"}, {\"ORTH\": \"-\",\"OP\":\"?\"},{\"IS_SPACE\": True,\"OP\":\"?\"},{\"TEXT\":{\"REGEX\": \"\\d{2}\"}},{\"ORTH\": \"-\",\"OP\":\"?\"} ,{\"TEXT\":{\"REGEX\": \"\\d{7}\"}}],\n",
    "\n",
    "    [{\"LOWER\": \"tid\"}, {\"ORTH\": \"-\",\"OP\":\"?\"},{\"IS_SPACE\": True,\"OP\":\"?\"},{\"TEXT\":{\"REGEX\": \"\\d{9}\"}}],\n",
    "    [{\"LOWER\": \"tid\"}, {\"ORTH\": \"-\",\"OP\":\"?\"},{\"IS_SPACE\": True,\"OP\":\"?\"},{\"TEXT\":{\"REGEX\": \"\\d{2}\"}},{\"ORTH\": \"-\",\"OP\":\"?\"} ,{\"TEXT\":{\"REGEX\": \"\\d{7}\"}}],\n",
    "\n",
    "    [{\"LOWER\": \"taxid\"}, {\"ORTH\": \"-\",\"OP\":\"?\"},{\"IS_SPACE\": True,\"OP\":\"?\"},{\"TEXT\":{\"REGEX\": \"\\d{9}\"}}],\n",
    "    [{\"LOWER\": \"taxid\"}, {\"ORTH\": \"-\",\"OP\":\"?\"},{\"IS_SPACE\": True,\"OP\":\"?\"},{\"TEXT\":{\"REGEX\": \"\\d{2}\"}},{\"ORTH\": \"-\",\"OP\":\"?\"} ,{\"TEXT\":{\"REGEX\": \"\\d{7}\"}}],\n",
    "\n",
    "    [{\"LOWER\": \"tax\"},{\"LOWER\": \"identification\"},{\"NORM\": \"number\",\"OP\":\"?\"},{\"IS_SPACE\": True,\"OP\":\"?\"}, {\"ORTH\": \"-\",\"OP\":\"?\"},{\"TEXT\":{\"REGEX\": \"\\d{9}\"}}],\n",
    "    [{\"LOWER\": \"tax\"},{\"LOWER\": \"identification\"},{\"NORM\": \"number\",\"OP\":\"?\"},{\"IS_SPACE\": True,\"OP\":\"?\"},{\"ORTH\": \"-\",\"OP\":\"?\"},{\"TEXT\":{\"REGEX\": \"\\d{2}\"}},{\"ORTH\": \"-\",\"OP\":\"?\"} ,{\"TEXT\":{\"REGEX\": \"\\d{7}\"}}],\n",
    "\n",
    "    [{\"LOWER\": \"tax\"},{\"NORM\": \"number\",\"OP\":\"?\"},{\"IS_SPACE\": True,\"OP\":\"?\"}, {\"ORTH\": \"-\",\"OP\":\"?\"},{\"TEXT\":{\"REGEX\": \"\\d{9}\"}}],\n",
    "    [{\"LOWER\": \"tax\"},{\"NORM\": \"number\",\"OP\":\"?\"},{\"IS_SPACE\": True,\"OP\":\"?\"},{\"ORTH\": \"-\",\"OP\":\"?\"},{\"TEXT\":{\"REGEX\": \"\\d{2}\"}},{\"ORTH\": \"-\",\"OP\":\"?\"} ,{\"TEXT\":{\"REGEX\": \"\\d{7}\"}}]\n",
    "\n",
    "    ]\n",
    "    matcher = Matcher(nlp.vocab)                \n",
    "    matcher.add(\"TIN\", tokpattern)\n",
    "    matches = matcher(pipelineRawContentdoc)\n",
    "    for match_id, start, end in matches:\n",
    "        tin = gettaxId(pipelineRawContentdoc[start:end].text)\n",
    "        if tin is not None:        \n",
    "            if chkTokenPresent(pipelineRawContent,5,2,fieldKeys,'TINrequesting',tin,None) is not None:\n",
    "                if chkTokenPresent(pipelineRawContent,5,2,fieldKeys,'TINservicing',tin,None) is None:\n",
    "                    if briaApiJson['providerDetails']['requestingProvider']['tin'] == '':\n",
    "                        briaApiJson['providerDetails']['requestingProvider']['tin'] = tin\n",
    "                        continue\n",
    "            if briaApiJson['providerDetails']['servicingProvider']['tin'] == '':\n",
    "                briaApiJson['providerDetails']['servicingProvider']['tin'] = tin\n",
    "\n",
    "\n",
    "    if briaApiJson['providerDetails']['servicingProvider']['tin'] == '':\n",
    "        for pipelineCustomkeyValuePair in pipelineCustomkeyValuePairs:\n",
    "            if pipelineCustomkeyValuePair['Name'] == 'servicing_Provider_Tax_ID_number':\n",
    "                tin = gettaxId(pipelineCustomkeyValuePair['Value'])\n",
    "                if tin is not None:\n",
    "                    briaApiJson['providerDetails']['servicingProvider']['tin'] = tin\n",
    "                    continue                \n",
    "\n",
    "    if briaApiJson['providerDetails']['requestingProvider']['tin'] == '':\n",
    "        for pipelineCustomkeyValuePair in pipelineCustomkeyValuePairs:\n",
    "            if pipelineCustomkeyValuePair['Name'] == 'requestingprovider_tax_id_number':\n",
    "                requestingTin = gettaxId(pipelineCustomkeyValuePair['Value'])\n",
    "                if requestingTin is not None:\n",
    "                    if (requestingTin != briaApiJson['providerDetails']['servicingProvider']['tin']):\n",
    "                        briaApiJson['providerDetails']['requestingProvider']['tin'] = requestingTin\n",
    "                        continue\n",
    "\n",
    "def getStateCode(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineRawContentdoc,pipelineOCRRawContent,pipelineCustomkeyValuePairs):\n",
    "\n",
    "    tokpattern = [ \n",
    "[{'LENGTH': 2,\"ORTH\":{\"REGEX\":\"(a[klrz]|c[aot]|d[ce]|fl|ga|hi|i[adln]|k[sy]|la|m[adeinost]|n[cdehjmvy]|o[hkr]|pa|ri|s[cd]|t[nx]|ut|v[at]|w[aivy])\"}},{\"TEXT\":{\"REGEX\": \"\\d{5}\"}}]\n",
    "]\n",
    "    matcher = Matcher(nlp.vocab)                \n",
    "    matcher.add(\"ADDRESS\", tokpattern)\n",
    "    matches = matcher(pipelineRawContentdoc)\n",
    "    match_count_dictionary = {} #hold counts of unique matches\n",
    "    for match_id, start, end in matches:\n",
    "        words = str(pipelineRawContentdoc[start:end]).split()\n",
    "        if len(words) > 1:\n",
    "            state = words[0]\n",
    "            if state in match_count_dictionary:\n",
    "                match_count_dictionary[state] = match_count_dictionary.get(state) + 1 #increasing count of match occurrences\n",
    "            else:\n",
    "                match_count_dictionary[state] = 1 # all unique matches start at 1\n",
    "\n",
    "    if len(matches) > 1: # only finding the highest count match if there is more than one match found\n",
    "        maxcount = 0 \n",
    "        mostmatches = ''\n",
    "        for x,y in match_count_dictionary.items():\n",
    "            if y > maxcount:\n",
    "                maxcount = y\n",
    "                mostmatches = x\n",
    "                briaApiJson['providerDetails']['servicingProvider']['address']['state'] = mostmatches\n",
    "\n",
    "\n",
    "\n",
    "def getAddress(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineRawContentdoc,pipelineOCRRawContent,pipelineCustomkeyValuePairs):\n",
    "\n",
    "    if briaApiJson['providerDetails']['servicingProvider']['address']['addressLineOne'] ==\"\":\n",
    "        for pipelineCustomkeyValuePair in pipelineCustomkeyValuePairs:\n",
    "            if pipelineCustomkeyValuePair['Name'] == 'facilityAddress':\n",
    "                varAddr1,varCity,varState,varZip = SplitAddress(pipelineCustomkeyValuePair['Value'])\n",
    "                if varAddr1 != '' and   varCity != '' and varState != '' and varZip != '':\n",
    "                    briaApiJson['providerDetails']['servicingProvider']['address']['state'] = varState\n",
    "                    briaApiJson['providerDetails']['servicingProvider']['address']['city'] = varCity\n",
    "                    briaApiJson['providerDetails']['servicingProvider']['address']['zipCode'] = varZip\n",
    "                    briaApiJson['providerDetails']['servicingProvider']['address']['addressLineOne'] = varAddr1\n",
    "                    return      \n",
    "\n",
    "\n",
    "    for fieldKey in fieldKeys['servicingProviderfacilityName']:\n",
    "        fieldKey = fieldKey.lower()\n",
    "\n",
    "        for extractedField in pipelinePreBuiltkeyValuePairs:\n",
    "            keyName = extractedField['Name']\n",
    "            \n",
    "            foundAddressKeyword = False\n",
    "            for addressKeyWord in fieldKeys['addressKeywords']:\n",
    "                if keyName.find(addressKeyWord) > -1: \n",
    "                    foundAddressKeyword=True\n",
    "                    break \n",
    "            if not(foundAddressKeyword):\n",
    "                continue\n",
    "\n",
    "            if (keyName.find(fieldKey) > -1 ):\n",
    "                if str(extractedField['Value']).find(\"selected\") > -1: \n",
    "                    break\n",
    "\n",
    "                varAddr1,varCity,varState,varZip = SplitAddress(str(extractedField['Value']).upper())\n",
    "                if varAddr1 == '' or  varCity == '' or varState == '' or varZip == '':\n",
    "                    continue\n",
    "\n",
    "                briaApiJson['providerDetails']['servicingProvider']['address']['state'] = varState\n",
    "                briaApiJson['providerDetails']['servicingProvider']['address']['city'] = varCity\n",
    "                briaApiJson['providerDetails']['servicingProvider']['address']['zipCode'] = varZip\n",
    "                briaApiJson['providerDetails']['servicingProvider']['address']['addressLineOne'] = varAddr1\n",
    "                return\n",
    "\n",
    "    pipelineRawContent=PreProcessforExtractAddress(pipelineRawContent)\n",
    "    addresses = ExtractAddress(pipelineRawContent)\n",
    "    if addresses is None:\n",
    "        return \n",
    "    match_start=0\n",
    "    for address in addresses:\n",
    "        if str(address).find(briaApiJson['providerDetails']['servicingProvider']['facilityName'].upper()) > -1:\n",
    "            addressFmt=str(address).replace(briaApiJson['providerDetails']['servicingProvider']['facilityName'].upper(),\" \")\n",
    "        else:\n",
    "            addressFmt=str(address)\n",
    "\n",
    "        varAddr1,varCity,varState,varZip = SplitAddress(addressFmt)\n",
    "\n",
    "        if varAddr1 == '' or  varCity == '' or varState == '' or varZip == '':\n",
    "            match_start=pipelineRawContent.find(varAddr1)\n",
    "            continue\n",
    "\n",
    "        if chkTokenPresent(pipelineRawContent,10,5,fieldKeys,'excludeAddress',str(address).upper(),None,match_start) is not None:\n",
    "            match_start=pipelineRawContent.find(varAddr1)            \n",
    "            continue\n",
    "        \n",
    "        if chkTokenPresent(pipelineRawContent,10,3,fieldKeys,'servicingProviderfacilityName',str(address).upper(),None,match_start) is not None:\n",
    "            briaApiJson['providerDetails']['servicingProvider']['address']['state'] = varState\n",
    "            briaApiJson['providerDetails']['servicingProvider']['address']['city'] = varCity\n",
    "            briaApiJson['providerDetails']['servicingProvider']['address']['zipCode'] = varZip\n",
    "            briaApiJson['providerDetails']['servicingProvider']['address']['addressLineOne'] = varAddr1\n",
    "            return\n",
    "\n",
    "        facilitySearch = PreProcessforExtractAddress(briaApiJson['providerDetails']['servicingProvider']['facilityName'].lower())\n",
    "        for match in re.finditer(facilitySearch, pipelineRawContent):\n",
    "            facilityPositionEnd = match.end()\n",
    "            facilityPositionStart = match.start()\n",
    "            #addressPos = pipelineRawContent.find((str(address)).lower())\n",
    "            #addressPosStart=address.match_start \n",
    "            #addressPosEnd=address.match_end\n",
    "            addressPosStart=pipelineRawContent.find(varAddr1)   \n",
    "            addressPosEnd=pipelineRawContent.find(varZip)+len(varZip)\n",
    "            try:\n",
    "                if  addressPosStart > facilityPositionStart:\n",
    "                    textBetween = pipelineRawContent[facilityPositionEnd:addressPosStart]\n",
    "                    if ( len(textBetween.split()) < 25) :\n",
    "                        briaApiJson['providerDetails']['servicingProvider']['address']['state'] = varState\n",
    "                        briaApiJson['providerDetails']['servicingProvider']['address']['city'] = varCity\n",
    "                        briaApiJson['providerDetails']['servicingProvider']['address']['zipCode'] = varZip\n",
    "                        briaApiJson['providerDetails']['servicingProvider']['address']['addressLineOne'] = varAddr1\n",
    "                        return                    \n",
    "                else:\n",
    "                    textBetween = pipelineRawContent[addressPosEnd :facilityPositionStart]\n",
    "                    if ( len(textBetween.split()) < 10) :\n",
    "                        briaApiJson['providerDetails']['servicingProvider']['address']['state'] = varState\n",
    "                        briaApiJson['providerDetails']['servicingProvider']['address']['city'] = varCity\n",
    "                        briaApiJson['providerDetails']['servicingProvider']['address']['zipCode'] = varZip\n",
    "                        briaApiJson['providerDetails']['servicingProvider']['address']['addressLineOne'] = varAddr1\n",
    "                        return                    \n",
    "                    \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    if briaApiJson['providerDetails']['servicingProvider']['address']['addressLineOne'] ==\"\":\n",
    "        for pipelineCustomkeyValuePair in pipelineCustomkeyValuePairs:\n",
    "            if pipelineCustomkeyValuePair['Name'] == 'facilityAddress':\n",
    "                varAddr1,varCity,varState,varZip = SplitAddress(pipelineCustomkeyValuePair['Value'])\n",
    "                if varAddr1 != '' and   varCity != '' and varState != '' and varZip != '':\n",
    "                    briaApiJson['providerDetails']['servicingProvider']['address']['state'] = varState\n",
    "                    briaApiJson['providerDetails']['servicingProvider']['address']['city'] = varCity\n",
    "                    briaApiJson['providerDetails']['servicingProvider']['address']['zipCode'] = varZip\n",
    "                    briaApiJson['providerDetails']['servicingProvider']['address']['addressLineOne'] = varAddr1\n",
    "                    return                \n",
    "    \n",
    "    getStateCode(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineRawContentdoc,pipelineOCRRawContent,pipelineCustomkeyValuePairs)\n",
    "\n",
    "def getGoogleMapsaddress(pipelineRawContent,briaApiJson):\n",
    "\n",
    "\n",
    "    cntBlank = 0\n",
    "    if briaApiJson['providerDetails']['servicingProvider']['facilityName'] == \"\":\n",
    "        cntBlank = cntBlank+1\n",
    "\n",
    "    if briaApiJson['providerDetails']['servicingProvider']['address']['addressLineOne'] == \"\":\n",
    "        cntBlank = cntBlank+1\n",
    "\n",
    "    if briaApiJson['providerDetails']['servicingProvider']['address']['city'] == \"\":\n",
    "        cntBlank = cntBlank+1\n",
    "\n",
    "    if briaApiJson['providerDetails']['servicingProvider']['address']['state'] == \"\":\n",
    "        cntBlank = cntBlank+1\n",
    "\n",
    "    if briaApiJson['providerDetails']['servicingProvider']['address']['zipCode'] == \"\":\n",
    "        cntBlank = cntBlank+1\n",
    "\n",
    "    if cntBlank > 2: # require atleast two pieces to proceed to google search\n",
    "        return\n",
    "\n",
    "    # Call google with Facility name and state code and get address, If address is empty but address line1, city, state is present in document , populate with what is returned by Google\n",
    "    addressText =  \" \".join([briaApiJson['providerDetails']['servicingProvider']['facilityName'] ,\n",
    "                            briaApiJson['providerDetails']['servicingProvider']['address']['addressLineOne'],\n",
    "                            briaApiJson['providerDetails']['servicingProvider']['address']['city'] ,\n",
    "                            briaApiJson['providerDetails']['servicingProvider']['address']['state'] ,\n",
    "                            briaApiJson['providerDetails']['servicingProvider']['address']['zipCode'] ])\n",
    "    (street_number,route_short_name,route_long_name,locality_short_name,\\\n",
    "        locality_long_name,administrative_area_level_1_short_name,\\\n",
    "            administrative_area_level_1_long_name,postal_code_short_name) = callGoogleMapsaddress(addressText)\n",
    "\n",
    "    if street_number is None:\n",
    "        return\n",
    "\n",
    "    if pipelineRawContent.find(street_number) > -1:\n",
    "        if (((pipelineRawContent.find(locality_short_name) > -1) or (pipelineRawContent.find(locality_long_name) > -1 )) and ((pipelineRawContent.find(administrative_area_level_1_short_name) > -1) or (pipelineRawContent.find(administrative_area_level_1_long_name) > -1 )))  \\\n",
    "        or (((pipelineRawContent.find(locality_short_name) > -1) or (pipelineRawContent.find(locality_long_name) > -1 )) and ((pipelineRawContent.find(postal_code_short_name) > -1))) \\\n",
    "        or ((pipelineRawContent.find(postal_code_short_name) > -1)                                                       and ((pipelineRawContent.find(administrative_area_level_1_short_name) > -1))): \n",
    "            briaApiJson['providerDetails']['servicingProvider']['address']['addressLineOne'] = \" \".join([street_number,route_long_name])\n",
    "            briaApiJson['providerDetails']['servicingProvider']['address']['city'] = locality_long_name\n",
    "            briaApiJson['providerDetails']['servicingProvider']['address']['state'] = administrative_area_level_1_short_name.upper()\n",
    "            briaApiJson['providerDetails']['servicingProvider']['address']['zipCode'] = postal_code_short_name\n",
    "\n",
    "\n",
    "\n",
    "def getRequestingProviderAddress(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineOCRRawContent,pipelineCustomkeyValuePairs):\n",
    "\n",
    "    if briaApiJson['providerDetails']['requestingProvider']['lastName'] ==\"\":\n",
    "        return\n",
    "\n",
    "    pipelineRawContent=PreProcessforExtractAddress(pipelineRawContent)\n",
    "    addresses = ExtractAddress(pipelineRawContent)\n",
    "    provAddressAnchors=[]\n",
    "    if briaApiJson['providerDetails']['requestingProvider']['lastName'] != '':\n",
    "        provAddressAnchors.append(briaApiJson['providerDetails']['requestingProvider']['lastName'].lower())\n",
    "\n",
    "    if briaApiJson['providerDetails']['requestingProvider']['npi'] != '':\n",
    "        provAddressAnchors.append(briaApiJson['providerDetails']['requestingProvider']['npi'].lower())\n",
    "\n",
    "    for providerSearch in provAddressAnchors:\n",
    "        \n",
    "        if addresses is None:\n",
    "            return \n",
    "        match_start=0\n",
    "        for address in addresses:\n",
    "\n",
    "            varAddr1,varCity,varState,varZip = SplitAddress(str(address))\n",
    "\n",
    "            if varAddr1 == '' or  varCity == '' or varState == '' or varZip == '':\n",
    "                match_start=address.match_start\n",
    "                continue\n",
    "\n",
    "            providerSearch = PreProcessforExtractAddress(providerSearch)\n",
    "            for match in re.finditer(providerSearch, pipelineRawContent):\n",
    "                providerPositionEnd = match.end()\n",
    "                providerPositionStart = match.start()\n",
    "                #addressPos = pipelineRawContent.find((str(address)).lower())\n",
    "                addressPosStart=pipelineRawContent.find(varAddr1)\n",
    "                try:\n",
    "                    if  addressPosStart > providerPositionStart:\n",
    "                        textBetween = pipelineRawContent[providerPositionEnd:addressPosStart]\n",
    "                        if ( len(textBetween.split()) < 5) :\n",
    "                            briaApiJson['providerDetails']['requestingProvider']['address']['state'] = varState\n",
    "                            briaApiJson['providerDetails']['requestingProvider']['address']['city'] = varCity\n",
    "                            briaApiJson['providerDetails']['requestingProvider']['address']['zipCode'] = varZip\n",
    "                            briaApiJson['providerDetails']['requestingProvider']['address']['addressLineOne'] = varAddr1\n",
    "                            return                    \n",
    "                    \n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "def findIPCMBestMatch(taxid,facilityName,npi,address,df):\n",
    "\n",
    "    provMatches = pd.DataFrame()\n",
    "    state = address['state'].upper()\n",
    "\n",
    "    zipcode =  address['zipCode'][0:5]\n",
    "\n",
    "    city =  address['city'].upper()\n",
    "    addressLineOne =  address['addressLineOne'].upper()\n",
    "    facilityName = facilityName.upper()\n",
    "\n",
    "    if addressLineOne != '' :\n",
    "        bldg_nm = addressLineOne.split(' ')[0]\n",
    "    \n",
    "    if state != '' and facilityName != '' and addressLineOne != '' and npi.isnumeric() and taxid.isnumeric() and city != '' and zipcode != '':\n",
    "        qry = \"(`FACILITY NAME` == @facilityName or PROV_NM == @facilityName or PROV_ALT_NM == @facilityName ) and STE_CD == @state and ADDRESS.str.startswith(@bldg_nm, na=False) and ADDRESS.str.contains(@city, na=False) and ADDRESS.str.contains(@zipcode, na=False) and NATL_PROV_ID == @npi and PROV_TAX_ID == @taxid\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('all 5 cases match')\n",
    "            if provMatches['FACILITY NAME'].nunique() == 1 and provMatches['ADDRESS'].nunique() == 1 :\n",
    "                return provMatches\n",
    "            if provMatches['ADDRESS'].nunique() == 1 :\n",
    "                return provMatches  \n",
    "    \n",
    "    if state != '' and addressLineOne != '' and npi.isnumeric() and taxid.isnumeric() and city != '' and zipcode != '':\n",
    "        qry = \"STE_CD == @state and ADDRESS.str.startswith(@bldg_nm, na=False) and ADDRESS.str.contains(@city, na=False) and ADDRESS.str.contains(@zipcode, na=False) and NATL_PROV_ID == @npi and PROV_TAX_ID == @taxid\" \n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('state, tax id, address, npi match')\n",
    "            if provMatches['FACILITY NAME'].nunique() == 1 and provMatches['ADDRESS'].nunique() == 1 :\n",
    "                return provMatches\n",
    "            if provMatches['ADDRESS'].nunique() == 1 :\n",
    "                return provMatches  \n",
    "    \n",
    "    if state != '' and facilityName != '' and addressLineOne != '' and taxid.isnumeric() and city != '' and zipcode != '':\n",
    "        qry = \"(`FACILITY NAME` == @facilityName or PROV_NM == @facilityName or PROV_ALT_NM == @facilityName ) and STE_CD == @state and ADDRESS.str.startswith(@bldg_nm, na=False) and ADDRESS.str.contains(@city, na=False) and ADDRESS.str.contains(@zipcode, na=False) and PROV_TAX_ID == @taxid\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('state, tax id, address, facility name match')\n",
    "            if provMatches['FACILITY NAME'].nunique() == 1 and provMatches['ADDRESS'].nunique() == 1 :\n",
    "                return provMatches\n",
    "            if provMatches['ADDRESS'].nunique() == 1 :\n",
    "                return provMatches\n",
    "    \n",
    "    if state != '' and facilityName != '' and npi.isnumeric() and taxid.isnumeric():\n",
    "        qry = \"(`FACILITY NAME` == @facilityName or PROV_NM == @facilityName or PROV_ALT_NM == @facilityName ) and STE_CD == @state and NATL_PROV_ID == @npi and PROV_TAX_ID == @taxid\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('state, tax id, npi, facility name match')\n",
    "            if provMatches['FACILITY NAME'].nunique() == 1 and provMatches['ADDRESS'].nunique() == 1 :\n",
    "                return provMatches\n",
    "            if provMatches['ADDRESS'].nunique() == 1 :\n",
    "                return provMatches\n",
    "    \n",
    "    if state != '' and facilityName != '' and addressLineOne != '' and npi.isnumeric() and city != '' and zipcode != '':\n",
    "        qry = \"(`FACILITY NAME` == @facilityName or PROV_NM == @facilityName or PROV_ALT_NM == @facilityName ) and STE_CD == @state and ADDRESS.str.startswith(@bldg_nm, na=False) and ADDRESS.str.contains(@city, na=False) and ADDRESS.str.contains(@zipcode, na=False) and NATL_PROV_ID == @npi\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('state, npi, address, facility name match')\n",
    "            if provMatches['FACILITY NAME'].nunique() == 1 and provMatches['ADDRESS'].nunique() == 1 :\n",
    "                return provMatches\n",
    "            if provMatches['ADDRESS'].nunique() == 1 :\n",
    "                return provMatches\n",
    "\n",
    "    if facilityName != '' and addressLineOne != '' and npi.isnumeric() and taxid.isnumeric() and city != '' and zipcode != '':\n",
    "        qry = \"(`FACILITY NAME` == @facilityName or PROV_NM == @facilityName or PROV_ALT_NM == @facilityName ) and ADDRESS.str.startswith(@bldg_nm, na=False) and ADDRESS.str.contains(@city, na=False) and ADDRESS.str.contains(@zipcode, na=False) and NATL_PROV_ID == @npi and PROV_TAX_ID == @taxid\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('tax id, address, npi, facility name match')\n",
    "            if provMatches['FACILITY NAME'].nunique() == 1 and provMatches['ADDRESS'].nunique() == 1 :\n",
    "                return provMatches\n",
    "            if provMatches['ADDRESS'].nunique() == 1 :\n",
    "                return provMatches\n",
    "\n",
    "    if taxid.isnumeric() and state != '' and addressLineOne != '' and city != '' and zipcode != '':\n",
    "        qry = \"(PROV_TAX_ID == @taxid ) and STE_CD == @state and ADDRESS.str.startswith(@bldg_nm, na=False) and ADDRESS.str.contains(@city, na=False) and ADDRESS.str.contains(@zipcode, na=False)\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('address, tax ID and state match')\n",
    "            if provMatches['FACILITY NAME'].nunique() == 1 and provMatches['ADDRESS'].nunique() == 1 :\n",
    "                return provMatches\n",
    "            if provMatches['ADDRESS'].nunique() == 1 :\n",
    "                return provMatches\n",
    "    \n",
    "    if taxid.isnumeric() and npi.isnumeric() and state != '':\n",
    "        qry = \"(PROV_TAX_ID == @taxid ) and STE_CD == @state and NATL_PROV_ID == @npi\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('tax ID, npi and state match')\n",
    "            if provMatches['FACILITY NAME'].nunique() == 1 and provMatches['ADDRESS'].nunique() == 1 :\n",
    "                return provMatches\n",
    "            if provMatches['ADDRESS'].nunique() == 1 :\n",
    "                return provMatches\n",
    "    \n",
    "    if facilityName != '' and taxid.isnumeric() and state != '':\n",
    "        qry = \"(`FACILITY NAME` == @facilityName or PROV_NM == @facilityName or PROV_ALT_NM == @facilityName ) and (PROV_TAX_ID == @taxid ) and STE_CD == @state\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('tax ID, facility name and state match')\n",
    "            if provMatches['FACILITY NAME'].nunique() == 1 and provMatches['ADDRESS'].nunique() == 1 :\n",
    "                return provMatches\n",
    "            if provMatches['ADDRESS'].nunique() == 1 :\n",
    "                return provMatches\n",
    "    \n",
    "    if npi.isnumeric() and state != '' and addressLineOne != '' and city != '' and zipcode != '' :\n",
    "        qry = \"ADDRESS.str.startswith(@bldg_nm, na=False) and ADDRESS.str.contains(@city, na=False) and ADDRESS.str.contains(@zipcode, na=False) and (NATL_PROV_ID == @npi ) and STE_CD == @state\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('Address, NPI and State match')\n",
    "            if provMatches['FACILITY NAME'].nunique() == 1 and provMatches['ADDRESS'].nunique() == 1 :\n",
    "                return provMatches    \n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1:\n",
    "                return provMatches\n",
    "    \n",
    "    if npi.isnumeric() and state != '' and facilityName != '':\n",
    "        qry = \"(`FACILITY NAME` == @facilityName or PROV_NM == @facilityName or PROV_ALT_NM == @facilityName ) and (NATL_PROV_ID == @npi ) and STE_CD == @state\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('facility name, NPI and State match')\n",
    "            if provMatches['FACILITY NAME'].nunique() == 1 and provMatches['ADDRESS'].nunique() == 1 :\n",
    "                return provMatches    \n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1:\n",
    "                return provMatches\n",
    "\n",
    "    if taxid.isnumeric() and npi.isnumeric() and addressLineOne != '' and city != '' and zipcode != '':\n",
    "        qry = \"(PROV_TAX_ID == @taxid ) and (NATL_PROV_ID == @npi) and ADDRESS.str.startswith(@bldg_nm, na=False) and ADDRESS.str.contains(@city, na=False) and ADDRESS.str.contains(@zipcode, na=False)\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('address, tax ID and npi match')\n",
    "            if provMatches['FACILITY NAME'].nunique() == 1 and provMatches['ADDRESS'].nunique() == 1 :\n",
    "                return provMatches\n",
    "            if provMatches['ADDRESS'].nunique() == 1 :\n",
    "                return provMatches\n",
    "\n",
    "    if taxid.isnumeric() and addressLineOne != '' and facilityName != '' and city != '' and zipcode != '':\n",
    "        qry = \"(`FACILITY NAME` == @facilityName or PROV_NM == @facilityName or PROV_ALT_NM == @facilityName ) and (PROV_TAX_ID == @taxid ) and ADDRESS.str.startswith(@bldg_nm, na=False) and ADDRESS.str.contains(@city, na=False) and ADDRESS.str.contains(@zipcode, na=False)\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('tax id, address, facility name match')\n",
    "            if provMatches['FACILITY NAME'].nunique() == 1 and provMatches['ADDRESS'].nunique() == 1 :\n",
    "                return provMatches    \n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1:\n",
    "                return provMatches\n",
    "\n",
    "    if npi.isnumeric() and taxid.isnumeric() and facilityName != '':\n",
    "        qry = \"(`FACILITY NAME` == @facilityName or PROV_NM == @facilityName or PROV_ALT_NM == @facilityName ) and (NATL_PROV_ID == @npi ) and (PROV_TAX_ID == @taxid )\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('tax id, npi, facility name match')\n",
    "            if provMatches['FACILITY NAME'].nunique() == 1 and provMatches['ADDRESS'].nunique() == 1 :\n",
    "                return provMatches    \n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1:\n",
    "                return provMatches\n",
    "\n",
    "    if npi.isnumeric() and addressLineOne != '' and facilityName != '' and city != '' and zipcode != '':\n",
    "        qry = \"(`FACILITY NAME` == @facilityName or PROV_NM == @facilityName or PROV_ALT_NM == @facilityName ) and (NATL_PROV_ID == @npi ) and ADDRESS.str.startswith(@bldg_nm, na=False) and ADDRESS.str.contains(@city, na=False) and ADDRESS.str.contains(@zipcode, na=False)\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('address, npi, facility name match')\n",
    "            if provMatches['FACILITY NAME'].nunique() == 1 and provMatches['ADDRESS'].nunique() == 1 :\n",
    "                return provMatches    \n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1:\n",
    "                return provMatches\n",
    "    \n",
    "    if addressLineOne != '' and state != '' and facilityName != '' and city != '' and zipcode != '':\n",
    "        facility_name = facilityName.split(' ')[0]\n",
    "        qry = \"ADDRESS.str.startswith(@bldg_nm, na=False) and ADDRESS.str.contains(@city, na=False) and ADDRESS.str.contains(@zipcode, na=False) and STE_CD == @state and `FACILITY NAME`.str.contains(@facility_name, na=False)\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('Building number, state, and facility name match')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['ADDRESS'].nunique() ==1 :\n",
    "                return provMatches  \n",
    "    \n",
    "    if npi.isnumeric() and taxid.isnumeric() :\n",
    "        qry = \"(NATL_PROV_ID == @npi ) and PROV_TAX_ID == @taxid\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('NPI and Tax ID Match')\n",
    "            if provMatches['FACILITY NAME'].nunique() == 1 and provMatches['ADDRESS'].nunique() == 1 :\n",
    "                return provMatches\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1:\n",
    "                return provMatches \n",
    "    \n",
    "    if taxid.isnumeric() and npi.isnumeric():\n",
    "        qry = \"(NATL_PROV_ID == @npi ) and PROV_TAX_ID == @taxid\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('tax ID and npi match')\n",
    "            if provMatches['FACILITY NAME'].nunique() == 1 and provMatches['ADDRESS'].nunique() == 1 :\n",
    "                return provMatches\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1:\n",
    "                return provMatches\n",
    "\n",
    "    if taxid.isnumeric() and state != '':\n",
    "        qry = \"(PROV_TAX_ID == @taxid ) and STE_CD == @state\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('tax ID and state match')\n",
    "            if provMatches['FACILITY NAME'].nunique() == 1 and provMatches['ADDRESS'].nunique() == 1 :\n",
    "                return provMatches\n",
    "            if provMatches['ADDRESS'].nunique() == 1 :\n",
    "                return provMatches                \n",
    "    \n",
    "    if npi.isnumeric() and state != '':\n",
    "        qry = \"(NATL_PROV_ID == @npi ) and STE_CD == @state\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('NPI and State match')\n",
    "            if provMatches['FACILITY NAME'].nunique() == 1 and provMatches['ADDRESS'].nunique() == 1 :\n",
    "                return provMatches    \n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1:\n",
    "                return provMatches     \n",
    "\n",
    "    if state != '' and facilityName != '':\n",
    "        qry = \"(`FACILITY NAME` == @facilityName or PROV_NM == @facilityName or PROV_ALT_NM == @facilityName ) and STE_CD == @state\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('facility name exact and state match')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['ADDRESS'].nunique() ==1 : \n",
    "                return provMatches                \n",
    "\n",
    "    if facilityName != '' and taxid.isnumeric():\n",
    "        qry = \"(`FACILITY NAME` == @facilityName or PROV_NM == @facilityName or PROV_ALT_NM == @facilityName ) and PROV_TAX_ID == @taxid\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('FACILITY NAME contains facility name and tax id match')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['ADDRESS'].nunique() ==1 :\n",
    "                return provMatches\n",
    "    \n",
    "    if facilityName != '' and taxid.isnumeric():\n",
    "        qry = \"`FACILITY NAME`.str.contains(@facilityName, na=False) and PROV_TAX_ID == @taxid\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('FACILITY NAME contains facility name and tax id match')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['ADDRESS'].nunique() ==1 :\n",
    "                return provMatches\n",
    "\n",
    "    if facilityName != '' and taxid.isnumeric():\n",
    "        qry = \"PROV_ALT_NM.str.contains(@facilityName, na=False) and PROV_TAX_ID == @taxid\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('PROV_ALT_NM contains facility name and tax id match')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['ADDRESS'].nunique() ==1 :\n",
    "                return provMatches\n",
    "    \n",
    "    if facilityName != '' and taxid.isnumeric():\n",
    "        qry = \"PROV_NM.str.contains(@facilityName, na=False) and PROV_TAX_ID == @taxid\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('PROV_NM contains facility name and tax id match')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['ADDRESS'].nunique() ==1 :\n",
    "                return provMatches\n",
    "  \n",
    "    \n",
    "    if facilityName != '' and npi.isnumeric():\n",
    "        qry = \"(`FACILITY NAME` == @facilityName or PROV_NM == @facilityName or PROV_ALT_NM == @facilityName ) and NATL_PROV_ID == @npi\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('exact facility name match and npi match')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['ADDRESS'].nunique() ==1 :\n",
    "                return provMatches\n",
    "\n",
    "    if facilityName != '' and npi.isnumeric():\n",
    "        qry = \"`FACILITY NAME`.str.contains(@facilityName, na=False) and NATL_PROV_ID == @npi\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('FACILITY NAME contains facility name and npi')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['ADDRESS'].nunique() ==1 :\n",
    "                return provMatches\n",
    "\n",
    "    if facilityName != '' and npi.isnumeric():\n",
    "        qry = \"PROV_ALT_NM.str.contains(@facilityName, na=False) and NATL_PROV_ID == @npi\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('PROV_ALT_NM contains facility name and npi')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['ADDRESS'].nunique() ==1 :\n",
    "                return provMatches\n",
    "    \n",
    "    if facilityName != '' and npi.isnumeric():\n",
    "        qry = \"PROV_NM.str.contains(@facilityName, na=False) and NATL_PROV_ID == @npi\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('PROV_NM contains facility name and npi')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['ADDRESS'].nunique() ==1 :\n",
    "                return provMatches\n",
    "\n",
    "    if addressLineOne != '' and state != ''  and city != '' and zipcode != '':\n",
    "        qry = \"ADDRESS.str.startswith(@bldg_nm, na=False) and STE_CD == @state and ADDRESS.str.contains(@city, na=False) and ADDRESS.str.contains(@zipcode, na=False)\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('building number, state, and city match')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['ADDRESS'].nunique() ==1 :\n",
    "                return provMatches\n",
    "    \n",
    "    if addressLineOne != '' and taxid.isnumeric() and city != '' and zipcode != '':\n",
    "        qry = \"ADDRESS.str.startswith(@bldg_nm, na=False) and ADDRESS.str.contains(@city, na=False) and PROV_TAX_ID == @taxid and ADDRESS.str.contains(@zipcode, na=False)\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('tax id, address match')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['ADDRESS'].nunique() ==1 :\n",
    "                return provMatches\n",
    "\n",
    "    if addressLineOne != '' and facilityName != '' and city != '' and zipcode != '':\n",
    "        qry = \"ADDRESS.str.startswith(@bldg_nm, na=False) and ADDRESS.str.contains(@city, na=False) and ADDRESS.str.contains(@zipcode, na=False) and (`FACILITY NAME` == @facilityName or PROV_NM == @facilityName or PROV_ALT_NM == @facilityName )\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('address, facility name match')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['ADDRESS'].nunique() ==1 :\n",
    "                return provMatches\n",
    "\n",
    "    if addressLineOne != '' and npi.isnumeric() and city != '' and zipcode != '':\n",
    "        qry = \"ADDRESS.str.startswith(@bldg_nm, na=False) and ADDRESS.str.contains(@city, na=False) and ADDRESS.str.contains(@zipcode, na=False) and NATL_PROV_ID == @npi\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('npi, address match')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['ADDRESS'].nunique() ==1 :\n",
    "                return provMatches\n",
    "    \n",
    "    if state != '' and facilityName != '':\n",
    "        qry = \"`FACILITY NAME`.str.contains(@facilityName, na=False) and STE_CD == @state\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('FACILITY NAME contains facility name and state match')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['ADDRESS'].nunique() ==1 :\n",
    "                return provMatches\n",
    "\n",
    "    if state != '' and facilityName != '':\n",
    "        qry = \"PROV_ALT_NM.str.contains(@facilityName, na=False) and STE_CD == @state\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('PROV_ALT_NM contains facility name and state match')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['ADDRESS'].nunique() ==1 :\n",
    "                return provMatches\n",
    "    \n",
    "    if state != '' and facilityName != '':\n",
    "        qry = \"PROV_NM.str.contains(@facilityName, na=False) and STE_CD == @state\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('PROV_NM contains facility name and state match')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['ADDRESS'].nunique() ==1 :\n",
    "                return provMatches\n",
    "\n",
    "    if addressLineOne != '' and zipcode != '' and city != '':\n",
    "        qry = \"ADDRESS.str.startswith(@bldg_nm, na=False) and ADDRESS.str.contains(@city, na=False) and ADDRESS.str.contains(@zipcode, na=False)\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('building number, city and zipcode match')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['ADDRESS'].nunique() ==1 :\n",
    "                return provMatches            \n",
    "           \n",
    "    return(provMatches)\n",
    "\n",
    "def findIPCMBestMatchCPF(taxid,facilityName,npi,address,df):\n",
    "\n",
    "    provMatches = pd.DataFrame()\n",
    "    state = address['state'].upper()\n",
    "\n",
    "    zipcode =  address['zipCode'][0:5]\n",
    "\n",
    "    city =  address['city'].upper()\n",
    "    addressLineOne =  address['addressLineOne'].upper()\n",
    "    facilityName = re.sub(\"[^0-9a-zA-Z]+\", \"\", facilityName.upper())\n",
    "\n",
    "    if addressLineOne != '' :\n",
    "        bldg_nm = addressLineOne.split(' ')[0]\n",
    "\n",
    "    df['PROV_NM_FMT']   = df['PROV_NM'].str.replace('\\W', '', regex=True)  #temporary, can be done in df building itself\n",
    "    df['PROV_ALT_NM_FMT']   = df['PROV_ALT_NM'].str.replace('\\W', '', regex=True) #temporary, can be done in df building itself\n",
    "    \n",
    "    if state != '' and facilityName != '' and addressLineOne != '' and npi.isnumeric() and taxid.isnumeric() and city != '' and zipcode != '':\n",
    "        qry = \"(PROV_NM_FMT == @facilityName or PROV_ALT_NM_FMT == @facilityName ) and STE_CD == @state and FRST_LN_ADDR.str.startswith(@bldg_nm, na=False) and CITY_NM.str.contains(@city, na=False) and ZIP_CD.str.contains(@zipcode, na=False) and NATL_PROV_ID == @npi and PROV_TAX_ID == @taxid\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('all 5 cases match')\n",
    "            if provMatches['PROV_NM_FMT'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() == 1 :\n",
    "                return provMatches\n",
    "    \n",
    "    if state != '' and addressLineOne != '' and npi.isnumeric() and taxid.isnumeric() and city != '' and zipcode != '':\n",
    "        qry = \"STE_CD == @state and FRST_LN_ADDR.str.startswith(@bldg_nm, na=False) and CITY_NM.str.contains(@city, na=False) and ZIP_CD.str.contains(@zipcode, na=False) and NATL_PROV_ID == @npi and PROV_TAX_ID == @taxid\" \n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('state, tax id, address, npi match')\n",
    "            if provMatches['PROV_NM_FMT'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() == 1 :\n",
    "                return provMatches\n",
    "    \n",
    "    if state != '' and facilityName != '' and addressLineOne != '' and taxid.isnumeric() and city != '' and zipcode != '':\n",
    "        qry = \"(PROV_NM_FMT == @facilityName or PROV_ALT_NM_FMT == @facilityName ) and STE_CD == @state and FRST_LN_ADDR.str.startswith(@bldg_nm, na=False) and CITY_NM.str.contains(@city, na=False) and ZIP_CD.str.contains(@zipcode, na=False) and PROV_TAX_ID == @taxid\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('state, tax id, address, facility name match')\n",
    "            if provMatches['PROV_NM_FMT'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() == 1 :\n",
    "                return provMatches\n",
    "    \n",
    "    if state != '' and facilityName != '' and npi.isnumeric() and taxid.isnumeric():\n",
    "        qry = \"(PROV_NM_FMT == @facilityName or PROV_ALT_NM_FMT == @facilityName ) and STE_CD == @state and NATL_PROV_ID == @npi and PROV_TAX_ID == @taxid\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('state, tax id, npi, facility name match')\n",
    "            if provMatches['PROV_NM_FMT'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() == 1 :\n",
    "                return provMatches\n",
    "    \n",
    "    if state != '' and facilityName != '' and addressLineOne != '' and npi.isnumeric() and city != '' and zipcode != '':\n",
    "        qry = \"(PROV_NM_FMT == @facilityName or PROV_ALT_NM_FMT == @facilityName ) and STE_CD == @state and FRST_LN_ADDR.str.startswith(@bldg_nm, na=False) and CITY_NM.str.contains(@city, na=False) and ZIP_CD.str.contains(@zipcode, na=False) and NATL_PROV_ID == @npi\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('state, npi, address, facility name match')\n",
    "            if provMatches['PROV_NM_FMT'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() == 1 :\n",
    "                return provMatches\n",
    "\n",
    "    if facilityName != '' and addressLineOne != '' and npi.isnumeric() and taxid.isnumeric() and city != '' and zipcode != '':\n",
    "        qry = \"(PROV_NM_FMT == @facilityName or PROV_ALT_NM_FMT == @facilityName ) and FRST_LN_ADDR.str.startswith(@bldg_nm, na=False) and CITY_NM.str.contains(@city, na=False) and ZIP_CD.str.contains(@zipcode, na=False) and NATL_PROV_ID == @npi and PROV_TAX_ID == @taxid\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('tax id, address, npi, facility name match')\n",
    "            if provMatches['PROV_NM_FMT'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() == 1 :\n",
    "                return provMatches\n",
    "\n",
    "    if taxid.isnumeric() and state != '' and addressLineOne != '' and city != '' and zipcode != '':\n",
    "        qry = \"(PROV_TAX_ID == @taxid ) and STE_CD == @state and FRST_LN_ADDR.str.startswith(@bldg_nm, na=False) and CITY_NM.str.contains(@city, na=False) and ZIP_CD.str.contains(@zipcode, na=False)\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('address, tax ID and state match')\n",
    "            if provMatches['PROV_NM_FMT'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() == 1 :\n",
    "                return provMatches\n",
    "    \n",
    "    if taxid.isnumeric() and npi.isnumeric() and state != '':\n",
    "        qry = \"(PROV_TAX_ID == @taxid ) and STE_CD == @state and NATL_PROV_ID == @npi\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('tax ID, npi and state match')\n",
    "            if provMatches['PROV_NM_FMT'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() == 1 :\n",
    "                return provMatches\n",
    "    \n",
    "    if facilityName != '' and taxid.isnumeric() and state != '':\n",
    "        qry = \"(PROV_NM_FMT == @facilityName or PROV_ALT_NM_FMT == @facilityName ) and (PROV_TAX_ID == @taxid ) and STE_CD == @state\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('tax ID, facility name and state match')\n",
    "            if provMatches['PROV_NM_FMT'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() == 1 :\n",
    "                return provMatches\n",
    "    \n",
    "    if npi.isnumeric() and state != '' and addressLineOne != '' and city != '' and zipcode != '' :\n",
    "        qry = \"FRST_LN_ADDR.str.startswith(@bldg_nm, na=False) and CITY_NM.str.contains(@city, na=False) and ZIP_CD.str.contains(@zipcode, na=False) and (NATL_PROV_ID == @npi ) and STE_CD == @state\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('Address, NPI and State match')\n",
    "            if provMatches['PROV_NM_FMT'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() == 1 :\n",
    "                return provMatches    \n",
    "    \n",
    "    if npi.isnumeric() and state != '' and facilityName != '':\n",
    "        qry = \"(PROV_NM_FMT == @facilityName or PROV_ALT_NM_FMT == @facilityName ) and (NATL_PROV_ID == @npi ) and STE_CD == @state\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('facility name, NPI and State match')\n",
    "            if provMatches['PROV_NM_FMT'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() == 1 :\n",
    "                return provMatches    \n",
    "\n",
    "    if taxid.isnumeric() and npi.isnumeric() and addressLineOne != '' and city != '' and zipcode != '':\n",
    "        qry = \"(PROV_TAX_ID == @taxid ) and (NATL_PROV_ID == @npi) and FRST_LN_ADDR.str.startswith(@bldg_nm, na=False) and CITY_NM.str.contains(@city, na=False) and ZIP_CD.str.contains(@zipcode, na=False)\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('address, tax ID and npi match')\n",
    "            if provMatches['PROV_NM_FMT'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() == 1 :\n",
    "                return provMatches\n",
    "\n",
    "    if taxid.isnumeric() and addressLineOne != '' and facilityName != '' and city != '' and zipcode != '':\n",
    "        qry = \"(PROV_NM_FMT == @facilityName or PROV_ALT_NM_FMT == @facilityName ) and (PROV_TAX_ID == @taxid ) and FRST_LN_ADDR.str.startswith(@bldg_nm, na=False) and CITY_NM.str.contains(@city, na=False) and ZIP_CD.str.contains(@zipcode, na=False)\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('tax id, address, facility name match')\n",
    "            if provMatches['PROV_NM_FMT'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() == 1 :\n",
    "                return provMatches    \n",
    "\n",
    "    if npi.isnumeric() and taxid.isnumeric() and facilityName != '':\n",
    "        qry = \"(PROV_NM_FMT == @facilityName or PROV_ALT_NM_FMT == @facilityName ) and (NATL_PROV_ID == @npi ) and (PROV_TAX_ID == @taxid )\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('tax id, npi, facility name match')\n",
    "            if provMatches['PROV_NM_FMT'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() == 1 :\n",
    "                return provMatches    \n",
    "\n",
    "    if npi.isnumeric() and addressLineOne != '' and facilityName != '' and city != '' and zipcode != '':\n",
    "        qry = \"(PROV_NM_FMT == @facilityName or PROV_ALT_NM_FMT == @facilityName ) and (NATL_PROV_ID == @npi ) and FRST_LN_ADDR.str.startswith(@bldg_nm, na=False) and CITY_NM.str.contains(@city, na=False) and ZIP_CD.str.contains(@zipcode, na=False)\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('address, npi, facility name match')\n",
    "            if provMatches['PROV_NM_FMT'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() == 1 :\n",
    "                return provMatches    \n",
    "    \n",
    "    if addressLineOne != '' and state != '' and facilityName != '' and city != '' and zipcode != '':\n",
    "        facility_name = facilityName.split(' ')[0]\n",
    "        qry = \"FRST_LN_ADDR.str.startswith(@bldg_nm, na=False) and CITY_NM.str.contains(@city, na=False) and ZIP_CD.str.contains(@zipcode, na=False) and STE_CD == @state\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('Building number, state, and facility name match')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() ==1 :\n",
    "                return provMatches  \n",
    "    \n",
    "    if npi.isnumeric() and taxid.isnumeric() :\n",
    "        qry = \"(NATL_PROV_ID == @npi ) and PROV_TAX_ID == @taxid\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('NPI and Tax ID Match')\n",
    "            if provMatches['PROV_NM_FMT'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() == 1 :\n",
    "                return provMatches\n",
    "    \n",
    "    if taxid.isnumeric() and npi.isnumeric():\n",
    "        qry = \"(NATL_PROV_ID == @npi ) and PROV_TAX_ID == @taxid\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('tax ID and npi match')\n",
    "            if provMatches['PROV_NM_FMT'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() == 1 :\n",
    "                return provMatches\n",
    "\n",
    "    if taxid.isnumeric() and state != '':\n",
    "        qry = \"(PROV_TAX_ID == @taxid ) and STE_CD == @state\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('tax ID and state match')\n",
    "            if provMatches['PROV_NM_FMT'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() == 1 :\n",
    "                return provMatches\n",
    "    \n",
    "    if npi.isnumeric() and state != '':\n",
    "        qry = \"(NATL_PROV_ID == @npi ) and STE_CD == @state\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('NPI and State match')\n",
    "            if provMatches['PROV_NM_FMT'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() == 1 :\n",
    "                return provMatches    \n",
    "\n",
    "    if state != '' and facilityName != '':\n",
    "        qry = \"(PROV_NM_FMT == @facilityName or PROV_ALT_NM_FMT == @facilityName ) and STE_CD == @state\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('facility name exact and state match')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() ==1 : \n",
    "                return provMatches                \n",
    "\n",
    "    if facilityName != '' and taxid.isnumeric():\n",
    "        qry = \"(PROV_NM_FMT == @facilityName or PROV_ALT_NM_FMT == @facilityName ) and PROV_TAX_ID == @taxid\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('FACILITY NAME contains facility name and tax id match')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() ==1 :\n",
    "                return provMatches\n",
    "    \n",
    "    if facilityName != '' and taxid.isnumeric():\n",
    "        qry = \"PROV_ALT_NM_FMT.str.contains(@facilityName, na=False) and PROV_TAX_ID == @taxid\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('PROV_ALT_NM_FMT contains facility name and tax id match')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() ==1 :\n",
    "                return provMatches\n",
    "    \n",
    "    if facilityName != '' and taxid.isnumeric():\n",
    "        qry = \"PROV_NM_FMT.str.contains(@facilityName, na=False) and PROV_TAX_ID == @taxid\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('PROV_NM_FMT contains facility name and tax id match')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() ==1 :\n",
    "                return provMatches\n",
    "  \n",
    "    \n",
    "    if facilityName != '' and npi.isnumeric():\n",
    "        qry = \"(PROV_NM_FMT == @facilityName or PROV_ALT_NM_FMT == @facilityName ) and NATL_PROV_ID == @npi\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('exact facility name match and npi match')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() ==1 :\n",
    "                return provMatches\n",
    "\n",
    "    if facilityName != '' and npi.isnumeric():\n",
    "        qry = \"PROV_ALT_NM_FMT.str.contains(@facilityName, na=False) and NATL_PROV_ID == @npi\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('PROV_ALT_NM_FMT contains facility name and npi')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() ==1 :\n",
    "                return provMatches\n",
    "    \n",
    "    if facilityName != '' and npi.isnumeric():\n",
    "        qry = \"PROV_NM_FMT.str.contains(@facilityName, na=False) and NATL_PROV_ID == @npi\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('PROV_NM_FMT contains facility name and npi')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() ==1 :\n",
    "                return provMatches\n",
    "\n",
    "    if addressLineOne != '' and state != ''  and city != '' and zipcode != '':\n",
    "        qry = \"FRST_LN_ADDR.str.startswith(@bldg_nm, na=False) and STE_CD == @state and CITY_NM.str.contains(@city, na=False) and ZIP_CD.str.contains(@zipcode, na=False)\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('building number, state, and city match')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() ==1 :\n",
    "                return provMatches\n",
    "    \n",
    "    if addressLineOne != '' and taxid.isnumeric() and city != '' and zipcode != '':\n",
    "        qry = \"FRST_LN_ADDR.str.startswith(@bldg_nm, na=False) and CITY_NM.str.contains(@city, na=False) and PROV_TAX_ID == @taxid and ZIP_CD.str.contains(@zipcode, na=False)\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('tax id, address match')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() ==1 :\n",
    "                return provMatches\n",
    "\n",
    "    if addressLineOne != '' and facilityName != '' and city != '' and zipcode != '':\n",
    "        qry = \"FRST_LN_ADDR.str.startswith(@bldg_nm, na=False) and CITY_NM.str.contains(@city, na=False) and ZIP_CD.str.contains(@zipcode, na=False) and (PROV_NM_FMT == @facilityName or PROV_ALT_NM_FMT == @facilityName )\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('address, facility name match')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() ==1 :\n",
    "                return provMatches\n",
    "\n",
    "    if addressLineOne != '' and npi.isnumeric() and city != '' and zipcode != '':\n",
    "        qry = \"FRST_LN_ADDR.str.startswith(@bldg_nm, na=False) and CITY_NM.str.contains(@city, na=False) and ZIP_CD.str.contains(@zipcode, na=False) and NATL_PROV_ID == @npi\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('npi, address match')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() ==1 :\n",
    "                return provMatches\n",
    "  \n",
    "    if state != '' and facilityName != '':\n",
    "        qry = \"PROV_ALT_NM_FMT.str.contains(@facilityName, na=False) and STE_CD == @state\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('PROV_ALT_NM_FMT contains facility name and state match')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() ==1 :\n",
    "                return provMatches\n",
    "    \n",
    "    if state != '' and facilityName != '':\n",
    "        qry = \"PROV_NM_FMT.str.contains(@facilityName, na=False) and STE_CD == @state\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('PROV_NM_FMT contains facility name and state match')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() ==1 :\n",
    "                return provMatches\n",
    "\n",
    "     \n",
    "    if addressLineOne != '' and zipcode != '' and city != '':\n",
    "        qry = \"FRST_LN_ADDR.str.startswith(@bldg_nm, na=False) and CITY_NM.str.contains(@city, na=False) and ZIP_CD.str.contains(@zipcode, na=False)\"\n",
    "        provMatches = df.query(qry)\n",
    "        if len(provMatches.index > 0):\n",
    "            print('building number, city and zipcode match')\n",
    "            if provMatches['PROV_TAX_ID'].nunique() == 1 and provMatches['FRST_LN_ADDR'].nunique() ==1 :\n",
    "                return provMatches            \n",
    "           \n",
    "    return(provMatches)\n",
    "\n",
    "def getIPCMValues(ipcmgrid,briaApiJson,fieldKeys):\n",
    "    \n",
    "    df = readIPCM(ipcmgrid,fieldKeys)\n",
    "    taxid = briaApiJson['providerDetails']['servicingProvider']['tin']\n",
    "    facilityName = briaApiJson['providerDetails']['servicingProvider']['facilityName']\n",
    "    npi = briaApiJson['providerDetails']['servicingProvider']['npi']\n",
    "    address = briaApiJson['providerDetails']['servicingProvider']['address']\n",
    "\n",
    "    provMatches = findIPCMBestMatch(taxid,facilityName,npi,address,df)\n",
    "    briaApiJson['additionalProviderDetails']['emrAvailable'] = 'N' \n",
    "    \n",
    "    if len(provMatches.index) > 0:\n",
    "        \n",
    "        prov_TaxID = provMatches['PROV_TAX_ID'].dropna().unique()\n",
    "        if len(prov_TaxID) == 1:\n",
    "            briaApiJson['additionalProviderDetails']['tin'] = prov_TaxID[0]\n",
    "\n",
    "        provNM = provMatches['PROV_NM'].dropna().unique()\n",
    "        facilityName =  provMatches['FACILITY NAME'].dropna().unique()\n",
    "        if len(provNM) == 1 and   len(provNM[0].strip()) > 3 :\n",
    "            briaApiJson['additionalProviderDetails']['facilityName'] = provNM[0]\n",
    "        elif (len(facilityName) ==1) and (len(facilityName[0].strip())) > 3 :\n",
    "            briaApiJson['additionalProviderDetails']['facilityName'] = facilityName[0]\n",
    "\n",
    "        provaddress = provMatches['ADDRESS'].dropna().unique()\n",
    "        if len(provaddress) == 1:\n",
    "            ipcmAddresses = PreProcessforExtractAddress (provaddress[0])\n",
    "            ipcmAddresses = ExtractAddress(ipcmAddresses)\n",
    "            if ipcmAddresses is not None:\n",
    "                for addr in ipcmAddresses:\n",
    "                    try:\n",
    "                        varAddr1,varCity,varState,varZip = SplitAddress(str(addr).upper().replace(\"|\",\" \").replace(\"#\",\" \"))\n",
    "                        briaApiJson['additionalProviderDetails']['address']['state'] = varState\n",
    "                        briaApiJson['additionalProviderDetails']['address']['city'] = varCity\n",
    "                        briaApiJson['additionalProviderDetails']['address']['zipCode'] = varZip\n",
    "                        briaApiJson['additionalProviderDetails']['address']['addressLineOne'] = varAddr1\n",
    "                    except Exception as ex:\n",
    "                        logging.info('FACE SHEET 2827 : ipcm grid address  extraction failure : %s ', str(ex))\n",
    "                        pass\n",
    "                qry = \"ADDRESS == @provaddress[0]\"\n",
    "                emrMatches = provMatches.query(qry)\n",
    "\n",
    "                if len(emrMatches.index) > 0:\n",
    "                    emr = str(emrMatches['EMR AVAILABLE'].dropna().unique()[0])\n",
    "                    briaApiJson['additionalProviderDetails']['emrAvailable'] = getEMR(emr)\n",
    "\n",
    "\n",
    "def getIPCMValuesCPF(ipcmgridCPF,briaApiJson,fieldKeys):\n",
    "    \n",
    "    df = readIPCMCPF(ipcmgridCPF,fieldKeys)\n",
    "    taxid = briaApiJson['providerDetails']['servicingProvider']['tin']\n",
    "    facilityName = briaApiJson['providerDetails']['servicingProvider']['facilityName']\n",
    "    npi = briaApiJson['providerDetails']['servicingProvider']['npi']\n",
    "    address = briaApiJson['providerDetails']['servicingProvider']['address']\n",
    "\n",
    "    provMatches = findIPCMBestMatchCPF(taxid,facilityName,npi,address,df)\n",
    "    if len(provMatches.index) > 0:\n",
    "        \n",
    "        prov_TaxID = provMatches['PROV_TAX_ID'].dropna().unique()\n",
    "        provNM = provMatches['PROV_NM'].dropna().unique()\n",
    "        provNMAlt =  provMatches['PROV_ALT_NM'].dropna().unique()\n",
    "        provaddress = provMatches['FRST_LN_ADDR'].dropna().unique()\n",
    "        varState = provMatches['STE_CD'].dropna().unique()\n",
    "        varZip = provMatches['ZIP_CD'].dropna().unique()\n",
    "        varCity = provMatches['CITY_NM'].dropna().unique()\n",
    "\n",
    "        if len(prov_TaxID) == 1 and len(provaddress) == 1 :\n",
    "            print(\"provaddress taken from CPF\")\n",
    "            briaApiJson['additionalProviderDetails']['tin'] = prov_TaxID[0]\n",
    "\n",
    "            if len(provNM) == 1 :\n",
    "                briaApiJson['additionalProviderDetails']['facilityName'] = provNM[0].lower()\n",
    "            elif (len(provNMAlt) ==1):\n",
    "                briaApiJson['additionalProviderDetails']['facilityName'] = provNMAlt[0].lower()\n",
    "\n",
    "            briaApiJson['additionalProviderDetails']['address']['state'] = varState[0]\n",
    "            briaApiJson['additionalProviderDetails']['address']['city'] = varCity[0]\n",
    "            briaApiJson['additionalProviderDetails']['address']['zipCode'] = varZip[0]\n",
    "            briaApiJson['additionalProviderDetails']['address']['addressLineOne'] = provaddress[0]\n",
    "\n",
    "\n",
    "def facilitySpecifickeyValueOverrides(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,keyValueOverrides):\n",
    "    for OverrideKeyValue in keyValueOverrides['OverrideKeyValues']:\n",
    "        briaJsonGroup = OverrideKeyValue['briaJsonGroup']\n",
    "        briaJsonSubGroup = OverrideKeyValue['briaJsonSubGroup']\n",
    "        briaJsonField = OverrideKeyValue['briaJsonField']\n",
    "        pipeLineContextKeyName = OverrideKeyValue['pipeLineContextKeyName']\n",
    "\n",
    "        if briaApiJson['providerDetails']['servicingProvider']['facilityName'].find(OverrideKeyValue['facilityName']) > -1: \n",
    "            for extractedField in pipelinePreBuiltkeyValuePairs:\n",
    "                keyName = extractedField['Name']\n",
    "                if (keyName == pipeLineContextKeyName ):\n",
    "                    if briaJsonSubGroup == None:\n",
    "                        briaApiJson[briaJsonGroup][briaJsonField] = extractedField['Value']\n",
    "                    else:\n",
    "                        briaApiJson[briaJsonGroup][briaJsonSubGroup][briaJsonField] = extractedField['Value']\n",
    "                    \n",
    "\n",
    "\n",
    "def getStaticValues(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,idpRequestID,pipelineRawContentdoc,fieldKeys,pipelineOCRRawContent,pipelineCustomkeyValuePairs):\n",
    "    if briaApiJson['procedureInformation']['requestType'] == 'Inpatient':\n",
    "        briaApiJson['procedureInformation']['admissionType'] = 'Emergent'\n",
    "        briaApiJson['procedureInformation']['placeOfService'] = 'Hospital - Inpatient'\n",
    "        briaApiJson['procedureInformation']['stayLevel'] = 'Medical'\n",
    "        del briaApiJson['procedureInformation']['procedureCodes']   \n",
    "    elif briaApiJson['procedureInformation']['requestType'] == 'Outpatient':\n",
    "        try:\n",
    "            getProcedureCodes(pipelineRawContent,pipelineRawContentdoc,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineOCRRawContent,pipelineCustomkeyValuePairs)\n",
    "        except Exception as ex:\n",
    "            message=\"Failure in GetProcedureCodes:\" + str(ex)\n",
    "            logging.warning('FACE SHEET 2827 : extractFace sheet :  ID: %s ,  %s',pipelineContextJson['Request']['Id'],message)\n",
    "        del briaApiJson['procedureInformation']['placeOfService']\n",
    "        del briaApiJson['procedureInformation']['admissionType']\n",
    "        del briaApiJson['procedureInformation']['stayLevel']\n",
    "\n",
    "    briaApiJson['procedureInformation']['serviceType'] = 'Medical'    \n",
    "    briaApiJson['procedureInformation']['sheetType'] = 'facesheet'\n",
    "    briaApiJson['transactionMetadata']['autoSubmit'] = 'false'    \n",
    "    # TO DO write logic based on number of fields extracted\n",
    "    briaApiJson['transactionMetadata']['status'] = 'SUCCESS'\n",
    "    briaApiJson['transactionMetadata']['transactionId'] = pipelineContextJson['Request']['Id']\n",
    "    #if message is None:\n",
    "    briaApiJson['transactionMetadata']['statusMessage'] = 'IDP Extraction Succesful'\n",
    "#    else :\n",
    "#        briaApiJson['transactionMetadata']['statusMessage'] = message\n",
    "#        briaApiJson['transactionMetadata']['status'] = 'Failed'\n",
    "\n",
    "    if briaApiJson['generalInformation']['phoneNumber'].strip() == '':\n",
    "        briaApiJson['generalInformation']['phoneNumber'] = '9999999999'\n",
    "\n",
    "    if briaApiJson['generalInformation']['faxNumber'].strip() == '':\n",
    "        briaApiJson['generalInformation']['faxNumber'] = '9999999999'\n",
    "\n",
    "    if briaApiJson['generalInformation']['authorizationContactName'].strip() == '' or len(briaApiJson['generalInformation']['authorizationContactName'].strip()) < 7 :\n",
    "        briaApiJson['generalInformation']['authorizationContactName'] = 'UR Department'\n",
    "\n",
    "    if briaApiJson['procedureInformation']['procedureStartDate'].strip() == '':\n",
    "        briaApiJson['procedureInformation']['procedureStartDate'] = '01/01/0001'\n",
    "\n",
    "#reset service provider state if addresslineone is not set\n",
    "    if briaApiJson['providerDetails']['servicingProvider']['address']['addressLineOne'] == '' and briaApiJson['providerDetails']['servicingProvider']['address']['state'] != '':\n",
    "        briaApiJson['providerDetails']['servicingProvider']['address']['state'] = \"\"            \n",
    "\n",
    "\n",
    "    return(briaApiJson)\n",
    "\n",
    "\n",
    "## PART 1 of code till here\n",
    "#################### MAIN FLASK ROUTE###################\n",
    "\n",
    "@facesheetextraction.route(\n",
    "    '/facesheetextraction', methods=['POST'], endpoint='fn_facesheetextraction')\n",
    "@validate_jwt\n",
    "def fn_facesheetextraction():\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO,  format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "    logging.info('IDP-PRE-PROCESS : facesheetextraction :  facesheetextraction : Received a request')\n",
    "\n",
    "    if request.method != 'POST':\n",
    "        return jsonify(\n",
    "                    message=\"Invalid Action- Should be POST\",\n",
    "                    category=\"error\",\n",
    "                    status=500)\n",
    "    request_data = request.get_data()\n",
    "    if request_data:\n",
    "        \n",
    "        if request_data is None:\n",
    "            return jsonify(\n",
    "                    message=\"Byte array is empty\",\n",
    "                    category=\"error\",\n",
    "                    status=400), 400\n",
    "        try:\n",
    "            bytesio_array = BytesIO(request_data)\n",
    "            pipelineContextJson = json.load(bytesio_array)\n",
    "        except Exception as ex:\n",
    "            logging.error('IDP-PRE-PROCESS : facesheetextraction :  : Error decoding byte array: ' + str(ex))\n",
    "            return jsonify(\n",
    "                    message=\"Unexpected Error in Error decoding byte array:: \" + str(ex),\n",
    "                    category=\"error\",\n",
    "                    status=500), 500\n",
    "        \n",
    "        # load files\n",
    "        try:\n",
    "            auth_user = os.getenv('OSCP_NP_USER')\n",
    "            auth_password = os.getenv('OSCP_NP_PASS')    \n",
    "\n",
    "           \n",
    "            logging.info('IDP-PRE-PROCESS : facesheetextraction :  facesheetextraction : Username is ' +  auth_user )\n",
    "            if auth_user is None:\n",
    "                print(\"Unable to read username\", sys.exc_info()[0])\n",
    "                return jsonify(\n",
    "                        message=\"Unable to read username\",\n",
    "                        category=\"error\",\n",
    "                        status=500)\n",
    "\n",
    "            if auth_password is None:\n",
    "                print(\"Unable to read password\", sys.exc_info()[0])\n",
    "                return jsonify(\n",
    "                        message=\"Unable to read password\",\n",
    "                        category=\"error\",\n",
    "                        status=500)\n",
    "                  \n",
    "            \n",
    "            file_path = os.getenv('FACESHEETEXTRACTION_2827_MODELSPATH')    \n",
    "            if file_path is None:\n",
    "                print(\"Unable to find directory\", sys.exc_info()[0])\n",
    "                return jsonify(\n",
    "                        message=\"Unable to find FACESHEETEXTRACTION_2827_MODELSPATH directory\",\n",
    "                        category=\"error\",\n",
    "                        status=500)                  \n",
    "            logging.info('IDP-PRE-PROCESS : facesheetextraction :  facesheetextraction : Directory is ' +  file_path )                        \n",
    "                        \n",
    "#            file_path = './api/2827/'\n",
    "            hospitalfile = os.path.join(file_path,\"hospitals.txt\")\n",
    "            \n",
    "            #ipcmgrid = os.path.join(file_path, \"IPCMGrid.xlsx\")\n",
    "            ipcmgrid = os.path.join(file_path, \"IPCMGrid.zip\")\n",
    "            ipcmgridCPF = os.path.join(file_path, \"IPCMGridCPF.pickled\")\n",
    "            icd10_file = os.path.join(file_path, \"icd10_codes.xlsx\")\n",
    "            \n",
    "            fieldkeysFile = os.path.join(file_path, \"fieldkeys.json\")\n",
    "            keyValueOverrideFile = os.path.join(file_path, \"keyValueOverrides.json\")\n",
    "            briaApiJsonTemplateFile = os.path.join(file_path,\"bria_idp_api_request_template.json\")\n",
    "\n",
    "                       \n",
    "            with smbclient.open_file(fieldkeysFile, mode=\"r\",username=auth_user, password=auth_password,share_access=\"r\") as fieldkeysFD:\n",
    "                fieldKeys = json.load(fieldkeysFD)\n",
    "\n",
    "            with smbclient.open_file(briaApiJsonTemplateFile, mode=\"r\",username=auth_user, password=auth_password,share_access=\"r\") as briaApiJsonTemplateFD:\n",
    "                briaApiJson = json.load(briaApiJsonTemplateFD)\n",
    "\n",
    "            with smbclient.open_file(keyValueOverrideFile, mode=\"rb\",username=auth_user, password=auth_password,share_access=\"r\") as keyValueOverrideFD:\n",
    "                keyValueOverrides = json.load(keyValueOverrideFD)\n",
    "            \n",
    "\n",
    "        \n",
    "        except Exception as ex:\n",
    "            logging.error('IDP-PRE-PROCESS : facesheetextraction :  facesheetextraction : Unexpected Error in facesheetextraction-1 request : ' + str(ex))\n",
    "            return jsonify(\n",
    "                        message=\"Unexpected Error in facesheetextraction: \" + str(ex),\n",
    "                        category=\"error\",\n",
    "                        status=420)\n",
    "        \n",
    "        \n",
    "        try: \n",
    "            idpRequestID = pipelineContextJson['Request']['Id']  \n",
    "            pipelineRawContent = getPipeLineRawContent(pipelineContextJson)\n",
    "            pipelineOCRRawContent = getPipeLineOCRRawContent(pipelineContextJson)\n",
    "            pipelineRawContentdoc=nlp(pipelineRawContent)                    \n",
    "\n",
    "            pipelineCustomkeyValuePairs = getPipelineCustomkeyValuePairs(pipelineContextJson,fieldKeys)\n",
    "            pipelinePreBuiltkeyValuePairs = getPipelinePreBuiltkeyValuePairs(pipelineContextJson,nlp,fieldKeys)\n",
    "            pipelineCustomJson =  None\n",
    "            if 'CustomJSON' in pipelineContextJson['PipelineOptions']:\n",
    "                if pipelineContextJson['PipelineOptions']['CustomJSON'] is not None:\n",
    "                    pipelineCustomJson = json.loads(pipelineContextJson['PipelineOptions']['CustomJSON'])\n",
    "\n",
    "            message=\"\"\n",
    "            try:\n",
    "                getFaxNumber(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineOCRRawContent,pipelineCustomkeyValuePairs)\n",
    "            except Exception as ex:\n",
    "                message = message + \"/\" + \"Failure in GetFaxNumber: \" + str(ex)\n",
    "                logging.info('FACE SHEET 2827 : extractFace sheet :  ID: %s ,  %s',idpRequestID,message)\n",
    "                pass\n",
    "\n",
    "            try:     \n",
    "                getContactPhoneNumber(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineOCRRawContent,pipelineCustomkeyValuePairs)\n",
    "            except Exception as ex:\n",
    "                message = message + \"/\" + \"Failure in getContactPhoneNumber: \" + str(ex)\n",
    "                logging.info('FACE SHEET 2827 : extractFace sheet :  ID: %s ,  %s',idpRequestID,message)\n",
    "                pass\n",
    "\n",
    "            try:                         \n",
    "                getCustomerId(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineRawContentdoc,pipelineCustomJson,pipelineOCRRawContent,pipelineCustomkeyValuePairs)\n",
    "            except Exception as ex:\n",
    "                message = message + \"/\" + \"Failure in getCustomerId: \" + str(ex)\n",
    "                logging.info('FACE SHEET 2827 : extractFace sheet :  ID: %s ,  %s',idpRequestID,message)\n",
    "                pass\n",
    "\n",
    "            try:                         \n",
    "                getAccountNum(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineOCRRawContent,pipelineCustomkeyValuePairs)\n",
    "            except Exception as ex:\n",
    "                message = message + \"/\" + \"Failure in getAccountNum: \" + str(ex)\n",
    "                logging.info('FACE SHEET 2827 : extractFace sheet :  ID: %s ,  %s',idpRequestID,message)\n",
    "                pass\n",
    "                    \n",
    "            try:                         \n",
    "                getDOB(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineCustomJson,pipelineOCRRawContent,pipelineCustomkeyValuePairs)\n",
    "            except Exception as ex:\n",
    "                message = message + \"/\" + \"Failure in getDOB: \" + str(ex)\n",
    "                logging.info('FACE SHEET 2827 : extractFace sheet :  ID: %s ,  %s',idpRequestID,message)\n",
    "                pass\n",
    "                    \n",
    "            try:                         \n",
    "                getPatientName(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineRawContentdoc,pipelineCustomJson,pipelineOCRRawContent,pipelineCustomkeyValuePairs)\n",
    "            except Exception as ex:\n",
    "                message = message + \"/\" + \"Failure in getPatientName: \" + str(ex)\n",
    "                logging.info('FACE SHEET 2827 : extractFace sheet :  ID: %s ,  %s',idpRequestID,message)\n",
    "                pass\n",
    "                    \n",
    "            try:                         \n",
    "                getRequestType(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineOCRRawContent,pipelineCustomkeyValuePairs)\n",
    "            except Exception as ex:\n",
    "                message = message + \"/\" + \"Failure in getRequestType: \" + str(ex)\n",
    "                logging.info('FACE SHEET 2827 : extractFace sheet :  ID: %s ,  %s',idpRequestID,message)\n",
    "                pass\n",
    "\n",
    "            try:                         \n",
    "                getProcedureStartDate(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineOCRRawContent,pipelineCustomkeyValuePairs)\n",
    "            except Exception as ex:\n",
    "                message = message + \"/\" + \"Failure in getProcedureStartDate: \" + str(ex)\n",
    "                logging.info('FACE SHEET 2827 : extractFace sheet :  ID: %s ,  %s',idpRequestID,message)\n",
    "                pass\n",
    "\n",
    "            try:                         \n",
    "                getDiagnosisCodes(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,icd10_file,fieldKeys,pipelineRawContentdoc,pipelineOCRRawContent,pipelineCustomkeyValuePairs)\n",
    "            except Exception as ex:\n",
    "                message = message + \"/\" + \"Failure in getDiagnosisCodes: \" + str(ex)\n",
    "                logging.info('FACE SHEET 2827 : extractFace sheet :  ID: %s ,  %s',idpRequestID,message)\n",
    "                pass\n",
    "                    \n",
    "            try:                         \n",
    "                getRequestingNPI(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineRawContentdoc,pipelineOCRRawContent,pipelineCustomkeyValuePairs)\n",
    "            except Exception as ex:\n",
    "                message = message + \"/\" + \"Failure in getRequestingNPI: \" + str(ex)\n",
    "                logging.info('FACE SHEET 2827 : extractFace sheet :  ID: %s ,  %s',idpRequestID,message)\n",
    "                pass\n",
    "                    \n",
    "            try:                         \n",
    "                getServicingfacilityName(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineRawContentdoc,hospitalfile,pipelineOCRRawContent,pipelineCustomkeyValuePairs)\n",
    "            except Exception as ex:\n",
    "                message = message + \"/\" + \"Failure in getServicingfacilityName: \" + str(ex)\n",
    "                logging.info('FACE SHEET 2827 : extractFace sheet :  ID: %s ,  %s',idpRequestID,message)\n",
    "                pass\n",
    "\n",
    "            try:                         \n",
    "                getRequestingProvider(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineRawContentdoc,nlp,pipelineOCRRawContent,pipelineCustomkeyValuePairs)\n",
    "            except Exception as ex:\n",
    "                message = message + \"/\" + \"Failure in getRequestingProvider: \" + str(ex)\n",
    "                logging.info('FACE SHEET 2827 : extractFace sheet :  ID: %s ,  %s',idpRequestID,message)\n",
    "                pass\n",
    "\n",
    "            try:     \n",
    "                getMRN(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineRawContentdoc,pipelineOCRRawContent,pipelineCustomkeyValuePairs)\n",
    "            except Exception as ex:\n",
    "                message = message + \"/\" + \"Failure in getMRN: \" + str(ex)\n",
    "                logging.info('FACE SHEET 2827 : extractFace sheet :  ID: %s ,  %s',idpRequestID,message)\n",
    "                pass\n",
    "                    \n",
    "            try:                         \n",
    "                getTIN(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineRawContentdoc,pipelineOCRRawContent,pipelineCustomkeyValuePairs)\n",
    "            except Exception as ex:\n",
    "                message = message + \"/\" + \"Failure in getTIN: \" + str(ex)\n",
    "                logging.info('FACE SHEET 2827 : extractFace sheet :  ID: %s ,  %s',idpRequestID,message)\n",
    "                pass\n",
    "\n",
    "            try:                         \n",
    "                getAddress(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineRawContentdoc,pipelineOCRRawContent,pipelineCustomkeyValuePairs)\n",
    "                getGoogleMapsaddress(pipelineRawContent,briaApiJson)\n",
    "            except Exception as ex:\n",
    "                message = message + \"/\" + \"Failure in getAddress: \" + str(ex)\n",
    "                logging.info('FACE SHEET 2827 : extractFace sheet :  ID: %s ,  %s',idpRequestID,message)\n",
    "                pass\n",
    "\n",
    "            try:                         \n",
    "                getRequestingProviderAddress(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineOCRRawContent,pipelineCustomkeyValuePairs)\n",
    "            except Exception as ex:\n",
    "                message = message + \"/\" + \"Failure in getRequestingProviderAddress: \" + str(ex)\n",
    "                logging.info('FACE SHEET 2827 : extractFace sheet :  ID: %s ,  %s',idpRequestID,message)\n",
    "                pass\n",
    "\n",
    "            try:     \n",
    "                pass\n",
    "#                       getAuthorizationContactName(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,fieldKeys,pipelineRawContentdoc,nlp,pipelineOCRRawContent,pipelineCustomkeyValuePairs)\n",
    "            except Exception as ex:\n",
    "                message = message + \"/\" + \"Failure in getAuthorizationContactName: \" + str(ex)\n",
    "                logging.info('FACE SHEET 2827 : extractFace sheet :  ID: %s ,  %s',idpRequestID,message)\n",
    "                pass\n",
    "\n",
    "            try:     \n",
    "                getIPCMValues(ipcmgrid,briaApiJson,fieldKeys)\n",
    "                getIPCMValuesCPF(ipcmgridCPF,briaApiJson,fieldKeys)\n",
    "            except Exception as ex:\n",
    "                message = message + \"/\" + \"Failure in getIPCMValues: \" + str(ex)\n",
    "                logging.info('FACE SHEET 2827 : extractFace sheet :  ID: %s ,  %s',idpRequestID,message)\n",
    "                pass\n",
    "\n",
    "            try:     \n",
    "                facilitySpecifickeyValueOverrides(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,keyValueOverrides)\n",
    "            except Exception as ex:\n",
    "                message = message + \"/\" + \"Failure in facilitySpecifickeyValueOverrides: \" + str(ex)\n",
    "                logging.info('FACE SHEET 2827 : extractFace sheet :  ID: %s ,  %s',idpRequestID,message)\n",
    "                pass\n",
    "\n",
    "\n",
    "            try:     \n",
    "                getStaticValues(pipelineContextJson,pipelineRawContent,pipelinePreBuiltkeyValuePairs,briaApiJson,idpRequestID,pipelineRawContentdoc,fieldKeys,pipelineOCRRawContent,pipelineCustomkeyValuePairs)\n",
    "            except Exception as ex:\n",
    "                message = message + \"/\" + \"Failure in getStaticValues: \" + str(ex)\n",
    "                logging.info('FACE SHEET 2827 : extractFace sheet :  ID: %s ,  %s',idpRequestID,message)\n",
    "                pass\n",
    "            \n",
    "            return jsonify(message=message, category=\"Success\", briaApiModel = briaApiJson, status=200)\n",
    "            \n",
    "        except Exception as ex:\n",
    "            logging.error('IDP-PRE-PROCESS : facesheetextraction :  facesheetextraction : Unexpected Error in facesheetextraction3: ' + str(ex))\n",
    "            return jsonify(\n",
    "                        message=\"Unexpected Error in facesheetextraction: \" + str(ex),\n",
    "                        category=\"error\",\n",
    "                        status=420)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0e2a59",
   "metadata": {},
   "source": [
    "# api_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7624d787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "from email.errors import FirstHeaderLineIsContinuationDefect\n",
    "from flask import Flask, request, send_file, Blueprint\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import io\n",
    "from PIL import Image\n",
    "import base64\n",
    "from flask.json import jsonify\n",
    "import jwt\n",
    "from ibm_db2 import IBM_DB2_Connection\n",
    "from pdf2image import convert_from_bytes\n",
    "from random import randint\n",
    "import datetime\n",
    "import multiprocessing\n",
    "import pytesseract\n",
    "import logging\n",
    "if os.name != 'nt':\n",
    "    from gunicornapplication import StandaloneApplication\n",
    "# Comment these lines in if attempting to run locally on windows\n",
    "# Requires .env file to exist in root directory\n",
    "#else:\n",
    "#    from dotenv import load_dotenv\n",
    "#    from pathlib import Path\n",
    "#    BASE_DIR = os.path.abspath(os.path.dirname(__file__))\n",
    "#    load_dotenv(dotenv_path=os.path.join(BASE_DIR, \"..\", \".env\"))\n",
    "from convert_png_to_pdf import convert_png_to_pdf\n",
    "from convert_pdf_to_png import convert_pdf_to_png, convert_pdf_to_png_bytes\n",
    "from annotate_pdf import annotate_pdf\n",
    "from validate_jwt import validate_jwt\n",
    "from digitize_cm_survey import digitize_cm_survey\n",
    "from digitize_hphb_survey import digitize_hphb_survey\n",
    "from digitize_oncology_support_survey import digitize_oncology_support_survey\n",
    "from digitize_customer_survey import digitize_customer_survey\n",
    "from split_pdf import split_pdf\n",
    "from split_tiff import split_tiff\n",
    "from covid_otc_claim_extract import covid_otc_claim_extract\n",
    "from convert_tif_to_pdf import convert_tif_to_pdf\n",
    "from footnotes_compare import footnotes_compare\n",
    "from apply_translation_to_pdf import apply_translation_to_pdf\n",
    "from extractPdqEmail import extractPdqEmail\n",
    "from extractPdqChecklist import extractPdqChecklist\n",
    "from convert_pdf_to_html import convert_pdf_to_html_bytes\n",
    "from get_intl_claims_key_name import get_intl_claims_key_name\n",
    "from expedited_appeals_info_extract import execute\n",
    "from gov_appeals_classify_page import is_expedited_page\n",
    "from gov_appeals_classify_page import merge_id_function\n",
    "from gov_appeals_classify_page import claim_extraction\n",
    "from facesheetextraction import facesheetextraction\n",
    "from md_sbc_preprocess_img import sbc_preprocess_img\n",
    "from contract_pdf_preprocess import contract_pdf_preprocess\n",
    "import json\n",
    "\n",
    "def number_of_workers():\n",
    "    optimum_workes_cnt  = (multiprocessing.cpu_count() * 2) + 1\n",
    "    return 9 if optimum_workes_cnt > 9 else optimum_workes_cnt\n",
    "\n",
    "\n",
    "def preprocess(img):\n",
    "    \n",
    "    img = img.astype(np.float32)\n",
    "\n",
    "    img /= 255.\n",
    "\n",
    "    img_gaussian = cv2.GaussianBlur(img, (3,3),0)\n",
    "\n",
    "    kernel = np.array([[1, 1, 1],[1, 0, 1],[1, 1, 1]])\n",
    "\n",
    "    img_filtered = cv2.filter2D(img_gaussian, -1, kernel)\n",
    "\n",
    "    height = img_filtered.shape[0]\n",
    "    width = img_filtered.shape[1]\n",
    "\n",
    "    img_comp_orig_filtered = np.ndarray((height, width))\n",
    "\n",
    "    j = 0\n",
    "    while j<height:\n",
    "        i = 0\n",
    "        while i<width:\n",
    "            if img_filtered[j,i] >= (6.5):\n",
    "            # if img_filtered[j,i] >= (7.25):\n",
    "                img_comp_orig_filtered[j,i] = (1)\n",
    "            else:\n",
    "                img_comp_orig_filtered[j,i] = img[j,i]\n",
    "            i = i+1\n",
    "        j = j+1\n",
    "    \n",
    "    img_comp_orig_filtered = img_comp_orig_filtered.astype(\n",
    "        np.uint8) * 255\n",
    "    \n",
    "    img_comp_orig_filtered_inv = cv2.bitwise_not(\n",
    "        img_comp_orig_filtered)\n",
    "\n",
    "    kernel_dilate = np.ones((1,2), np.uint8)\n",
    "\n",
    "    img_comp_orig_filtered_inv_dilated = cv2.dilate(\n",
    "        img_comp_orig_filtered_inv, kernel_dilate,iterations=1)\n",
    "\n",
    "    img_comp_orig_filtered_dilated = cv2.bitwise_not(\n",
    "        img_comp_orig_filtered_inv_dilated)\n",
    "\n",
    "    img_comp_orig_filtered_dilated_resized = cv2.resize(\n",
    "        img_comp_orig_filtered_dilated,\n",
    "        (1024,1024),\n",
    "        interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    return img_comp_orig_filtered_inv_dilated, \\\n",
    "        img_comp_orig_filtered_dilated_resized\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.register_blueprint(convert_pdf_to_png)\n",
    "app.register_blueprint(convert_png_to_pdf)\n",
    "app.register_blueprint(convert_pdf_to_png_bytes)\n",
    "app.register_blueprint(annotate_pdf)\n",
    "app.register_blueprint(split_pdf)\n",
    "app.register_blueprint(split_tiff)\n",
    "app.register_blueprint(apply_translation_to_pdf)\n",
    "app.register_blueprint(extractPdqEmail)\n",
    "app.register_blueprint(extractPdqChecklist)\n",
    "app.register_blueprint(convert_pdf_to_html_bytes)\n",
    "app.register_blueprint(get_intl_claims_key_name)\n",
    "app.register_blueprint(facesheetextraction)\n",
    "app.register_blueprint(is_expedited_page)\n",
    "app.register_blueprint(merge_id_function)\n",
    "app.register_blueprint(claim_extraction)\n",
    "app.register_blueprint(contract_pdf_preprocess)\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "@app.route('/health')\n",
    "def health():\n",
    "    logging.basicConfig(level=logging.INFO,  format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    logging.info('IDP-PRE-PROCESS : health :  Healthy')\n",
    "    return {'message': 'Healthy'}  # This will return as JSON by default with a 200 status code\n",
    "\n",
    "@app.route('/ocr', methods=['POST'], endpoint='ocr')\n",
    "def ocr():\n",
    "    if request.method == 'POST':\n",
    "        img_sent = base64.b64decode(request.data)\n",
    "        nparr = np.frombuffer(img_sent, np.uint8)\n",
    "        img = cv2.imdecode(nparr, 0)\n",
    "        config=('--l ebg --oem 3 --psm 8')\n",
    "        pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'\n",
    "        return {'analyzeResult': pytesseract.image_to_string(img)}\n",
    "\n",
    "@app.route('/preprocess', methods=['POST'], endpoint='upload_file')\n",
    "@validate_jwt\n",
    "def upload_file():\n",
    "\n",
    "    if request.method == 'POST':\n",
    "        img_sent = base64.b64decode(request.data)\n",
    "        nparr = np.frombuffer(img_sent, np.uint8)\n",
    "        img = cv2.imdecode(nparr, 0)\n",
    "\n",
    "        _, preprocessed_resized_img = preprocess(img)\n",
    "        img_pil = Image.fromarray(preprocessed_resized_img.astype('uint8'))\n",
    "        file_object = io.BytesIO()\n",
    "\n",
    "        img_pil.save(file_object,'png')\n",
    "        file_object.seek(0)\n",
    "        return send_file(\n",
    "            file_object,\n",
    "            as_attachment=True,\n",
    "            download_name='response_img.png',\n",
    "            mimetype='image/png')\n",
    "\n",
    "@app.route(\n",
    "    '/pdf2tiff', methods=['POST'], endpoint='convert_pdf_to_images')\n",
    "@validate_jwt\n",
    "def convert_pdf_to_images():\n",
    "\n",
    "    if request.method == 'POST':\n",
    "        try: \n",
    "            data = request.get_data()\n",
    "        except:\n",
    "            print(\"Unexpected error :\", sys.exc_info()[0])\n",
    "            raise\n",
    "\n",
    "        try: \n",
    "            images = convert_from_bytes(\n",
    "                data,\n",
    "                dpi=200)\n",
    "        except:\n",
    "            print(\"Unexpected error :\", sys.exc_info()[0])\n",
    "            raise\n",
    "\n",
    "        msecpart=datetime.datetime.now().strftime(\"%f\")\n",
    "        dir_path = os.path.dirname(os.path.realpath(__file__))\n",
    "        output_folder = dir_path+f\"/data-{randint(0,1000000000)}-{msecpart}\"\n",
    "\n",
    "        try:\n",
    "            os.makedirs(output_folder)\n",
    "            print(f\"directory {output_folder} created successfully\")\n",
    "        except:\n",
    "            print(\"Unexpected error :\", sys.exc_info()[0])\n",
    "            raise\n",
    "\n",
    "        for index, image in enumerate(images):\n",
    "            try:\n",
    "                image.save(f'{output_folder}/image-converted-from-bytes{index}.tiff')\n",
    "            except:\n",
    "                print(\"Unexpected error :\", sys.exc_info()[0])\n",
    "                raise\n",
    "\n",
    "            \n",
    "\n",
    "        #Read all tiff images and base64 encode\n",
    "        tif_images = os.listdir(output_folder)\n",
    "        print(f\"tif images saved {tif_images}\")\n",
    "\n",
    "        encoded_images = {}\n",
    "        for index, tif_image in enumerate(tif_images):\n",
    "            tif_image_full_path = f'{output_folder}/{tif_image}'\n",
    "            \n",
    "            print(f\"tif image full path {tif_image_full_path}\")\n",
    "            \n",
    "            with open(tif_image_full_path, \"rb\") as f:\n",
    "                tif_file = base64.b64encode(f.read())\n",
    "                tif_file_str = tif_file.decode(\"utf-8\")\n",
    "\n",
    "            try:\n",
    "                encoded_images[index] = tif_file_str\n",
    "            except:\n",
    "                print(\n",
    "                    \"Unexpected error with creating obj to be returned:\",\n",
    "                    sys.exc_info()[0])\n",
    "                raise\n",
    "\n",
    "        # Deletes all saved images and returns a binary of TIFF images\n",
    "        for tif_image in tif_images:\n",
    "            tif_image_full_path = f'{output_folder}/{tif_image}'\n",
    "            os.remove(tif_image_full_path) \n",
    "        \n",
    "        try:\n",
    "            os.rmdir(output_folder)\n",
    "            print(f\"directory {output_folder} removed successfully\")\n",
    "        except:\n",
    "            print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "            print(f\"failed to remove the directory {output_folder}\")\n",
    "\n",
    "        return jsonify(encoded_images)\n",
    "\n",
    "@app.route('/digitizecmsurvey', methods=['POST'], endpoint='digitize_cm_survey_ep')\n",
    "@validate_jwt\n",
    "def digitize_cm_survey_ep():\n",
    "\n",
    "    if request.method == 'POST':\n",
    "        pdf_tiff_base64_str = request.get_json()\n",
    "\n",
    "        if 'pdf_bytes' in pdf_tiff_base64_str:\n",
    "            pdf_data_str = pdf_tiff_base64_str['pdf_bytes']\n",
    "\n",
    "            pdf_data_str_encoded = pdf_data_str.encode('utf-8')\n",
    "            pdf_data_bytes = base64.b64decode(pdf_data_str_encoded)\n",
    "        \n",
    "        \n",
    "        if 'tiff_bytes' in pdf_tiff_base64_str:\n",
    "            tiff_data_str = pdf_tiff_base64_str['tiff_bytes']\n",
    "\n",
    "            tiff_data_str_encoded = tiff_data_str.encode('utf-8')\n",
    "            tiff_data_bytes = base64.b64decode(tiff_data_str_encoded)\n",
    "\n",
    "        return digitize_cm_survey(pdf_data_bytes, tiff_data_bytes)   \n",
    "\n",
    "@app.route('/digitizehphbsurvey', methods=['POST'], endpoint='digitize_hphb_survey_ep')\n",
    "@validate_jwt\n",
    "def digitize_hphb_survey_ep():\n",
    "\n",
    "    if request.method == 'POST':\n",
    "        pdf_tiff_base64_str = request.get_json()\n",
    "\n",
    "        if 'pdf_bytes' in pdf_tiff_base64_str:\n",
    "            pdf_data_str = pdf_tiff_base64_str['pdf_bytes']\n",
    "\n",
    "            pdf_data_str_encoded = pdf_data_str.encode('utf-8')\n",
    "            pdf_data_bytes = base64.b64decode(pdf_data_str_encoded)\n",
    "        \n",
    "        \n",
    "        if 'tiff_bytes' in pdf_tiff_base64_str:\n",
    "            tiff_data_str = pdf_tiff_base64_str['tiff_bytes']\n",
    "\n",
    "            tiff_data_str_encoded = tiff_data_str.encode('utf-8')\n",
    "            tiff_data_bytes = base64.b64decode(tiff_data_str_encoded)\n",
    "\n",
    "        return digitize_hphb_survey(pdf_data_bytes, tiff_data_bytes)  \n",
    "\n",
    "@app.route('/digitizeoncologysurvey', methods=['POST'], endpoint='digitize_oncology_support_survey_ep')\n",
    "@validate_jwt\n",
    "def digitize_oncology_support_survey_ep():\n",
    "\n",
    "    if request.method == 'POST':\n",
    "        pdf_tiff_base64_str = request.get_json()\n",
    "\n",
    "        if 'pdf_bytes' in pdf_tiff_base64_str:\n",
    "            pdf_data_str = pdf_tiff_base64_str['pdf_bytes']\n",
    "\n",
    "            pdf_data_str_encoded = pdf_data_str.encode('utf-8')\n",
    "            pdf_data_bytes = base64.b64decode(pdf_data_str_encoded)\n",
    "        \n",
    "        \n",
    "        if 'tiff_bytes' in pdf_tiff_base64_str:\n",
    "            tiff_data_str = pdf_tiff_base64_str['tiff_bytes']\n",
    "\n",
    "            tiff_data_str_encoded = tiff_data_str.encode('utf-8')\n",
    "            tiff_data_bytes = base64.b64decode(tiff_data_str_encoded)\n",
    "\n",
    "        return digitize_oncology_support_survey(pdf_data_bytes, tiff_data_bytes)  \n",
    "\n",
    "@app.route('/digitizesurveyforms', methods=['POST'], endpoint='digitize_customer_survey_ep')\n",
    "@validate_jwt\n",
    "def digitize_customer_survey_ep():\n",
    "\n",
    "    if request.method == 'POST':\n",
    "        pdf_tiff_base64_str = request.get_json()\n",
    "\n",
    "        if 'pdf_bytes' in pdf_tiff_base64_str:\n",
    "            pdf_data_str = pdf_tiff_base64_str['pdf_bytes']\n",
    "\n",
    "            pdf_data_str_encoded = pdf_data_str.encode('utf-8')\n",
    "            pdf_data_bytes = base64.b64decode(pdf_data_str_encoded)\n",
    "        \n",
    "        \n",
    "        if 'tiff_bytes' in pdf_tiff_base64_str:\n",
    "            tiff_data_str = pdf_tiff_base64_str['tiff_bytes']\n",
    "\n",
    "            tiff_data_str_encoded = tiff_data_str.encode('utf-8')\n",
    "            tiff_data_bytes = base64.b64decode(tiff_data_str_encoded)\n",
    "\n",
    "        return digitize_customer_survey(pdf_data_bytes, tiff_data_bytes)   \n",
    "\n",
    "@app.route('/covidotcclaimextract', methods=['POST'], endpoint='covid_otc_claim_extract_ep')\n",
    "@validate_jwt\n",
    "def covid_otc_claim_extract_ep():\n",
    "    \n",
    "    if request.method == 'POST':\n",
    "        # img_bytes_str_encoded = request.data.encode('utf-8')\n",
    "        img_bytes = base64.b64decode(request.data)\n",
    "    \n",
    "    return covid_otc_claim_extract(img_bytes)  \n",
    "\n",
    "\n",
    "@app.route('/contractfncompare', methods=['POST'], endpoint='contract_footnotes_compare_ep')\n",
    "@validate_jwt\n",
    "def contract_footnotes_compare_ep():\n",
    "\n",
    "    if request.method == 'POST':\n",
    "        key_value_pair_loaded = request.get_json()\n",
    "\n",
    "        old_footnotes = {}\n",
    "        new_footnotes = {}\n",
    "        \n",
    "        for k,v in key_value_pair_loaded.items():\n",
    "            if k == 'OldFootNotes':\n",
    "                for old_footnotes_key, old_footnotes_value in v.items():\n",
    "                    old_footnotes_key_int = int(old_footnotes_key)\n",
    "                    old_footnotes[old_footnotes_key_int] = old_footnotes_value\n",
    "            if k == 'NewFootNotes':\n",
    "                for new_footnotes_key, new_footnotes_value in v.items():\n",
    "                    new_footnotes_key_int = int(new_footnotes_key)\n",
    "                    new_footnotes[new_footnotes_key_int] = new_footnotes_value\n",
    "\n",
    "    try:    \n",
    "        comp_results = footnotes_compare(\n",
    "            old_footnotes,\n",
    "            new_footnotes)\n",
    "\n",
    "    except Exception as err:\n",
    "        logging.error(\n",
    "            f'FOOTNOTES-COMPARISON : contract_footnotes_compare : '\n",
    "            f'Unexpected error in footnotes_compare : {str(err)}')\n",
    "\n",
    "        comp_results = {\n",
    "            'comparison_status':'failed',\n",
    "            'error_type': (\n",
    "                f'Unexpected error with contract_footnotes_compare'),\n",
    "            'error_message': str(err)}\n",
    "\n",
    "    finally:\n",
    "        return comp_results\n",
    "\n",
    "\n",
    "@app.route('/db2_methods', methods=['POST'], endpoint='db2_methods')\n",
    "@validate_jwt\n",
    "def db2_methods():\n",
    "    '''\n",
    "    API endpoint for all DB2 methods.  The POST call expects the body to be JSON formatted with the following objects:\n",
    "        \n",
    "        - 'connection'  - The DB2 connection string (TODO:  Look at adding this as an environment variable.).\n",
    "        - 'data1'       - The first data object expected to to be supplied to the intended method.\n",
    "        - 'method'      - The intended method to be called.\n",
    "\n",
    "    Returns:\n",
    "        The response from the intended method.\n",
    "    '''\n",
    "\n",
    "    required_fields = [ 'connection', 'data1', 'method' ]\n",
    "\n",
    "    if request.method == 'POST':\n",
    "        elements = request.get_json()\n",
    "\n",
    "        if not all(element in elements for element in required_fields):\n",
    "            return f\"Missing one or more required fields: {required_fields}\", 400\n",
    "        if not 'life' in elements['connection'].lower():\n",
    "            return f\"Invalid connection string\", 400\n",
    "\n",
    "        ibm = IBM_DB2_Connection(elements['connection'], \"\", \"\")\n",
    "\n",
    "        try:\n",
    "            method = elements['method']\n",
    "            logging.info(f'Attempting to perform (' + method + ')')\n",
    "            if method == 'GetMemberInfo':\n",
    "                res = ibm.check_for_member(elements['data1'])\n",
    "                logging.info(f'Returning HTTP 200')\n",
    "                return { \"result\": res }, 200\n",
    "\n",
    "            elif method == 'WriteCoversheetInfo':\n",
    "                res = ibm.insert_coversheet(elements['data1'])\n",
    "                logging.info(f'Returning HTTP 200')\n",
    "                return { \"result\": res }, 200\n",
    "\n",
    "            elif method == 'InsertItemizationData':\n",
    "                res = ibm.insert_itemizations(elements['data1'])\n",
    "                logging.info(f'Returning HTTP 200')\n",
    "                return { \"result\": res }, 200\n",
    "\n",
    "            else:\n",
    "                return f\"method value provided: (\" + elements['method'] + ') has not been implemented.', 400\n",
    "\n",
    "        except ValueError as e:\n",
    "            logging.error(f'{e}')\n",
    "            return str(e), 400\n",
    "\n",
    "\n",
    "@app.route(\n",
    "    '/expdappealext', \n",
    "    methods=['POST'], \n",
    "    endpoint='expd_appeal_extract_ep')\n",
    "    \n",
    "@validate_jwt\n",
    "def expd_appeal_extract_ep():\n",
    "\n",
    "    if request.method == 'POST':\n",
    "        image_wise_extract = request.get_json()\n",
    "\n",
    "        try:    \n",
    "            if len(image_wise_extract) == 1:\n",
    "                for img_name, page_level_extracts_list in image_wise_extract.items():\n",
    "                    _, _, _,extract_results = \\\n",
    "                        execute(\n",
    "                            img_name, page_level_extracts_list )\n",
    "\n",
    "        except Exception as err:\n",
    "            logging.error(\n",
    "                f'EXPEDITED-APPEALS-INFO-EXTRACT : expedited_appeals_info_extract : '\n",
    "                f'Unexpected error in execute: {str(err)}')\n",
    "\n",
    "            extract_results = {\n",
    "                'comparison_status':'failed',\n",
    "                'error_type': (\n",
    "                    f'Unexpected error with expedited_appeals_info_extract'),\n",
    "                'error_message': str(err)}\n",
    "\n",
    "        finally:\n",
    "            return json.dumps(extract_results)\n",
    "\n",
    "\n",
    "@app.route('/sbcpreprocess', methods=['POST'], endpoint='sbc_preprocess_ep')\n",
    "@validate_jwt\n",
    "def sbc_preprocess_ep():\n",
    "    \n",
    "    if request.method == 'POST':\n",
    "        base64_str = request.data\n",
    "\n",
    "        \n",
    "        try:    \n",
    "          results = sbc_preprocess_img(base64_str)  \n",
    "\n",
    "        except Exception as err:\n",
    "            logging.error(\n",
    "                f'SBC-PREPROCESS-IMG : sbc_preprocess_ep : '\n",
    "                f'Unexpected error in execute: {str(err)}')\n",
    "\n",
    "            results = {\n",
    "                'img_preprocess_status':'failed',\n",
    "                'error_type': (\n",
    "                    f'Unexpected error with sbc_preprocess_img'),\n",
    "                'error_message': str(err)}\n",
    "\n",
    "        finally:\n",
    "            return results\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    if os.name == 'nt':\n",
    "        app.run()\n",
    "    else:\n",
    "        if os.environ.get('TLS_CERT') is not None and os.environ.get('TLS_KEY') is not None :\n",
    "            tls_cert_path = os.getenv('TLS_CERT')\n",
    "            tls_key_path = os.getenv('TLS_KEY')\n",
    "           \n",
    "            options = {\n",
    "            'bind': '%s:%s' % ('0.0.0.0', '5000'),\n",
    "            'workers': number_of_workers(),\n",
    "            #'workers':2,\n",
    "            # 'threads':4,\n",
    "            'max_requests' : os.getenv('APP_MAX_REQUESTS', 1),\n",
    "            'reload': os.getenv('DEBUG_MODE', False),\n",
    "    #        'worker_tmp_dir' : '/dev/shm',\n",
    "            'certfile': tls_cert_path,\n",
    "            'keyfile': tls_key_path,\n",
    "            'timeout' : 600,\n",
    "            'loglevel': 'info'\n",
    "            }\n",
    "            StandaloneApplication(app, options).run()\n",
    "            \n",
    "        else:\n",
    "            options = {\n",
    "            'bind': '%s:%s' % ('0.0.0.0', '5000'),\n",
    "            # 'workers':2,\n",
    "            # 'threads':4,\n",
    "            'workers': number_of_workers(),\n",
    "            'max_requests' : os.getenv('APP_MAX_REQUESTS', 1),\n",
    "    #        'worker_tmp_dir' : '/dev/shm',\n",
    "            'reload': os.getenv('DEBUG_MODE', False),\n",
    "            'timeout' : 600,\n",
    "            'loglevel': 'info'\n",
    "            }\n",
    "            StandaloneApplication(app, options).run()  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
